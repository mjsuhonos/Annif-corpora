TOWARDS AN AUTOMATED SOFT PROOFING SYSTEM USING HIGH DYNAMIC RANGE IMAGING AND ARTIFICIAL NEURAL NETWORKS
by

Nawar Fdhal, B.A.Sc, B.Eng.

A thesis presented to Ryerson University in partial fulfillment of the requirement for the degree of Master of Applied Science in the Program of Electrical and Computer Engineering

Toronto, Ontario, Canada, April 2011

c Nawar Fdhal, April 2011 

Author's Declaration
I hereby declare that I am the sole author of this thesis. I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research only.

Signature

I further authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research only.

Signature

ii

Borrowers' Page
Ryerson University requires the signatures of all persons using or photocopying this thesis. Please sign below, and give address and date.

iii

Abstract

Towards an Automated Soft Proofing System using High Dynamic Range Imaging and Artificial Neural Networks Nawar Fdhal Master of Applied Science, Electrical and Computer Engineering Ryerson University, Toronto, Ontario, Canada, 2011

In this thesis, an adaptive mechanism for controlling the illumination is combined with a closed loop technique and the use of High Dynamic range (HDR) to generate a black box model that can simulate the hard proof of a given digital image. An adaptive Artificial Neural Network (ANN) was used to create the black box model, using the camera as a measuring device. The non-uniformity of the illumination in the viewing booth is typically a barrier in creating such a black box model since color appearance varies with location in the viewing booth. This issue was addressed in this thesis by compensating for viewing booth illumination using an inexpensive camera and a Liquid Crystal Display (LCD) projector. HDR was found to give a favourable representation that is more indicative of the image perceived by the operator, and was used as the basis for mapping the original image to the soft proof. A proof of concept was also developed to highlight the utility of the LCD projector based approach in providing a more broad range of varying intensity color illuminants (thus environments) under which a proof may be not only viewed, but modeled through the closed loop process. In this sense, a system has been developed to generate and provide custom soft proofs that can extend the functionality of the standard viewing booth. The proposed technique will open the doors to new automated systems that can be very beneficial to the printing industry. iv

Acknowledgments
I, Nawar Fdhal, would like to express my gratitude to everyone who contributed to making my master studies a great experience. I wish to single out my supervisor, my friend, a mentor, Dr. Matthew Kyan, for his great guidance, support and encouragement during my master studies. He had a great impact on my study, his great ideas and thoughts made my life as graduate student interesting, and the amount that I have learned from him was unlimited. I also would like to thank my co-supervisor Dr. Dimitri Androutsos for everything especially for his valuable course in the digital imaging processing in which I learned a significant amount of information that help me in my thesis. This thesis would not have been possible without the great help and assistant from MPP Marketing Group for providing the equipments needed to make this thesis happen. It was a pleasure to meet MPP president, Mark Sibilia, who was a great person to meet. It was also honour for me to meet and work with Angus Pady who is the best color specialist in the imaging and printing media. I learned a big deal from his experience and knowledge. I appreciate the great help from him in making my thesis beneficial to the printing industry. I would also like to extent my special thanks and appreciations to all my family especially my mother, Bashar, Ammar, Najwan, and Nadeen for their continuous support, encouragement and love throughout my life that helped me excel in my academic studies. I would like to single out my brother Bashar who supported me all my life especially when I came to Canada and started my undergraduate degree. He helped and made my life to where I am today. I really thank him very much for all his efforts. A special thank to my great father Badie Mahfooth, he used to tell me that I should do my master's degree in the printing industry since my family established the first printing press business in Iraq in 1908. My father and mother, I now realize more what you have done for me to make the person I am today. Finally, I would like to thank my lovely wife, Bassma, for being there for me especially during the tough times in my research. My thanks to you is unlimited. I love you so much and I will keep supporting you during your PhD research to make it very successful. You are such a great wife and you have put enormous efforts towards me especially in my study since we met. I also would like to thank Bassma's family for their continuous support during my study.

v

Contents
Author's Declaration Borrowers' Page Abstract Acknowledgments 1 Introduction 1.1 Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2 Problem Statement and Thesis Contributions . . . . . . . . . . . . . . . . . 1.3 Organization of the Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2 Background Theory and Related Work 2.1 The Importance of Color Management . . . . . . . . . . . . 2.1.1 Color Workflow Control . . . . . . . . . . . . . . . . 2.2 ICC Color Management . . . . . . . . . . . . . . . . . . . . 2.2.1 ICC Profiles . . . . . . . . . . . . . . . . . . . . . . . 2.2.2 How to Obtain an ICC Profile . . . . . . . . . . . . . 2.3 Calibration of Imaging Devices . . . . . . . . . . . . . . . . 2.3.1 Calibrating a Monitor . . . . . . . . . . . . . . . . . 2.3.2 Calibrating a Printer . . . . . . . . . . . . . . . . . . 2.3.3 Calibrating a the Camera . . . . . . . . . . . . . . . 2.4 Soft Proofing Systems . . . . . . . . . . . . . . . . . . . . . 2.5 Projection System as a Potential Illuminant . . . . . . . . . 2.5.1 Overview on Projectors . . . . . . . . . . . . . . . . . 2.5.2 Types of Projector Display Technology . . . . . . . . 2.5.3 Choice of Projector Technology for Compensating the 2.5.4 Color Variations in a Projector . . . . . . . . . . . . 2.5.5 Intensity Transfer Function of the Projector . . . . . ii iii iv v 1 1 5 9 10 10 10 12 14 15 18 18 19 20 21 24 25 25 28 30 31

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Viewing . . . . . . . . . .

. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Booth . . . . . . . .

vi

3 Printer Modeling Using an Artificial Neural Network 3.1 Color Imaging Device Characterization . . . . . . . . . . . . 3.2 Artificial Neural Networks for Printer Modeling . . . . . . . 3.3 Experimental Procedure . . . . . . . . . . . . . . . . . . . . 3.3.1 Generating an ICC Profile . . . . . . . . . . . . . . . 3.3.2 Data Preprocessing . . . . . . . . . . . . . . . . . . . 3.3.3 Training Process using LM Back Propagation Model 3.4 Results and Discussion . . . . . . . . . . . . . . . . . . . . . 4 Modeling The Printer Output In The 4.1 Investigation of HDR Imaging . . . . 4.1.1 Normal Imaging Techniques . 4.1.2 HDR Imaging Techniques . . 4.2 Experimental Setup . . . . . . . . . . 4.2.1 Image Registration . . . . . . 4.2.2 Data Preprocessing . . . . . . 4.2.3 Training . . . . . . . . . . . . 4.3 Results and Discussion . . . . . . . . Viewing Booth . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

. . . . . . .

33 33 34 35 36 37 39 39 43 43 44 49 49 51 53 53 56 61 61 62 63 65 67 70 71 73 73 74 75 79 84 84 87 93

With . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

HDR . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

. . . . . . . .

. . . . . . . .

. . . . . . . .

. . . . . . . .

5 Improved Modeling By Viewing Booth Light Compensation 5.1 Projector Calibration and Registration . . . . . . . . . . . . . . . . 5.1.1 Experimental Setup . . . . . . . . . . . . . . . . . . . . . . . 5.1.2 Finding the Camera Response Curve . . . . . . . . . . . . . 5.1.3 Calculating the Intensity Transfer Function of the Projector 5.1.4 Camera - Projector Registration . . . . . . . . . . . . . . . . 5.1.5 Calculating the Luminosity surface of the Projector . . . . . 5.1.6 Achieving Photometric Uniformity . . . . . . . . . . . . . . 5.2 Viewing booth lighting . . . . . . . . . . . . . . . . . . . . . . . . . 5.2.1 Experimental setup . . . . . . . . . . . . . . . . . . . . . . . 5.2.2 Camera - Projector Registration in the Viewing Booth . . . 5.2.3 Uniform Viewing Booth Based on an LCD Projector . . . . 5.2.4 Methodology of Creating a Uniform Viewing Booth . . . . . 5.3 Soft Proofing Using Hybrid Viewing Booth . . . . . . . . . . . . . . 5.3.1 HDR for Modeling . . . . . . . . . . . . . . . . . . . . . . . 5.3.2 Training process for the HDR based model . . . . . . . . . . 5.4 Results and Discussion . . . . . . . . . . . . . . . . . . . . . . . . . 6 Conclusions and Future Work 6.1 Conclusions . . . . . . . . . . . . . . . . . . . . . . . 6.2 Future Work . . . . . . . . . . . . . . . . . . . . . . . 6.2.1 Towards custom illuminants for proofing . . . 6.2.2 Embedding Intensity changes within the proof 6.2.3 Other Extensions and Practical Improvements vii

. . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . .

. . . . . . . . . . . . . . . .

. . . . .

. . . . .

. . . . .

. . . . .

. . . . .

. . . . .

. . . . .

. . . . .

. . . . .

. . . . .

. . . . .

. . . . .

97 . 97 . 99 . 99 . 100 . 100

Bibliography

102

viii

List of Figures
1.1 1.2 1.3 2.1 2.2 2.3 2.4 2.5 2.6 2.7 2.8 Soft proofing example . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Untouched scans of hard proofs from different SWOP certified printers . . . Viewing booth by GTI for soft proofing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . cor. . . . . . . . . . . . . . . 2 4 7 11 12 13 17 19 20 21 23 26 27 28 29 36 37 45

Closed-loop color control system. . . . . . . . . . . . . . . . . . . . . . Open-loop color control system. . . . . . . . . . . . . . . . . . . . . . . Three scanners from different brands used to measure the same patch . Measuring instrument i1 with automated table iO, together called i1iO LaCie 526 monitor . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Epson stylus photo 1400 inkjet RGB printer. . . . . . . . . . . . . . . . GretagMacbeth DC test chart . . . . . . . . . . . . . . . . . . . . . . . The algorithm for correcting the white point(left) and the algorithm for recting the chromatic colors(right) . . . . . . . . . . . . . . . . . . . . . 2.9 LCD technology based projector . . . . . . . . . . . . . . . . . . . . . . 2.10 DLP technology based projector . . . . . . . . . . . . . . . . . . . . . . 2.11 LCOS technology based projector . . . . . . . . . . . . . . . . . . . . . 2.12 Images taken of screen while the DLP projector is displaying full white 3.1 3.2 4.1 4.2

Test chart TC9.18. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Gamut of the ICC profile made and viewed in 3-dimensional CIELAB . . . . Color checker test chart. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Raw image of the color checker in the viewing booth taken in Capture One software and processed using custom ICC profile made for the camera. Camera settings were IS0=100, Sh=1/30sec and AP=4.0 . . . . . . . . . . . . . . . . Raw image of the color checker in the viewing booth taken in Capture One software and processed using the Generic ICC profile. Camera settings were IS0=100, Sh=1/30sec and AP=4.0 . . . . . . . . . . . . . . . . . . . . . . . Raw image of the color checker in the viewing booth taken in Capture One software and processed using custom ICC profile made for the camera. Camera settings were IS0=200, Sh=1/10sec and AP=4.0 . . . . . . . . . . . . . . . . HDR image of the color checker using sRGB. . . . . . . . . . . . . . . . . . . HDR image of the color checker using Adobe98. . . . . . . . . . . . . . . . . Test chart TC9.18 in the viewing booth. . . . . . . . . . . . . . . . . . . . . ix

47

4.3

47

4.4

4.5 4.6 4.7

48 50 50 51

4.8 4.9 4.10 4.11 4.12 4.13 4.14 4.15 4.16 5.1 5.2 5.3

The original test chart TC9.18 without borders. . . . . . . . . . . . . . . . . The original RGB of test chart TC9.18 shows 911 unique values. . . . . . . . The printed RGB of Test chart TC9.18. . . . . . . . . . . . . . . . . . . . . . The RGB values of the printed target with the predicted RGB by ANN. . . Original Lena image before printing (Left) and the predicted image of the printed version of it (Right). . . . . . . . . . . . . . . . . . . . . . . . . . . . Original color checker image before printing (Left) and the predicted image of the printed version of it (Right). . . . . . . . . . . . . . . . . . . . . . . . HDR image of the color checker using Adobe98. . . . . . . . . . . . . . . . . Gray scale image of the viewing booth . . . . . . . . . . . . . . . . . . . . . The luminosity of the viewing booth. . . . . . . . . . . . . . . . . . . . . . . The full setup of the system which includes: LCD projector, camera, and laptop. The general image acquisition pipeline in a camera . . . . . . . . . . . . . . 19 Differently exposed images starting from 10 second on the top left image(Overexposed) to the 1.3 second on the second row left image (Neutral exposure) and 1/6 second on the bottom right(Underexposed). . . . . . . . . The recovered CRC for the camera . . . . . . . . . . . . . . . . . . . . . . . The CRC for red, green, and blue plotted on the same axes. . . . . . . . . . The resulted ITF for RGB channels of the NEC VT670 3LCD projector. . . Checkerboard image sent to the projector. . . . . . . . . . . . . . . . . . . . Checkerboard image captured by the camera. . . . . . . . . . . . . . . . . . The registered captured image of the checkerboard image originally sent to the projector. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The luminance measured using HDR when the projector displays a full white image. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The gray scaled image when projector displays full white before making it uniform (Left) and after making it uniform (Right). . . . . . . . . . . . . . . The experimental setup of the hybrid system. . . . . . . . . . . . . . . . . . The image sent to the projector for registration (Left) and the captured image of the booth with checkerboard image (Right). . . . . . . . . . . . . . . . . . The white image sent to the projector (Left) and the captured image of the booth when ROI is white (Right). . . . . . . . . . . . . . . . . . . . . . . . . The RGB images sent to the projector to determine the LAM. . . . . . . . . The luminance channel of the viewing booth Measured by the camera before compensation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . The luminance of the viewing booth with projector displaying black (Left) and the LAM needed for the compensation (Right). . . . . . . . . . . . . . . The image sent to the projector to improve the uniformity of the viewing booth. Testing the uniformity performance of the hybrid system . . . . . . . . . . . The set up of the capturing the color test chart with the camera at 45 degrees looking at the viewing booth with the LCD projector to compensate for light.

52 54 54 55 56 57 58 58 59 63 64

5.4 5.5 5.6 5.7 5.8 5.9 5.10 5.11 5.12 5.13 5.14 5.15 5.16 5.17 5.18 5.19 5.20

65 65 66 67 68 69 69 70 72 74 75 75 76 79 80 81 83 85

x

5.21 5.22 5.23 5.24 5.25 5.26 5.27 5.28 5.29 5.30 5.31 5.32 6.1

The customized test chart. . . . . . . . . . . . . . . . . . . . . . . . . . . . . Images needed to generate HDR for the customized test chart . . . . . . . . The captured HDR image of the customized test chart after registration. . . The captured LDR image of the customized test chart after registration. . . The original RGB of test chart TC9.18. . . . . . . . . . . . . . . . . . . . . . The printed RGB of Test Chart TC9.18 (viewing booth only). . . . . . . . . The printed RGB of test chart TC9.18 (hybrid viewing booth). . . . . . . . . The correlation measure of target vs. predicted by the ANN for training, validation, testing, and all data set. . . . . . . . . . . . . . . . . . . . . . . . The printed RGB of test chart predicted by the ANN. . . . . . . . . . . . . . The printed RGB of Test Chart TC9.18 (measured by i1iO) . . . . . . . . . The original digital Lena image (top) and the prediction of the printed version of the Lena image by the ANN model (bottom). . . . . . . . . . . . . . . . . The original digital colorchecker image (top) and the prediction of the printed version of the colorchecker image by the ANN model(bottom). . . . . . . . .

85 86 88 88 89 90 90 91 92 92 94 95

The example of projector based evenly illuminated viewing booths from right to left are bluish, reddish, and yellowish lights. . . . . . . . . . . . . . . . . . 100

xi

List of Tables
3.1 3.2 5.1 5.2 5.3 5.4 Experiment to confirm that an ICC profile used within MATLAB or Photoshop produces equivalent results. . . . . . . . . . . . . . . . . . . . . . . . . 40 Sample data points were processed via an ICC profile and also by ANN Model 41 The results of making white uniform using green channel and a full white. . The results of making a white image in the booth uniform using green channel, RGB channels, and full white. . . . . . . . . . . . . . . . . . . . . . . . . . . The results of making white in the booth uniform in RGB camera space. . . The results of using the projector to enhance the viewing booth. . . . . . . . 72 77 78 81

xii

List of Abbreviations
Abbreviation ANN CIELAB or L*a*b* CMM CMS CMYK CRC CRT DLP GRNN HDR ICC ITF LAM LCD LCOS LDR LM LUT MSE PCS RBP ROI TRC Description Artificial Neural Network Lab color space Color Management Module Color Management System Cyan Magenta Yellow Black inks used for printing Camera Response Curve Cathode Ray Tube Digital Light Processing Generalized Regression Neural Network High Dynamic Range International Color Consortium Intensity Transfer Function Luminance Attenuation Map Liquid Crystal Display Liquid Crystal On Silicon Low Dynamic Range Levenberg-Marquardt algorithm for training ANN LookUp Table Mean Squared Error Profile Connection Space Resilient Back Propagation Region Of Interest Tone Reproduction Curve

xiii

Chapter 1 Introduction

S

OFT proofing is a viewing tool where the user has the ability to view how an image printed by the press will physically look based on a prediction formulated on a well

calibrated monitor. A more general definition is that a proof should simulate the appearance of the final print before the actual print job goes to press. An example of a typical soft proofing system is shown in Fig. 1.1. In this thesis, techniques are developed to enhance and simplify the process of achieving a soft proof prediction of a hard proof generated off the printing press. The techniques move away from traditional offline International Color Consortium (ICC) profile construction and physical modeling. High Dynamic Range (HDR) acquired images that more naturally reflect the visual sense as perceived by the human observer are incorporated into a closed loop acquisitioning and modeling process that compensates for non-uniformity in illumination, improve color prediction and shows potential new directions in soft proofing applications.

1.1

Motivation

Proofing is a simulation of the printing press. In general, a proof is needed in order to establish the quality of color reproduction realizable on any given substrate by an individual press. Press operators then rely on these proofs in order to make fine tuned adjustments to ink combinations in order to achieve a desired output. Proofs are also essential for communicating with the customer in order to have some agreement on the quality of the 1

2

Figure 1.1: Soft proofing example shows hard copy print (right) and the predicted printed version on the monitor (left).

reproduction for a given job. There are mainly two kinds of proofing, hard copy proofing which has been known for quite a long time and the more recent soft proofing technology. It goes without saying that the hard copy proof of the press is very important in saving time and cost since it is possible to simulate the printing press prior to the start of the actual printing process. In other words, it is important to check the quality of the final printed image (product) before printing, since the printing process is expensive to set up and time-consuming because it takes time to place inks, papers, and get the press to provide the desired output [1]. Consequently, proofing is an essential process because it offers the full power to control the prepress work and offers the opportunity to ensure that the job will be performed as desired. Hard copy proofing is typically done by a proofer (most likely a digital inkjet printer) that simulates the press and has the ability to reproduce all the colors of the press [2]. There are many shortcomings with hard copy proofing systems. For instance, they may not deliver consistency from one proof to another, they may involve tedious, trial by error corrections and adjustments, may incur much waste in material and, most importantly, there is no automated method of tracking revisions and checking who has looked at the proofs and when. More shortcomings are listed in [3]. These shortcomings were considered as disadvantages for this type of proofing system.

3 Moreover, industry experts have noticed differences between proofs generated from different vendors. For that reason, in 2007, a survey was conducted to evaluate the confidence of hard proofs. 14 Canadian companies produced hard proof with each proof purported to be SWOP
1

certified. The resulting hard proofs were shown to have dramatic differences

between them as it can be seen from the uncorrected scanned proofs in Fig. 1.2. Although all proofs were SWOP certified and were produced from the same PDF file [3], appearance in skin tones and highlights are far from consistent. These hard copy proofs are usually viewed under standard lighting conditions such as D50 using a specially designed viewing booth with variable intensity. Since the proof is a representation of how the final printed job is intended to look, the proof is the reference that the press operators strive to match [4, 2]. The usefulness of hard-copy proofing technology has been known for a long time. However, hard copy proofing systems need expensive equipment as well as the cost of paper and ink involved. In addition, hard-copy proofing is associated with a high cost of courier services needed to distribute the proof to all parties involved in the graphic arts workflow. Such parties include publishers, advertisers, agencies, editors, artists, and the printers, and all need to discuss the content of the proof and evaluate from remote locations which may not provide efficient viewing environments. Therefore, in today's technology, many printing companies along with their customers have decided to exchange/view proofs electronically using calibrated computer displays. This has led to the use of the newly developed soft proofing technology: sometimes called remote or virtual proofing [1] Soft proofing is a new method of visualizing how the printed image will look before printing, using a calibrated monitor. This method saves a lot of time and money compared to hard copy proofing. Also, changes to color/content can be made easily without reprinting the proof again. In order for this method to work, a good viewing conditions such as standard lighting and surrounding [4] are required as described in ISO 12646 2 . This ISO
Specifications for Web Offset Publications which help to reduce tolerances via its specifications for graphic arts 2 Graphic technology Displays for color proofing - Characteristics and viewing conditions
1

4

Figure 1.2: Untouched scans of hard proofs from different SWOP certified printers [3].

5 was developed in order to give recommendations regarding the viewing conditions and help the user achieve an accurate and reliable match between soft proofs and hard copy printed images. Soft proofing also allows different people to compare the same color at different monitors when viewed in standard viewing conditions unlike the hard copy proofs [2]. In addition, soft proofing in Photoshop enables the user to view the soft proof with different printers and paper type such as newspaper vs. glossy paper to choose the options that give the desired output.

1.2

Problem Statement and Thesis Contributions

This thesis aims to enhance soft proofing technology and find solutions for issues with new soft proofing systems that the industry strives for. Despite the advancements in soft proofing technology, it still lacks many aspects such as automation and accuracy. Therefore, the objective of this thesis is to propose new methods that can potentially simplify and create more accurate prediction models that can help to make soft proofing technology more widely acceptable. Specifically, this thesis focuses on creating a black box model that can simulate the appearance of the printed hard copy image of a given digital image on the monitor. The model demonstrates robustness by first creating a uniform lighting condition in the viewing booth using an inexpensive camera and a Liquid Crystal Display (LCD) projector. The proposed method is also computationally efficient. This thesis addresses some problems in the current soft proofing technology and some current issues in the printing industry. The main contributions achieved in this thesis are summarized as follows:  Problem 1: Color space transformation is usually done using a well established color management implementation which exists in the form of ICC
3

profiles. In ICC-based

systems, device characterization information is stored in single and multi-dimensional LookUp Table (LUT) within profile files, such that an input profile provides a mapping
3

http://www.color.org

6 between input RGB and CIELAB, and an output profile provides a mapping between CIELAB and output RGB/CMYK values. Thus, the accuracy of color transformation from the input image to the displayed image and then to the printed image depends in part on the quality of the characterization. Contribution: The proposed method in this thesis employs an Artificial Neural Network (ANN) model based on Levenberg-Marquardt (LM) back propagation training algorithm to implement a color transformation between two color spaces (eg.RGB to CIELAB). This method was compared with a standard ICC profile and the results with the developed algorithm were extremely accurate.  Problem 2: To be able to match two colors and/or judge if two colors have the same appearance, the illumination applied to both colors should be the same because slight changes in illumination result in changes in the perceived color. This can include changes in luminance level (dark to bright) as well as the changes in the chrominance of the illumination. Luminance changes are very common in everyday life: for instance, a bright sunny day versus a dark overcast day where objects tend to appear very bright and colorful on sunny day and somewhat subdued on an overcast day [5]. For example, if someone wants to compare two images, the two images have to be viewed in identical viewing conditions where light intensity is the same across the viewing field. In other words, the light should be as uniform as possible at least on the viewed image. Therefore, it is important to control the intensity and its uniformity because changing the intensity of the light changes the perceived color. For that reason, when generating a soft proof, the user often needs to fine tune the intensity in the viewing booth until a good subjective match occurs between the monitor and the booth. One flaw however is that these expensive viewing booths do not provide uniform lighting conditions as it can be seen from Fig 1.3. Achieving a workable environment in which to view soft proofs is therefore currently not automated, and consistent results within the viewing booth are rarely possible without manual tweaking. Even in the case of hard proofing, there is a need for uniform lighting conditions in the viewing booth so

7

Figure 1.3: Viewing booth by GTI for soft proofing4 .

that all colors of the image are perceived in the same manner. Contribution: Automatic and accurate estimation of the scene's illumination from digital images is still an undetermined problem [6]. Moreover, research for improving Color Management Systems (CMSs) continues in many fields within the printed media industry [7]. As there are still many issues to resolve, especially with illumination, a primary goal in this thesis was to establish a system for achieving uniform lighting in the viewing booth that can be used to illuminate the printed image in a uniform manner both for viewing and modeling purposes. The novel approach of using an LCD projector is introduced to create an ideal viewing condition for this purpose. Projector uniformity was investigated and compensated using spatial information from a white image that the projector displays. This was found to provide better results than depending on the green channel used projection blending applications [8, 9]. Furthermore, existing viewing booths do not provide the flexibility of viewing the image under illumination with different colors and levels. Therefore, the projector was used to create a wide range of different colors of uniform illuminations with varying intensities. The LCD projector was also used to compensate the non-uniform lighting in the viewing booth.
4

GTI Graphic Technology, Inc is a leading manufacture in viewing booth systems,http://www.gtilite.com

8 This led to a uniform illumination inside the viewing booth and represents work that has not been done before for this type of application. The utility of the proposed method is that it enables equally illuminated areas for accurate color investigation, a step that is crucial to the future of soft proofing systems.  Problem 3: Creating a successful soft proof requires a viewing booth with variable intensity levels so that it can be varied to achieve the same appearance on the monitor. Some off-the-shelf products like Photoshop perform a very basic soft proofing in that limited modeling of a standard substrate combined with measurements collected using dedicated measuring apparatus is performed. However, these approaches are rarely correct. The user has to manipulate settings in Photoshop while changing the intensity of the light source in the viewing booth until a subjectively close match is achieved against a calibrated monitor. This process is extremely tedious. Moreover, it is not an automated method and does not provide consistent results from time to time. Plus, different people adjust the proof differently. An automated method is needed to get more repeatable results. The current models of soft proofing systems depend greatly on ICC profile modeling which is based on LUT's built from hard colorimetric measurements. This introduces some discontinuities in colors and other interpolation errors. Moreover, current soft proofing systems do not take into consideration varying intensities of illumination. Contribution: In this thesis, an adaptive mechanism for controlling the illumination is combined with a closed loop technique and the use of HDR to capture the true reproducible color gamut of the printed image in the viewing booth. This was used to generate a black box model that can simulate the hard proof of an arbitrary given digital image. Adaptive techniques such as ANN were used to create the black box model, using the camera as a measuring device.

1.3

Organization of the Thesis

9

The rest of the thesis is organized as follows. Chapter 2 discusses relevant literature pertaining to importance of color management and ICC profiles, calibrating digital imaging devices, soft proofing techniques and overview about projectors as potential light source. Modeling the color transformations via ANN versus the current methods that were implemented and tested are explained in Chapter 3. Chapter 4 discusses the importance of using HDR to create an accurate and reliable color reproduction of the printed image on the monitor along with some experimental results. In Chapter 4, ANN was used to create a model but it was found that the viewing booth is not uniform. Therefore, in Chapter 5 a new method is proposed to compensate the viewing booth lighting to create a uniform hybrid viewing booth to capture images and be able to create an accurate model. Finally, in Chapter 6, a conclusion of this thesis was made including the contributions and the importance of this work as well as some suggestions for future work.

Chapter 2 Background Theory and Related Work

T
2.1

HIS chapter explores some of the background theory behind the digital imaging workflow, the establishment of CMSs and their importance in soft proofing, and explains

the use of projector as a potential light source.

The Importance of Color Management

Color management techniques are very important in controlling the image workflow so as to ensure a best match between the original image design and the reproduction copy. Indeed, the image workflow is typically controlled by managing color transformations between different imaging devices. In this way, the range of colors available in the original image will be kept visually matched as much as possible throughout the digital imaging workflow [2].

2.1.1

Color Workflow Control

There are two ways of controlling colors in color management workflow, the closed-loop color control which is considered as the old way of controlling color control workflow and the new well known way which is open-loop color control. Both methods are explained below:

10

11

Figure 2.1: Closed-loop color control system.

Closed-Loop Color Control In this kind of color control system, all imaging devices in the control loop have to be manufactured by the same vendor. This means scanners, printers, software, and monitors all are installed and sold by the same vendor [2]. An example of such a system is shown in Fig. 2.1 which shows that every imaging device in the system is connected to all other devices through T which refers to device-device color transformation which will make this scheme very complex. This kind of color control system is sometimes called device dependent color transformation because unique color transformation happens between every pair of devices in the system. The process involves the direct conversion from one device color space to another device color space.This kind was in use in 1970's and 1980's and has many disadvantages in terms of its complexity. For instance, suppose having N devices in the color management workflow, this will require N2 device-device color transformations to characterize all possible interconnections. Adding a new device to the existing workflow will require N new color transformations. Open-Loop Color Control In this kind of color control system, all the imaging devices are connected to a one station which is called the "central connecting space". Any device communicating with another device should first be connected into the central connecting space. This principle is analogous to that used in airports. For example, if someone needs to travel from one place to another,

12

Figure 2.2: Open-loop color control system.

it is not always a direct fight and passing through a transit station is a must. In other words, there are no direct connections between all airports in this world [2]. An example of this system is shown in Fig. 2.2 in which T for each device refers to the transformation from device color space to standard color space or vice versa. Comparing to the closed loop system, this system is much better in terms of complexity. Therefore, this kind of color control system is sometimes called device independent color transformation because every color transformation has to happen through to some standard color space. Device independent color spaces such as XYZ or L*a*b* serve this purpose. For instance, you can add devices very easily and adding one device will require only one color transformation compared with N color transformations in the closed loop system. For N devices, it requires only N color transformations compared with N2 color transformations. The advantages of using this type of system are increased flexibility in adding and removing imaging devices from different brands and the whole system does not have to be supplied and installed by any vendor [2, 10], rather they provide only a transformation to the device independent space.

2.2

ICC Color Management

As mentioned previously, color management techniques are important in perceiving accuracy and quality from scanning, manipulating, and printing the image. Consider the situation when we have a hardcopy image, scan the image, and then print it out via any desktop color printer. By comparing the original hardcopy image with the printed one, are they an exact

13

Figure 2.3: Three scanners from different brands used to measure the same patch [2].

match? The answer is no even if they look similar because if the colors in both images are measured by colorimeter, they will have some deviation in the measured values. For that reason, color management techniques are important to convert the color from one space to another. To be specific, each device has its own characteristics even the same device from different manufacture has different behavior. Consider the situation in Fig 2.3, the same red patch was scanned by three different scanners: HP scanner, Heidelberg scanner, and UMAX scanner. The resulting RGB values of the three scanners are quite different and will cause a big problem during the communication between different imaging devices. For instance, sending these RGB values to a printer will result in three printed patches that have variations in their red which will not match the original red patch as well. Moreover, different printers have different characteristics [2, 11]. Furthermore, every imaging device has it own characteristic which means the response of the device to the color is different from device to device. In fact, even the response of the

14 same device is expected to change over time. It is very clear from the previous example that RGB color space is a device dependent color space. Therefore, a mechanism that can convert this RGB device dependent color space to a device independent color space such as XYZ or L*a*b* is used so that when converting RGB values of each scanner to L*a*b, the results should be the same. This step is done by using the device ICC profile that will convert RGB to L*a*b*. This will be revisited in more detail of device dependent color in the next section. Currently, solutions for this problem is provided by the CMS which is responsible for the color transformations between imaging devices in the workflow by handling conversions from device dependent to device independent color space and vice versa using ICC profiles [12].

2.2.1

ICC Profiles

History of ICC Profiles In 1993, the ICC was formed by the eight biggest companies in printing and imaging industry in order to build the standardization of the new CMS. This organization creates new protocols for color management techniques which helped software vendors, equipment manufactures, and equipment users to communicate very easily with one another while ensuring as much as possible color information could remain perceptually unaltered across various stages of the workflow. This framework was called ICC-color management. This led to the creation of ICC profiles which are used to convert color from the device color space to the Profile Connection Space (PCS) and vice versa. This made transferring images very easy. The idea being that by embedding the ICC profile within the image no matter what the operation system was, the image appearance would not undergo any appreciable change. Similarly, having an ICC profile for one printer means that this printer could be used on any computer with any operation system, and accurate color reproduction could be achieved [13, 2]. This made for incredible flexibility in color management for users and vendors.

15 Details of ICC Profiles ICC profiles have all the necessary data for a specific device such as a scanner, printer, or monitor. This file contains more detailed information about the color transformation between the device color space (RGB in the case of a scanner or monitor and CMYK for printers) and the PCS which is usually a L*a*b* or XYZ color space. This information is stored in LUTs in order to create the Color Management Module (CMM) that is used to convert color data from one space to another. It also has more information than the tables for color conversion such as the type of the profile (output or input profile), reference white point, and the time when the profile was created [14]. The file size of a profile could vary from 4K to 4MB or may be bigger and their extension is either .icc or .icm. They can be found for example in the windows operating system. Moreover, there are some programs that are used to examine a profile. These programs are called ICC Profile Inspectors in which viewing the content of an ICC profile is possible. By using these programs to look inside the profile, it is very easy to see the header and the tags of the profile. The header has the information about the manufacture and the type of the device, while the tags have all the important data and information for color conversion. There are two kinds of profiles, output profiles that convert from PCS to device color space and input profiles that convert from device color space to PCS. However, nowadays, most of the profiles are bidirectional [2, 14].

2.2.2

How to Obtain an ICC Profile

The importance of ICC profiles in color management was addressed in section 2.2. Now the question is how can these ICC profiles be obtained for each imaging device? The more accurate way that is used in imaging and printing industry is to obtain custom ICC profiles through exhaustive measurements. Before explaining how to obtain a custom ICC profile using profile making software, different ways of how to get ICC profiles are first outlined:  Generic profile: This is a simple method in which the provided ICC profile by the manufacture will be used [2]. For example, every computer has its own ICC monitor

16 profile that is supplied by the vendor. However, it is recommended to make your own profile because the monitor efficiency will likely change over time.  Process profile: It is possible to consider the device you have to be operating according to some conditions by using known standard ICC profiles such as sRGB, but this is not recommended due to the lack of knowledge of individual device specifications [2, 15].  Custom profile: This method can be done by the user in order to make an ICC profile for each device. The requirements are measuring instruments, a color test chart and profiling making software. This is one of the best ways to obtain an accurate ICC profile [2]. To be able to have accurate color management workflow, custom profiles have to be used in order to ensure all the factors are taken into consideration when the profile was made. Therefore, the created custom profile is valid only if the same conditions can be reproduced as those used at the time when the profile was made. These conditions could be the type of paper, inks, room temperature, and humidity. For instance, if an ICC profile was made for a printer by using Matte paper, then this profile is valid only for this kind of paper. If different kind of paper was used such as glossy or semi-gloss, then that profile is not valid and a new profile has to be made for the new paper used in printing in order to accurate and faithful modeling of the printer and how inks respond to the new type of paper [16]. In order to make a custom profile for any imaging device such as monitor, scanner or a printer, three essential things are needed which are described in the following points:  Measuring Instrument: There are different instruments used to measure color patches of a printout and on the monitor such as X-Rite530, Eye One Pro (i1 Pro), or i1iO from X-Rite 1 . These instruments mainly use light source converted to D50 applied to a small patch of color and measure the reflectance properties of the patch. From this, L*a*b* values can be computed by using standard observer color matching
1

http://www.xrite.com; X-Rite is the global leader in color science and technology.

17

Figure 2.4: Measuring instrument i1 with automated table iO, together called i1iO2

functions [2, 11]. These instruments are expensive and can range anywhere between $USD 1000 up to $USD 10,000. In this thesis work, i1iO was used which comprises of one i1 Pro that is mounted in a robotics arm on an automated Scanning Table for fast and accurate measurements. i1iO is shown in Fig. 2.4.  Test Chart: It is a chart that contains a wide range of colors that are uniformly distributed in equally spaced patches. Each imaging device has a specific test that is used to measure its response. Measuring these test charts will give a device response which can be used to create an ICC profile. [17, 2].  Profile Making Software: This software will build required ICC profiles based on the measurement of the test chart. There are several software packages from different vendors such as ProfileMaker Pro 5.0.8 or EyeOne Match3 [18]. Each have some differences in the quality of the ICC profiles generated. The quality of the ICC profiles will depend on the chosen test chart plus the measuring instrument [18, 2]. Lastly, to make a printer profile, one test chart has to be chosen from many available standard test charts. A test chart is a chart that has many patches of different colors. This test chart has known CMYK values for each patch. By printing this test chart and measuring the
2

http://www.crispdigital.co.uk/products/xrite/i1io.html

18 device independent color space such as L*a*b* with the i1iO, an ICC profile can be made by using the known values of CMYK and its corresponding measured values of L*a*b* in the profile maker software. The profile maker software uses CMYK and L*a*b* data to construct the LUT [19].

2.3

Calibration of Imaging Devices

Device calibration means bringing the device to a known characteristic color response for which the relationship between device-dependent color space and device-independent will be recorded in a custom ICC profile. This is done for every device in the digital imaging chain to maintain an accurate color transformation throughout the digital workflow.

2.3.1

Calibrating a Monitor

The monitor is a very important device in the imaging chain since it lets us view the digital image and make adjustments of the colors before the printing process begins. If the monitor does not provide accurate colors then what we see is not reliable. One important use of an accurately profiled (calibrated) monitor is the soft proofing in which the screen is used to view the printed image before actually printing it. This process save lots of time and cost. Profiling a monitor means creating a custom ICC profile for the monitor [2]. To profile a monitor, a profile maker software and measuring instrument are needed in order to measure the colors and create an ICC profile. The monitor used in this thesis was LaCie 526
3

which

comes with special software together with measuring instrument called Blue eye pro as shown in 2.5. Once the monitor is calibrated that means the new ICC is built and automatically made as the default monitor ICC profile. In other words, this ICC profile contains new Tone Reproducion Curves (TRC) for the monitor stored as a look up table.
3

http://www.lacie.com/ca/index.htm

19

Figure 2.5: LaCie 526 monitor with blue eye measuring instrument during calibration process.

2.3.2

Calibrating a Printer

Calibrating a printer is important step in order to know the response of the printer. Printers mainly include three categories: desktop printer, proofers, and printing press. Creating an ICC profile for almost every printer is the same, and requires printing a test chart, measuring the printed test chart, and feeding the measured values to the profile making software to create the custom ICC profile [20]. The printer used in this thesis is an Epson stylus photo 1400 inkjet RGB printer shown in Fig. 2.6. In this case, creating an ICC profile for this printer means building the relationship between RGB values sent to the printer and the resulting L*a*b* values when measured. The chosen test chart is TC9.18 shown in Fig. 3.1. This test chart contains values of RGB from (0,0,0) to (255,255,255) uniformly sampled so that it can accurately measure the printer response. It is very important to print the test chart without any color management because the goal is to record the natural printer behavior, and then compensate accordingly. After printing the test chart with the known RGB values, this chart has to be measured in order to obtain the resulting (device independent) L*a*b* values [21]. In order to reduce the error introduced by the measuring instrument, it is recommended to measure the printed chart a few times and take the average. In this case, the chart was

20

Figure 2.6: Epson stylus photo 1400 inkjet RGB printer.

measured three times and averaged to get accurate L*a*b* values. By now, RGB values verses L*a*b* values are known which will be used by the profile maker software to create the ICC profile [2].

2.3.3

Calibrating a the Camera

High quality cameras are available almost everywhere today at low cost, allowing cameras to play an important role in the digital imaging workflow. It is becoming very important to have a truthful control of camera colors by having an accurate ICC profile. This ensures colors are accurately represented in the source image to be later used in the workflow [22]. There are different test charts designed for camera calibration. It is often necessary to consider which test chart is most appropriate for a given camera. For instance, the IT8 chart may not be the best choice to profile the camera if the intended purpose to use the camera to take pictures of everyday objects [17]. The test chart has known L*a*b* values that will be captured to generate RGB values by the camera which will used to generate mapping between RGB and L*a*b* to create the ICC profile. Therefore, the most important thing in calibrating a camera is to consider the lighting conditions during the process of creating a custom ICC profile. Perfect conditions relate to an environment in which there is no change in the illumination during the capture process of the test chart [11]. There are also white,

21

Figure 2.7: GretagMacbeth DC test chart for camera calibration4 .

gray, and black patches around the test chart and in the center as shown in Fig. 2.7 used to determine the uniformity of the illumination. Furthermore, digital cameras produce images in two ways:  Processed: This is what most consumer digital cameras are capable of doing in which the captured image is processed by the internal software in order to produce pleasing results. The camera will also assigns a standard ICC profile such sRGB to the image to be displayed in order to produce meaningful results.  Unprocessed: This is the exact data from the sensor without being modified by the camera software (ie. the raw image). In this case, a custom ICC profile has to be made in order to apply it to the image to produce meaningful results. This option is not available in every camera. Professional photographers often use this option to get the best out of their cameras.

2.4

Soft Proofing Systems

Soft proofing is used to verify the print jobs on the monitor. Despite the successful development and use of the current soft proofing systems, they often still fail to deliver a result that can compare to hard copy proofing. This is primarily due to changes in appearance
4

http://www.dpnow.com/695d.html

22 due to different illumination intensities and levels [23]. In work published in [24], visual experiments were done to simplify the across-media color appearance reproduction between a Cathode Ray Tube (CRT) display of a soft copy and a hard copy NCS color atlas in a D50 viewing booth. Psychophysical experiments by nine observers were carried out in order to visually match the soft copy with hard copy. Each observer was asked to match the two samples in different viewing condition at the same time by using a black splitting board between the display and the viewing booth. Each observer then used the left eye to view the hard copy while using his/her right eye to view the samples on the display. The soft copy color patches were made in Photoshop, and the nine observers were asked to adjust RGB sliders until it matched to hard copy NCS chips. In total 488 samples were used by nine observers for two runs which led to a total of 8784 samples. 8460 used to training and 324 used for testing. The total samples were divided into four parts: each being trained with back propagation neural network to get a good generalization. The main concept of this study was to model hard copy samples on a CRT display by observers. Therefore, this method depends on the human to match colors and there is no automation in the process. The main objective of the soft proofing system is to be able to reproduce printed color images on the display faithfully in order that displayed color images are visually matched (perceptually) to the same image on the printed media. A recent patent "Correction techniques for soft proofing" explained in [25], outlines new techniques to enhance current soft proofing techniques. Referring to the white point correction algorithm as in Fig. 2.8, a white point correction is implemented by placing a white surface (paper) in a viewing booth with a D50 light source. Then, a white patch is created using Photoshop on the display that has same L*a*b* as the white paper. Then, this white patch does not match the white in the booth so the user has to visually adjust it until an acceptable visual match occurs between the white display and white paper in the viewing booth. After visually documenting the white point, the RGB on the display has to be visually adjusted to a achieve a good match between the display and the hard copy in viewing booth with D50 light source. This process can be done incrementally for RGB until an acceptable

23

Figure 2.8: The algorithm for correcting the white point(left) and the algorithm for correcting the chromatic colors(right) [25].

24 visual match is achieved. This process is shown in the algorithm shown in Fig. 2.8. It is argued that these corrections can be applied to any digital image to obtain a soft proof. For more details about this work refer to the patent in [25]. The problem in practice is that the viewing booth is not uniform which makes the white paper look different in the booth. Moreover, the booth has different intensities at different locations which affects the white point as well as RGB colors. This method also depends on the human to adjust colors; therefore, is not automated and we believe, will not deliver consistency in the color reproduction. In addition to these approaches, there are some available proprietary soft proofing tools such as those built into Photoshop [2], however, soft proofing lacks the feeling/appearance of an actual printed image. Moreover, a tool to predict what the image will look like under different lighting conditions with different intensities is a very important step for soft proofing [26]. An LCD projector is considered in this thesis in order to create a uniform light in a viewing booth as well as for possible use in simulating different controlled illuminations. In the next section, a brief overview is given about projector technologies they might be used as a potential light source.

2.5

Projection System as a Potential Illuminant

Color consistency depends heavily on the illumination under which the product is viewed. This includes changes in luminance level (brightest to darkest) or changes in chrominance [5]. Achieving consistent lighting booth (uniformly lit viewing booth) is strongly recommended in order to provide robust evaluation when colors are viewed. As such, Projector-based Illumination Techniques are investigated in this thesis as a possible solution. Digital media projectors can be classified as large digital displays which provide high resolution images. Conversely, projectors have been used as two-dimensional display devices just like CRT monitors or LCD panels, more typical within larger scale versions of monitors. Projectors, with the aid of a camera can be used for more powerful and valuable applications such as 3-Dimensional (3D) scanning and modeling [27]. While such tasks involve the inter-

25 pretation of depth and structure based on illumination variations, it is also true that any surface or object can change its appearance by controlling the illumination [28]. Accurate control of the surface's illumination can be accomplished using the current projection display technology which will allow for pixelwise control of the color of the surface. Consequently, digital media projectors were considered to provide a uniform light by controlling the pixels of the projector as measured through a camera.

2.5.1

Overview on Projectors

Media Projectors are widely used as big screens to display vibrant presentations slides and movies for large groups of people with fast moving images that has brilliant colors for entertainment as well as for education purposes and conferences. Recently, the size and the cost of the digital media projectors have been decreasing rapidly which allow their use in many valuable applications. Projection display technology has significantly grown and highly developed in the past few years and became very dominant in displaying images with high spatial resolution and dynamic range. These developments in the projection display technology made significant impact in today's complex display systems [28]. Projectors have been used in many applications but not in the printing industry.

2.5.2

Types of Projector Display Technology

Digital media projectors can be classified according to the technology they use internally. The two primary types are: LCD and Digital Light Processing (DLP) projectors. Liquid Crystal Display (LCD) Projectors When the LCD technology is used in projectors, it is called 3 LCD because the main source of light source is an ultra bright lamp that emits a white light which is split into three beams of red, green, and blue using multiple dichroic mirrors. These mirrors transmit and reflect specific wavelength generating a narrow band spectrum with peaks at red, green, and blue as shown in Fig. 2.9. Each band is then passed to individual LCD panels (three in total) which contain numerous liquid crystals through which the light will travel. The light will

26

Figure 2.9: LCD technology based projector5

be modulated by these crystals according to the required intensity for each pixel. The light from each LCD panel is combined by a prism and reflected towards the lens in order to focus the image. The details are shown in Fig. 2.9. Since the light is being passed through an LCD, it is considered a "transmissive" technology [29, 11]. Digital Light Processing (DLP) Projectors This technology is based on Digital Micromirror Device (DMD) which is hundreds of thousands of tiny mirrors to reflect light [30]. These microscopic mirrors are controlled individually and can tilt 10 degrees in order to change the direction of the light. The other difference is that the red, green, and blue light is generated using a color wheel that spins fast to allow the right color to be passed to the DMD at the right time, where it is reflected onto the screen through the lens (Fig. 2.10). Therefore, it is a "reflective" technology. Images can be generated by titling the mirrors away or toward the light source in a very fast manner. The resulting intensity depends on the frequency of turning the mirror on and off. For instance, when the mirror is turned on more than off, it produce higher intensity and vice versa. When a desired color is needed at specific pixel, then the responsible mir5

www.trueprojection.com/LCDproj.php

27

Figure 2.10: DLP technology based projector6 .

rors will only reflect a specific combination of RGB to get the request color in a very fast manner [31, 29, 11]. Liquid Crystal on Silicon (LCoS) Projectors LCOS technology is related to the LCD technology. It uses reflective LCOS modulators instead of the transmissive LCD panels. LCOS is an LCD light modulator but fabricated on silicon. The modulation of the light is achieved using the liquid crystals which are sandwiched between a glass layer and a silicon layer, as opposed to the two glass layers used in an LCD panel. The silicon layer is coated with a reflective metal which acts like a mirror. These liquid crystals turns on and off using an electronic control circuit embedded into the silicon layer. This technology allows closer liquid crystals which allows higher resolution at the final projected image. Some of these projectors use one chip with sequentially flashed color of red, green, and blue instead of using color wheel. But higher end projectors uses three panels of LCOS and dichroic mirrors to generate red, green, and blue in a same way as in the LCD projectors. [29, 11].
6 7

http://www.pctechguide.com/projectors/dlp-projectors http://electronics.howstuffworks.com/lcos2.htm

28

Figure 2.11: LCOS technology based projector7 .

2.5.3

Choice of Projector Technology for Compensating the Viewing Booth

Section 2.5.2 briefly discussed the types of projector display technology. One of most important advantage of LCOS is the minimum spaced pixels which provide a smoother image and higher resolution. The other thing is that 3LCD and three chip LCOS provide red, green, and blue colors simultaneously unlike the DLP which provide colors sequentially, one color at time, in high speed using the color wheel. DLP projectors tend to provide rainbow artifacts (visible color separation artifacts) because of the color wheel. For instance, taking an image of the display using a camera requires synchronization between the camera and the projector in terms of sampling. For that reason, the exposure time of the camera should be synchronized with the projector. For example, if the projector color wheel is operating at 60 Hz, then the camera should use an exposure of (1/60) seconds in order to capture an accurate image without rainbow artifacts. One issue is that taking images with different exposure values will result in incorrect images as it can be seen in Fig. 2.12 in which three images of a full displayed white image were taken using a DLP projector. Images were captured using the same Canon camera with an exposure value

29

Figure 2.12: Images taken of screen while the DLP projector is displaying full white image with camera settings: ISO=100, Apreture=5.6, and Shutter Speed=1/200

of (1/200) second, ISO of 100, and aperture set to 5.6. For that reason, using HDR techniques are not possible with DLP projectors because of the color wheel plus it does not provide a good lighting source as the colors are sequentially displayed one after another which is not how a normal lighting source behaves [32]. It was also noticeable that taking images with different exposures other than (1/60) seconds will result in different colors at different times because it depends on the color wheel. Since, the goal is to use HDR imaging techniques for creating an even illumination using the projector, it is not possible to use a DLP projector. In addition, the DLP projector has obvious artifacts that result in shades of red, green, and blue on the screen when a white color is displayed; therefore, it cannot be used as a good light source to compensate the viewing booth. On the other hand, since neither LCD projectors nor LCOS projectors have a color wheel, the rainbow artifacts are not present and are ideal light source to be used for the work done in this thesis. A research review was done in [33], it was concluded that the largest E calculated based on Eq 3.1 were 10.17 and 21.71 for LCD and DLP respectively. Therefore, LCD projectors are better in providing superior results by better color uniformity. Therefore, an LCD projector based lighting system is used in this thesis as a stable light source to compensate and thereby create a uniform illumination on the paper displayed in the viewing booth. One more thing to mention is that linearizing the camera requires a series of different exposure images in order to calculate the Camera Response Curve (CRC). In this case, when an LCD projector is used, it is possible to calculate the CRC based on the LCD projector with all other light in the room turned off which provides more stable and reasonable results

30 in terms of luminous measurements acquired using HDR techniques. Once the camera is linearized using this condition, it should give slightly better results when it is used to measure luminosity under similarly lit environments.

2.5.4

Color Variations in a Projector

There are mainly two kinds of color non-uniformity in the projector display technology:  Intra-Projector Variation: Color variation of the displayed image by one projector, a condition more noticeable with flat images than with complicated images [9]. It has been shown that the variation in luminosity is greater than the chrominance which is almost spatially constant within a single projector due to the lens [34]. Moreover, in some projectors, luminance can differ anywhere from 40% to 80% from the center to the edge of the displayed image [35, 36].  Inter-Projector Variation: Color variation of the displayed image from one projector compared to another projector. Also, it can be thought of as the color variation between different projectors within the same manufacture and same projector model. There is some variation in the luminosity and chrominance; however, luminosity radically varies across different projectors even within same model and technology type [35, 9]. The Human Visual System (HVS) is more sensitive to change in luminance than chrominance [11, 37, 38, 39]. The reason behind this is that the number of the rods (cells sensitive to light and dark) in the human eye outnumber the cones (cells sensitive to more specific color wavelength). They are also more sensitive than the cones which makes the human eye much more sensitive to luminance than to chrominance. This fact has been used as an advantage in designing the analog color television standards plus in digital image compression algorithms such as JPEG [40]. Luminance uniformity of the image displayed by a projector must be made as uniform as possible to deliver a good quality image especially for creating a viewing booth with even and uniform lighting conditions. In a tiled display which consist

31 of a set of projectors with the same model from the same manufacture, spatial variation in luminosity is very noticeable and has been addressed to create more seamless projector outputs for overlap when merging tiled displays [37]. Perceptually, photometric variation issues are mainly due to a luminance variation which is the most significant contributor to the color variation in the projector display [34].

2.5.5

Intensity Transfer Function of the Projector

It has been known that the display devices such as CRT and LCD monitors have a non-linear response for the output luminosity of the RGB channels [11]. This is also true for digital media projectors which means that the relationship of the input for each RGB channel is not linear with output luminance. This non-linear response is known as the Intensity Transfer Function (ITF). It is important to know this response so that a desired luminosity can be related to an RGB input. It is also shown that the ITF is not the same from one pixel to another, yet their shape is the same. Since it is desired that an RGB output delivers consistent luminosity regardless of location, ITF should be normalized to be the same across every pixel (spatially invariant). After normalizing, a single non-linearity correction look up table is needed for each channel. In total, there will be three different look up tables, one per channel (red, green, and blue) [34]. In [34], a precision spectroradiometer (Photo Research PR 715) was used for point measurements in order to accurately measure the ITF. For measuring the spatial luminosity variation of the whole display, a high-resolution digital camera is usually used. Nowadays, DSLR cameras are available for quite reasonable price and can be used with different exposures (by varying the shutter speed) to measure different levels of luminosities accurately and faithfully [36, 34]. An inexpensive camera was used in this thesis (Canon Rebel t1i 500D DSLR) and its nonlinearity was recovered using the HDR imaging method explained by Debevec and Malik in [41]. After finding the nonlinearity of the camera which is known as the CRC, its inverse is used to linearize the RGB image in order to calculate the luminance using RGB to YUV

32 linear transformation as in equation 2.1 [11].

Y = 0.299R + 0.587G + 0.114B where R, G and B are Linearized RGB from the camera

(2.1)

Chapter 3 Printer Modeling Using an Artificial Neural Network

I

N this chapter, the feasibility of using an ANN to learn and model mappings between color spaces is established. Specifically, transformations in digital color imaging from

RGB to CIELAB are compared between conventional ICC profiles and a newly developed ANN model. The accuracy of the transformations are computed in terms of E and a comparison is made between the ICC profile and the ANN model implemented in MATLAB. The transformations are used to characterize and test the color response of an Epson 4800 inkjet printer. A number of data preprocessing techniques are also described which helped in creating a clean data set for modeling the accurate response of the printer. The results demonstrate a back propagation ANN model based on LM with accuracy of 0.28 E for non-training set data.

3.1

Color Imaging Device Characterization

Most practical CMSs adjust image values by transforming device-dependent pixel values (RGB and CMYK) into, and out of, a central, device-independent CIELAB color space [2]. A devices color response is measured and modeled, this data is then used to determine a transform relationship that is incorporated into the conversion of pixel data from RGB to CIELAB and/or from CIELAB to CMYK which depends on the imaging device wether a CMYK printer, RGB monitor, or RGB printer. A well established color management 33

34 implementation exists in the form of the ICC color profiles. In ICC-based systems, device characterization information is stored in single and multi-dimensional LUTs within profile files, such that an input profile provides a mapping between input RGB and CIELAB, and an output profile provides a mapping between CIELAB and output RGB/CMYK values [42]. The accuracy of color from input to the displayed image, to the printed image, depends in part on the quality of the characterization. There are a number of ways to define the characterization and transform relationship between device-dependent values and CIELAB. Typically, a test chart of equi-spaced RGB/CMYK values is printed or displayed, and the resultant CIELAB values are measured using a colorimeter or spectrophotometer. This physical data is then used to model the response of the system. It is possible to use data fitting processes that range from a simple linear matrix approximation to higher order polynomial regression [20] or Newton-Raphson iterative techniques [43]. Researchers have described parametric dye modeling that uses Neugebauer-type mathematical models to predict the color produced when different amounts of dye colorant are present [44]. It is possible to use an empirical approach to construct a LUT [17] and the literature also describes attempts to use both LUTs and curves to expand data in certain areas [45]. In general, devices such as additive color, computer monitors can be characterized by a linear expression (the phosphor matrix), combined with a nonlinear expression (the gamma curve), while more complex subtractive color systems, such as print devices require fitting techniques that can adequately model a non-linear color response.

3.2

Artificial Neural Networks for Printer Modeling

Artificial Neural Networks can be used to approximate the non-linear relationship between device-dependent and device independent data sets [46, 47]. A recent paper uses a Generalized Regression Neural Network (GRNN) in order to model the transformation between CMYK and CIELAB [48]. In another ANN approach, Resilient Back Propagation (RBP) was used to train a system using 56 patches [49]. Generally, RBP is not recommended for function approximation problems. Despite this, the approach showed some potential for

35 forming accurate transformations. This research relates to the use of an ANN to identify faster and more robust color conversion methods. The method proposed in this chapter is based on LM back propagation training algorithm which has a high computer memory requirement, but accelerated convergence. The accuracy of the LM back propagation artificial intelligence model implemented via MATLAB is compared with a standard ICC output profile made with X-Rite ProfileMaker 5.0.8 (a commercial ICC profiling software application 1 ) [50]. The accuracy of the transform relationship between RGB and CIELAB is studied for an Epson 4800 inkjet printer, addressed in RGB mode using a ColorBurst RIP. This chapter describes the use of the LM algorithm and proposes a process to filter and pre-sort the data, which is important for removing non-unique solutions, speeding up the training process and increasing the accuracy of the algorithm.

3.3

Experimental Procedure

The proposed setup seeks to establish a transform between RGB instructions and measured CIELAB response for an Epson inkjet printer. The Epson 4800 is a 7-color printer (CMYK + light cyan + light magenta + light black), but was treated as an RGB device to avoid the complexity of the redundancy introduced by the black (K) channel. Training data was obtained by printing an RGB test target called TC9.18 [51]. This target was chosen because the CIELAB measurement data could be used to create an ICC profile and the same data could be used to train the MATLAB implemented neural network algorithm. A fair comparison between the two processes could then be undertaken, as the same training data was presented to each system. The test target was printed, allowed to dry, and then measured using an X-Rite i1iO spectrophotometer as shown in Fig. 2.4
1 2

http://www.xrite.com/home.aspx TC9.18 is one of the many test charts included in the X-Rite ProfileMaker 5.0.8

36

Figure 3.1: Test chart TC9.18.2

3.3.1

Generating an ICC Profile

A conventional ICC output profile was made using X-Rite ProfileMaker 5.0.8 [50]. In the user GUI, the operator requested an output profile of large size, this increases the nodes in the LUT from 25 to 33. The larger number of cube nodes increases the file size of the profile but provides better accuracy during interpolation. Training (measurement) data was presented to ProfileMaker that uses a proprietary internal fitting procedure to model the device response and then populate a color LUT tag and save an ICC profile on disk. In creating the training data it is necessary to consider the number of patches used. For a non-linear device (e.g. a printer), a large number of patch samples allows the algorithms to create a better transform relationship and thus color conversions with better quality. The trade-off is between quality and chart size, as the larger number of patches necessitate a larger target which takes up more space on the printer and will take longer to measure. The difference in the characterization due to a smaller target was also studied by making an ICC output profile from a 360 patch target and comparing that to a 936 patch target made on the same device, Fig. 3.2. The 3-dimensional L*a*b* gamut visualization shows limitations where sparse data re-

37

Figure 3.2: Gamut of the ICC profile made and viewed in 3-dimensional L*a*b* color space, a small color target creates a jagged color gamut (left), while more data points creates a smoother characterization (right).

sults in a non-smooth response. In the subsequent experiment, the larger target with 936 patches was used.

3.3.2

Data Preprocessing

The TC9.18 test target which is shown in Fig. 3.1 contains 936 patches, but these are not unique R, G, B combinations. In test targets it is normal to include a duplication of certain important colors, such as the white point RGB of (255, 255, 255) and/or a neutral gray (128, 128, 128). In some targets there are extra pixel values near skin tones in order that the training data contain adequate information in these colors as they are important for making visually pleasing images. The TC9.18 test chart has a number of patches with the same RGB value such as (255, 255, 255), in practice their measured L*a*b* values will be slightly different for each patch, due to measuring instrument variability and printer deviation. This will affect the training

38 process as there are different L*a*b* values for the same RGB value. In this experiment, a filtering process was developed that checks for the same RGB patches in the data set and then averages the corresponding L*a*b* values so that each RGB pixel value has a unique L*a*b* solution. There is another aspect that also requires preprocessing of the data. When a target is printed, there may be pixel values that are outside the color gamut of the printer, these colors will be mapped to the outer extent of the printer gamut. This creates a situation where differing RGB pixel values create essentially the same measured L*a*b* value. This effect will happen at the very light and very dark ends of the color scales. Once again this leads to non-unique solutions in the training data set. A second filter was therefore developed that sought to reduce the effect that gamut clipping has on the data set. The use of the two filters creates unique training data and improves the accuracy of the ANN model. The effect of the two filtering processes was to reduce the 936 patches to 909 filtered data points. Another aspect of preprocessing to improve the quality of the raw data is manipulation of the RGB target values in order to create equi-spacing of the measured data points in L*a*b* color space. While this is considered beneficial this type of filtering was beyond the scope of the project at this time. In the last step before using the data for training, it was necessary to map or scale the data to a suitable range. The activation function chosen for each hidden node was tansig. As such, within the range of [+3,-3], the hidden nodes exhibit sufficient sensitivity and nonlinearity to allow the network to efficiently model the non-linear nature of the overall transfer function. Beyond such a range, hidden nodes would easily become saturated, leading to less stable, prolonged convergence. In general, RGB pixel values are in the range of [0, 255], L ranges from 0 to 100, and a and b have a scale from -128 to +127. Each channel of the input and the output was normalized to have a mean of zero and standard deviation of 1.0 [52]. The normalized data was then necessarily mapped to a range of [+2.5,-2.5] to comply with the hidden node configuration.

3.3.3

Training Process using LM Back Propagation Model

39

A robust back propagation, LM neural network solution [52] was considered to model the response of the inkjet printer. The network model has 3 inputs (RGB) and 3 outputs (L*a*b*). The total number of layers was chosen to be 3. There were two layers for input and output. The number of nodes in the hidden layer was chosen to be 360 as it gave a good balance between speed and accuracy. The total number of weights in the network had to be limited because the LM back propagation training algorithm only works with several hundreds of weights. The transfer functions for all the hidden nodes were chosen as tansig and the purlin for the output layer. The function was called trainlm, and it works best when training networks with several hundreds of weights and is recommended for function approximation problems especially when accuracy of the training is an issue.

3.4

Results and Discussion

An ICC profile was compared to the back propagation algorithm. To automate the processing of data, the LUT structures of the ICC profile were imported into MATLAB using iccread. The MATLAB command makecform was used to create a concatenated LUT structure akin to the function of the CMM [14] and the other command applyecform was also used to do color transformations in MATLAB. In order to confirm that MATLAB was processing the ICC profile contents correctly, the result was compared with the use of the same profile in Adobe Photoshop. The use of the ICC profile structure within MATLAB was compared to a standalone mode where the profile was used in Adobe Photoshop CS3 with the Adobe CMM. In Table 3.1 shows a comparison between MATLAB R2007b and Adobe Photoshop CS3 when converting specific RGB to L*a*b* values. The E was also computed as colorimetric difference measure as in Eq. 3.1 where L*, a* and b* are CIELAB coordinates [53]. There is good correlation between an ICC profile being used within MATLAB or in Adobe Photoshop CS3. The rendering intent

40
Table 3.1: Experiment to confirm that an ICC profile used within MATLAB or Photoshop produces equivalent results.

RGB pixel value CIELAB via ICC profile in MATLABR 2007b 0,0,0 5.88,-1,0 128,128,128 65.49,0,1 255,255,255 95.29,0,1 0,0,255 42.35,3,-54 was used in both cases was Absolute Colorimetric.  E =

CIELAB via ICC profile in Photoshop CS3 6,-1,0 66,0,1 95,0,1 42,3,-54

E

0.12 0.51 0.29 0.35

(L1 - L2 )2 + (a1 - a2 )2 + (b1 - b2 )2

(3.1)

where L*, a* and b* are CIELAB We now consider the results of preprocessing the data using the two preprocessing filters and then training the network. The TC9.18 test target with 936 patches was printed and measured. The data was used to make an ICC profile using the process described earlier. Next the measurement data was filtered and then used to train the back propagation LM neural network. The effect of the two filtering processes reduced the 936 patches to 909 patches. The 909 patches form the training data set. In general a more useful test of accuracy is when non-training set data is used to estimate the accuracy of the transform. A different, proprietary target, called TC2.83 with 360 patches was printed and measured, this became the non-training or testing data set. Before using the testing set, patch values were compared to the training set, to ensure that the testing set is indeed unique, any identical patch values were removed, this process reduced the testing set from 360 to 256 unique patch values. The 256 RGB pixel values were processed via the ICC profile and also via the ANN model and in each case the predicted L*a*b* value was noted. The efficiency of each process was estimated by comparing the predicted L*a*b* values with the values measured from the testing color target. The mean and maximum E error for the ICC profile was 0.46

41
Table 3.2: Sample data points were processed via an ICC profile and also by the ANN Model.

RGB Value Measured CIELAB using i1iO 0,0,51 11.46,-0.8,-21.47 0,255,127 79.35,-30.9,19.26 15,15,0 8.22,-1.54,1.39 112,94,94 53.41, 10.44,5.38

CIELAB via ICC profile in MATLAB 11.76,0,-21 79.6,-31,20 9.01,-2,2 53.72, 10,5

E

0.73 0.78 1.1 0.66

CIELAB via ANN Model in MATLAB 11.45,-0.68,-21.4 79.42,30.99,19.50 8.7,-2.08,1.39 53.57,10.51,5.73

E

0.13 0.27 0.73 0.4

(3.64) and for the ANN model the mean and maximum E error was 0.28 (2.29), when computed for 256 color patches. Some individual results are also shown in Table 3.2. A comparison was made with other researchers who also used a back propagation algorithm to train their network for a RGB printer [49]. In that research, the average E for 14 (testing) color patches was 2.35 when converting from RGB to L*a*b*. In other research, a GRNN model was used to model the transformation between CMYK and L*a*b using the ECI2002 printer target [48]. The accuracy of the GRNN process for 171 (testing) patches was a E of 1.82. In general, for a conventional ICC-based LUT, generated with commercial software, the accuracy of an output profile for a CMYK device is around 2.0-4.0 E [18]. These results provide a ball-park figure for the expected accuracy of any transform relationship and show that the algorithm developed in this project is extremely accurate. The research produced a valuable comparison between a standard ICC profile and the ANN approach. Experimentation and variables were examined to determine the most suitable neural network solution that produced the lowest fit error. It is important to note that an ICC profile is a quantized LUT that may suffer interpolation inaccuracies, while the ANN model that can naturally generalize, in essence acting as a continuous mapping. For runtime applications it is often necessary to use a quantized LUT and accept the lower quality; however interpolation is then needed as a final stage. In a feedforward state, the trained ANN model is fast and can function using a small memory footprint, without the need for interpolation. Some major areas of this investigation are ongoing. Since the forward, i.e. the device to L*a*b* transform was considered here only. An extension to this work might be

42 to consider the reverse transform, from L*a*b* to device. Another aspect that also needs to be examined in the future is extension of the model to include CMYK to L*a*b* characterizations, i.e. the situation of mapping a CMYK (4-channel) input to a L*a*b* (3-channel) output. To conclude, the LUT required complex 3D interpolations but in ANN model this is not the case. Finally, the work achieved in this chapter was published in [53].

Chapter 4 Modeling The Printer Output In The Viewing Booth With HDR

I

N this chapter, a soft proofing system was established with the help of the HDR imaging techniques. Since it was noticed in Chapter 3 that ANN is very powerful in modeling

color space conversions, this method was used as a ground truth in modeling the soft proofing system for which there is one input (the digital image) and one output (the HDR image which represents the soft proofed version of the digital image). It was also shown that taking an HDR image of the printed image in the viewing booth gives a better detailed soft proof compared to Photoshop as it was investigated by industry color expert, Angus Pady 1 . More details on why HDR was taken into consideration are discussed in section 4.1.

4.1

Investigation of HDR Imaging

It is widely known that the printing industry did not follow the fast advancements of the digital imaging devices such cameras and monitors. As such, it has been always a challenge to produce a printout that looks like the digital version on the screen because the dynamic range of the printers is much smaller than the gamut of the monitor. The dynamic range refers to the ability of the imaging device to capture or reproduce colors. For instance, imagine taking an image with a camera (even high quality camera) then displaying the
Angus Pady is a Color Management Connoisseur,G7 Certified, GRACoL Certified Master Consultant, ONYX Profiling Expert, Certified EFI ColorProof RIP Color Consultant, and Reseller of all color management products
1

43

44 image on the monitor of your laptop and one might wonder wether the displayed image on the monitor is the same real scene observed with one's eyes. It can not be exactly the same as the real scene because the scene has a much wider gamut range of colors compared to the limited gamut of the camera and the monitor. In addition, when it comes to printing devices, their dynamic range is even smaller compared to a camera or a monitor. Therefore, theoretically, to capture a printed image which has a smaller dynamic range compared to a camera and a monitor, one Low Dynamic Range (LDR) shot from the camera should be enough to capture the full range of the printed colors and there is no need to use HDR [54].

4.1.1

Normal Imaging Techniques

Since an "Automated" Soft Proofing System is the ultimate goal of this thesis, a camera (Canon Rebel t1i 500D DSLR) was used to capture the printed image in the viewing booth and reproduce it on the calibrated monitor so that it looks exactly like the hard copy displayed in the viewing booth. After calibrating the printer, the test target TC9.18 was printed using the customized ICC profile and displayed in the viewing booth with moderate intensity level of the D50 light in the viewing booth. In order to make sure that the camera settings were chosen accurately, another test image which has more complex patterns of colors with highlight and shadows needed to be printed and displayed. The image that was employed for this purpose was designed by the color specialist Angus Pady and it is shown in Fig. 4.1. The use of this image helped in determining the correct camera settings to capture the right colors with all the highlight and shadow information so that colors are reproduced as accurate as possible. The accurate reproduction of the printed image is important towards getting the relationship between the original image and the printed image. The used camera can operate in a RAW mode in which a RAW image is captured. In this mode, the custom ICC profile should be assigned to the images in order to display the correct colors of the captured RAW image. However, when shooting images in the JPEG format, the camera uses the sRGB profile to display the correct image. In other words, the

45

Figure 4.1: Color checker test chart.

internal software of the camera will automatically apply this standard ICC profile (sRGB) to the captured image. Adobe98 is another standard RGB profile in the camera and sometimes it is used to get a wider gamut since its gamut is bigger than the sRGB profile. The ISO setting in the camera represents the gain, therefore, the ISO is kept as low as possible (100) so that the noise will not get amplified in the captured image. For a given viewing lighting condition in the booth with the Color Check being displayed, the camera recommends a shutter speed of 1/30 second, aperture of 4.0 and an ISO of 100. The camera can get the right shutter speed based on the built-in photometer that measures the light in the actual scene and sets the correct exposure. Two captured JPEG images were displayed in Photoshop, one used the sRGB profile and the other used the Adobe98 profile. The displayed images were compared to the hard copy image in the viewing booth and the overall appearance was not quite similar to the hard copy. For instance, there was a little change in some colors and the most noticeable difference was in the highlights and shadow areas which were not visible compared to the hard copy. However, the Adobe98 JPEG captured more colors without compressing them so that colors looked closer to the

46 real scene compared to the sRGB captured image. This is expected because Adobe98 has a bigger gamut than sRGB. A custom ICC profile was created for the camera as it was explained in section 2.3.3. The process of generating a good custom ICC profile required 4-5 hours of work most of which was to get a uniform lighting. A completely even illumination was not possible to achieve but the generated custom ICC profile was tested by a set of pictures (outdoor and indoor scenes) and it was acceptable. That is the general tedious process for generating custom ICC profiles for photographers. This ICC profile was used in Capture One software which allows RAW images to be taken and processed using the custom ICC profile and saves the results as TIFF images. The resulting image is shown in Fig. 4.2. The generic Canon EOS 500D ICC profile (this profile is ready from the manufacture for general use) was also used when a raw image was taken using Capture One software. The same camera settings were employed so that a comparison can be made. The resulting image did not show a good representation of the original print (the image was yellowish) as shown in Fig. 4.3. Therefore, the custom profile performs better than the generic ICC profile but the image still needs to be manipulated and adjusted manually in Photoshop in order to give a good (close) match compared to the original prints in the viewing booth. None of the previous images in Fig. 4.2 and in Fig. 4.3 show a good representation of the printed image in the booth. There are problems in the highlight and dark areas. Changing the camera settings such as ISO, shutter speed, and aperture priority did not improve the results. It was noticed that when the shutter speed is reduced (more light passing through the camera lens), some details of highlight areas were missing because these area are now over-exposed, while other details of dark areas looked closer to the printed image as it can be seen from Fig. 4.4. It can be concluded that increasing the shutter speed from the chosen value by the camera, which is 1/30 sec, will allow more light to come in through the camera lens. This results in over-exposed highlight details which will not be captured well but the details of dark areas (such as hair) will be captured. On the other hand, decreasing the shutter speed

47

Figure 4.2: Raw image of the color checker in the viewing booth taken in Capture One software and processed using custom ICC profile made for the camera. Camera settings were IS0=100, Sh=1/30sec and AP=4.0

Figure 4.3: Raw image of the color checker in the viewing booth taken in Capture One software and processed using the Generic ICC profile. Camera settings were IS0=100, Sh=1/30sec and AP=4.0

48

Figure 4.4: Raw image of the color checker in the viewing booth taken in Capture One software and processed using custom ICC profile made for the camera. Camera settings were IS0=200, Sh=1/10sec and AP=4.0

will make the highlight details clearly visible but the dark areas will be darker and its details will be missed. Changing ISO, shutter speed, and aperture priority did not produce a good representation on the calibrated monitor compared to the hard copy prints as shown in the previous images taken with different ISO and shutter speed. Based on the above simple experiment, getting a good match between the captured image in Photoshop and the original printed image can be achieved by selecting the best of the above images and manipulating the image in Photoshop such as changing gamma, exposure, brightness, contrast and some other settings related to color levels, shadows, and highlights until a good match is achieved. This process is time consuming, not consistent and requires professionals. Therefore, the main goal of this thesis is to produce a consistent and automated soft proof with a simple click of a mouse, negating the need for tedious measurments, and matching the viewing booth intensity to the monitor. Specifically, HDR was considered in order to accurately capture colors and more importantly the highlights and shadows as it is explained in the following section.

4.1.2

HDR Imaging Techniques

49

From the experiments and discussion in section 4.1.1, it was found that using neither custom ICC profile nor LDR give accurate reproduction of the hard copy contrary to recommendations made in [54]. HDR imaging techniques were considered to provide images with true colors that represent the original scene because HDR captures the details of both highlights and dark areas and combines them into a single image. Intuitively, taking an HDR image should improve the soft proofing system because details can be shown with greater dynamic range which means colors should appear more indicative of the original scene. The HDR image was made from LOW resolution JPEG images which performed better in terms of complexity and appearance. There is no need to make a custom ICC profile for this purpose. 15 exposures (with 1/3 f-stop between each exposure) were taken using the camera's normal JPEG format in order to reduce the noise in the printed image and avoid amplifying the noise in the digital version of the printed image. These 15 images were merged into single HDR image using Photoshop. The resulted HDR image from sRGB mode is shown in Fig. 4.5 and the resulted HDR image from Adobe98 mode is shown in Fig. 4.14. On a calibrated monitor, it was seen that HDR images with Adobe98 profile gave better results (colors are very close to the printed image) compared to the sRGB profile. Therefore, it was found that an HDR image made from JPEG low resolution images is much closer to the original prints than the calibrated RAW image.

4.2

Experimental Setup

It was shown in section 4.1 that the HDR capture of the printed image in the viewing booth gave an accurate image reproduction on the calibrated monitor. When the HDR image was compared with an image generated by the soft proofing tool in Photoshop, it was noticeable that HDR gave accurate reproduction in terms of colors and details. Since the image on the monitor showed a good representation of the printed image in the viewing booth, it was possible to build a model that can learn the relationship between the original digital image

50

Figure 4.5: HDR image of the color checker using sRGB.

Figure 4.6: HDR image of the color checker using Adobe98.

51

Figure 4.7: Test chart TC9.18 in the viewing booth.

and the new digital version of the printed image. This model can be applied to any image to predict its hard copy appearance before printing which is the basis for a new soft proofing tool proposed in this thesis. Furthermore, this approach can be extended across multiple intensity levels as will be explained in detail in chapter 5, thereby enabling soft proofs to potentially model variation due to changing illuminant. The test chart TC9.18 shown in Fig. 3.1 was printed using the calibrated RGB printer. The printed test chart was allowed to dry for 10 minutes and it was placed in the middle of the viewing booth where the light is as even as possible as shown in Fig. 4.7. 15 automated exposures were taken and merged in Photoshop in order to create the HDR image in the same way as described in section 4.1.

4.2.1

Image Registration

In order to build a mapping between the original test chart (RGB values before printing) and the HDR image of the printed image (RGB of the printed version), the HDR image of the printed version has to be registered to the original image. An algorithm was written in order to remove the borders of the test chart and extract only the internal color patches which are required for building an accurate mapping. The test chart after cutting the borders is shown in Fig 4.8.

52

Figure 4.8: The original test chart TC9.18 without borders.

The next step is to register the image in Fig. 4.8 to the image of printed version of the test chart in the viewing booth. The registration algorithm was implemented in MATLAB. The main idea is to find the cross correlation between the two overlaid images and manipulate how they are overlaid until a correlation is maximized. In other words, the two images being well aligned resulted in maximum correlation. A Gaussian smoothing filter with a window size of 3x3 was used to smooth the images and resulted in better registration. The whole image registration process was done in two steps as explained below:  Step One: The two images were converted to gray scale images and a square was cut from the middle of the original image. This small image was correlated with the printed version in order to determine the maximum correlation. The printed image was resized with different ratios and the corresponding maximum correlation was calculated. The resizing ratio with the highest correlation was chosen to lead to more accurately aligned images.  Step Two: In this step, the resized printed image was slightly rotated a few angles clockwise and counter clockwise. The rotation angle that generated the maximum correlation was chosen. After determining the size and angle that generate the maximum correlation, the printed im-

53 age was correlated with original image to get the maximum correlation in order to accurately register the two images.

4.2.2

Data Preprocessing

After the registration, the mapping between the two images should be modeled in order to be able to predict the printed version of any digital image before actually printing it. In order to create an accurate model, clean data should be used. The original test chart has 936 patches, however, after removing similar patches and making the data unique, there was 911 unique RGB patches as shown in Fig. 5.25. Each unique RGB value corresponds to many RGB values in the printed image. Therefore, these values were filtered by an algorithm that takes all the printed RGB values that belong to one RGB value in the original test chart and filters them to a smaller set of values. This was done for each unique RGB value as it is described in the following steps:  A mean value is calculated from all the values that corresponds to one RGB value in the original test chart.  The distance between every RGB value and the mean is calculated.  Data is then sorted based on the measured distance in the previous step.  The median RGB values were chosen along with  5% of the population which means 5% above the median value and 5% below the median value. The explained filtering process resulted in an overall data size of 2983 points which means that for each original RGB value, there are few printed RGB values and the goal of the ANN is to learn the mapping in a manner similar to that presented in chapter 3. The printed RGB values are shown in Fig. 5.26.

4.2.3

Training

The 2983 samples were divided into training, validation, and testing samples during the training process. Since the data was sorted, the validation samples were 299 samples indexed

54

Figure 4.9: The original RGB of test chart TC9.18 shows 911 unique values.

Figure 4.10: The printed RGB of Test chart TC9.18.

55

Figure 4.11: The RGB values of the printed target with the predicted RGB by ANN.

at 1, 11, 21, 31, .....2981 and the testing samples were 299 samples indexed at 2, 12, 22, 32,......2982. 20% of the overall data was used for testing and validation and 80% was used for training. The number of nodes in the hidden layer was chosen to be 360 after a few trails with different structures. This structure provided a good mapping with a Mean Squared Error (MSE) on the test data of 4.8 with training time of 135 seconds in 15 epochs. However, a more complicated network of 600 nodes was trained and resulted in an MSE of RGB on testing data set of 4.5 with training time of 533 seconds. Comparing the two network structures indicates that the smaller network is better, given its faster training time and implementation when an image is applied. Also, an MSE of 4.8 for the smaller network is quite good and it is not much higher than the MSE of 4.5 of the bigger network 4.5. The predicted values of the printed RGB values are plotted versus the targeted values and shown in Fig. 4.11

56

Figure 4.12: Original Lena image before printing (Left) and the predicted image of the printed version of it (Right).

4.3

Results and Discussion

In the previous section, the modeling of the original RGB values of the original image (digital image before printing) with the HDR image of the printed image viewed in the viewing booth was explained. This model was created since it was shown that the HDR image of the printed image in the viewing booth is a good reproduction of the image in the viewing booth. The modeling was done using the TC9.18 chart shown in Fig. 3.1 to create an accurate mapping that can be used as a black box with any future image for which the printed version needs to be predicted on the calibrated monitor before actually printing the image. Fig. 4.12 shows the original Lena image and the predicted printed version of Lena image. However, the colors of the predicted image are not the same as the printed image or Photoshop results. In order to check the results accurately, the image should be displayed on a calibrated monitor aimed for soft proofing purposes. The color checker image shown in Fig. 4.1 was used in order to predict its appearance when it is printed, as it can be seen in Fig. 4.13. It was shown in sections 4.1.1 and 4.1.2 that HDR imaging techniques can produce accurate and faithful results on the calibrated monitor. However, when the prediction model that was created using ANN as it was described in section 4.2 was used, the results were not as accurate as was expected. It can be seen in

57

Figure 4.13: Original color checker image before printing (Left) and the predicted image of the printed version of it (Right).

Fig. 4.13, the predicted image does not provide a reasonable appearance compared to the image in Fig. 4.14 which is the HDR captured image of the printed image of the original color checker image. Therefore, the predicted image did not meet the requirement and it did not give the same appearance as the HDR captured image. The main reason that the implemented model did not meet the requirement was that the lighting on the test chart in the viewing booth was not uniformly distributed on the chart which makes each patch of the test chart have a specific color value depending on how much light was illuminating each patch. This issue introduced a serious problem in modeling the original RGB shown in Fig. 5.25 with the printed RGB shown in Fig. 5.26. For example, when a plain white paper was displayed in the viewing booth, it was very clear that the lighting in the viewing booth was not uniform. Moreover, when an image was taken of this plain white paper, it was very obvious that the white paper did not look uniform and pixels have different values as can be seen from the gray scale image shown in Fig. 4.15. To have a better understanding of the overall uniformity issue, a simple measure of variability was calculated, the standard deviation, for the pixel values of the white image after cropping it to a smaller image of the white paper which includes the Region Of Interest (ROI). The Std value for the cropped image was calculated to be 12.04 on gray scaled image which means that 68.2% of the data (pixels) are within 12.04 from the mean value of 165.

58

Figure 4.14: HDR image of the color checker using Adobe98.

X: 679 Y: 490 Index: 134 RGB: 0.588, 0.588, 0.588

X: 1496 Y: 990 Index: 177 RGB: 0.776, 0.776, 0.776

X: 2332 Y: 1518 Index: 152 RGB: 0.671, 0.671, 0.671

Figure 4.15: Gray scale image of the viewing booth showing intensity values at arbitrary different locations on the white paper.

59

Figure 4.16: The luminosity of the viewing booth.

This cannot be considered a uniformly illuminated white paper especially when the minimum and maximum pixel values were found to be 125 and 186 respectively. The luminosity was also calculated after linearizing the camera as it is shown in Fig. 4.16 in which the nonuniformity of the luminosity in the viewing booth can be noticeably seen. As it was mentioned before, the viewing booth is not uniform as seen by the camera and the eyes as well. In addition, the non-uniformity of the viewing booth luminosity is mainly due to the type of light source used and it is not possible to make it uniform since it can not be altered or its intensity be changed on a location basis. It is also worthwhile to mention that the camera introduces some kind of non-uniformity due to the lens as well as introducing some noise [11]. The noise was significantly reduced by taking the average of five images of the exact same scene with the camera fixed on the tripod. For those reasons, it is applicable to say that the created model was not accurate due to illumination issues of the viewing booth which made the color appearance dependent on the specific lighting condition on each patch color. For instance, a green patch has an RGB value of (52,123,65) at one position in the viewing booth while the same green patch displayed in different position in the viewing booth has an RGB values of (61,141,70). Therefore, creating a model to represent

60 the original RGB values with the printed RGB values of the HDR image will not be valid because each color patch will be modeled based on the amount of illumination at this patch. Consequently, it was hypothesized that uniformly distributed illumination would be the key to successful modeling. To conclude, a projector based lighting was introduced in order to create a uniform lighting condition in order to capture the test chart accurately and having the color patches independent of their location as it will be described in the next chapter.

Chapter 5 Improved Modeling By Viewing Booth Light Compensation

I

T was discussed earlier in chapter 4 that it is possible to use HDR to reproduce an accurate image on the calibrated monitor to represent the printed image in the viewing

booth. Building the model using ANN techniques was also implemented in order to apply it for other images and predict the printed version on the monitor. As discussed in section 4.3, the lighting in the viewing booth was not uniform which led to inaccurate representation of the colors and so did not provide meaningful and reliable results. Therefore, the goal of this chapter is to find an alterative and effective technique in order to compensate for the nonuniform illumination in the viewing booth, in order to ensure that color values measured from a test chart are independent of their location in the viewing booth.

5.1

Projector Calibration and Registration

As explained in section 2.5.1 that LCD projector is suitable for the intended purpose in this thesis. In this section methods for calculating the camera's nonlinearity curves, projector's ITF, projector-camera registration, and compensating for the projector's uniformity are explained in this section.

61

5.1.1

Experimental Setup

62

The goal is to achieve the same photometric response for the whole projected area of the display. This is called photometric uniformity [55]. To get more accurate results, the ambient light affects were reduced by taking the measurement in a black painted wall room with all lights turned off. Since MATLAB was used as an interface platform, finding a method of connecting the camera and the projector to the PC and to be controlled via MATLAB was an essential initial step towards achieving a uniform lighting in the viewing booth. The Canon camera that was used in thesis can be fully controlled via a software called DSLR Remote Pro for Windows by connecting the camera to the computer using a USB port. By using this software, all the functionality of the camera including ISO setting, exposure values, aperture settings plus all the available setting on the camera can be controlled via the software interface. This software was purchased and downloaded from Breeze Systems 1 . A tripod was used to fix the camera in order to have consistent images without any movement in addition to remotely controlling the camera. It was also necessary to be able to control the camera via MATLAB. For that purpose,the DSLR Remote Pro software includes an interface library which can be used from other applications. Vignetting effect is mainly caused by the camera's lens limitations which can be compensated by setting the camera to operate at a low aperture setting. The camera's nonuniformity can be neglected at narrow aperture setting below F8. The lower the aperture, the smaller the area of the lens is and this leads to a more uniform image since only a small area of the lens is used. [56]. The projector used in this thesis was NEC VT670 3LCD projector. This projector had to be controlled via MATLAB while having the ability to control the images being sent to it. The projector was connected via VGA cable to the computer. In order to be able to work in a closed loop system while controlling the projector and the camera, the computer was set to extended mode so that the extended image could be sent to the projector. By displaying
1

http://www.breezesys.com/DSLRRemotePro/index.htm

63

Figure 5.1: The full setup of the system which includes: LCD projector, camera, and laptop.

a figure in MATLAB and sending it to the projector, some edges of the MATLAB figure were displayed by the projector. In this case, it was not possible to control every single pixel of the image sent to the projector when a full white image was displayed on the projector. Therefore, a MATLAB code that uses JAVA was employed to have the full image content displayed by the projector with no edges. Hence, it is required to send an image with the exact same size as the projector image (1024 by 768). Thereby, a full controllable system of the camera and the projector via MATLAB was obtained. The full setup is shown in Fig. 5.1. Finally, the projector was set at a height of 30 cm with a distance of 160 cm from the screen and the camera was at distance of 170 cm from screen with a height of 45 cm. With this setting, the center of the camera lens lay on the center of the projected image.

5.1.2

Finding the Camera Response Curve

As explained in section 2.5.5, it was important to linearize the camera by finding the CRC in order to truthfully measure the luminance of a scene using only the digital camera. Debevec and Malik explained in [41] how to recover HDR radiance maps from images taken with

64

Figure 5.2: Image acquisition pipeline that relate the real radiance from the scene to pixel values for both film and digital cameras. This relationship is unknown and nonlinear because of the exposure, development, scanning, digitization, and re-mapping [41].

normal camera using images of the same scene with different exposures. For more details, check the link 2 . The algorithm described in [41, 11, 54] calculates the mapping from scene radiance L to pixel values Z with a set of differently exposed images Fig 5.2. The more images with varying exposures that are taken, the better the mapping is in terms of noise sensitivity. This algorithm was used in order to linearize the camera in a LUT that is used to linearize any RGB values read by the camera which is used to calculate the luminance. It is very important to have a static scene to capture more than one image with varying exposures in order to obtain an accurate result for computing CRC. In this case, CRC was computed from a set of exposures starting at 10 second to 1/6 second in 1/3 f-stops which led to a total of 19 differently exposed images. The neutral exposure is 1.3 seconds which is what the camera gives when aperture is set to 29 using the camera's built in photometer; thus, nine under exposed and nine over exposed images were taken which led to 19 images in total as shown in Fig. 5.3. 19 exposures was used to cover wider dynamic range to accurately calculate the CRC. The camera ISO was set to 100 and the camera aperture was set to 29 with all images in order to minimize any distortion due to lens non-uniformity. These images were taken while the projector was displaying a full white image (i.e. R,G,B=255,255,255). Since the white image contains the full amount of RGB, the CRC should represent the cameras' non-linearity function which is used as a look up table to linearize the RGB and compute the luminosity.
2

http://ict.debevec.org/ debevec/Research/HDR/

65

Figure 5.3: 19 Differently exposed images starting from 10 second on the top left image(Overexposed) to the 1.3 second on the second row left image (Neutral exposure) and 1/6 second on the bottom right(Underexposed).

These CRCs can be seen in Fig. 5.4 and Fig. 5.5.

5.1.3

Calculating the Intensity Transfer Function of the Projector

Research work by [57] showed that it is possible to use the HDR method proposed by Debevec and Malik [41] to compute the projector's ITF without the need for an expensive spectraradiometer to accurately measure the ITF. In [58], a photometer was used to measure the per channel non-linear luminance response
300 250 Pixel Value Z Pixel Value Z 200 150 100 50 0 -6 -4 -2 0 log Exposure X 2 300 250 200 150 100 50 0 -6 -4 -2 0 log Exposure X 2 Pixel Value Z 300 250 200 150 100 50 0 -6 -4 -2 0 log Exposure X 2

Figure 5.4: Recovered CRC for the Canon Rebel t1i 500D DSLR camera with three response curves (red, green, and blue channels). Pixel values Z are plotted with logarithmic exposure X.

66
300 Red Green Blue

250

200 Pixel Value Z

150

100

50

0 -5

-4

-3

-2 -1 log Exposure X

0

1

2

Figure 5.5: The CRC for red, green, and blue plotted on the same axes.

at the center with varying input since the projector's ITF does not vary spatially on a normalized scale. As it was described in section 2.5.5, the linearized LUT of the camera was used to measure luminance accurately. The ITF for each channel was measured using HDR techniques for each channel with the following steps: 1. In order to cover the full range of RGB, 52 images were created from 0 to 255 in steps of 5. 2. For each intensity level image, the luminance was computed based on the camera linearity LUT and using HDR to compute the luminance for each level from 19 differently exposed images. 3. The maximum luminance was located and window size of 20 by 20 pixels located at the image centre was created where the maximum luminance could be sampled. 4. Since the luminance response is spatially invariant, the luminance values inside the window were averaged in order to obtain more accurate response and reduce the noise introduced by the image captured in addition to noise reduction done by HDR.

67
1 0.9 0.8 0.7 Luminance 0.6 0.5 0.4 0.3 0.2 0.1 0 0 50 100 150 200 RGB values (Projector input) Green Channel Blue Channel Red Channel 250 300

Figure 5.6: The resulted ITF for RGB channels of the NEC VT670 3LCD projector.

5. From the above steps, 52 luminance values were obtained for each RGB input from 0 to 255 in step of 5. These values were smoothed in order to provide a reasonable curve. The smoothing function used in this step was local regression which uses weighted linear least squares and a 2nd degree polynomial model. This function also assigns lower weight to outliers in the regression. 6. The resulted response was then normalized between 0 and 1. After the above steps were done for the three channels, the resulted ITF's for each RGB channel was obtained (shown in Fig. 5.6).

5.1.4

Camera - Projector Registration

To be able to analyze the uniformity of the projector and to compensate it using the camera, there has to be a good method of registering RGB values sent to the projector and the captured pixels. The advantage of using a projector is that specific patterns can be send to the projector and recognized by the camera, thus registration can be more readily achieved [59, 60, 61]. Capturing the image displayed by the camera resulted in the image

68

Figure 5.7: Checkerboard image sent to the projector.

shown in Fig 5.8 (input image). The goal of this step is to have an accurate geometric registration that maps the input image to the base image. By selecting four pairs of pixels such that each pair corresponds the same feature or landmark in the base and input images, a spatial transformation can be formed using these pairs in order to bring the input image into alignment with the base image. By using cross correlation for the aligned image and the base image, it was possible to cut the aligned image so that it is registered with the base image. This process is also called Camera-Projector Geometric Calibration [57]. Once it is done on the checkerboard image, this registration is valid and can be used later since both the camera and the projector are not moved. The size of the image sent to the projector is 768x1024 and the captured image size is 3168x4752. This resolution of the camera was used in order to capture more information. The captured image was then resized by a factor of 0.25 yielding to 792x1188. After getting the spatial transformation, the images were aligned to give the maximum correlation. The maximum correlation obtained was 95%. The resulted final image is shown in Fig 5.9. The beauty of using the checkerboard image is that it is easy to select feature points. Also, a plain image was not used since it does not allow using cross correlation because it is not possible to correlate constant image with the captured image. This registration was used as ground truth setting for the plain images captured later.

69

Figure 5.8: Checkerboard image captured by the camera.

Figure 5.9: The registered captured image of the checkerboard image originally sent to the projector.

70

Figure 5.10: The luminance measured using HDR when the projector displays a full white image.

5.1.5

Calculating the Luminosity surface of the Projector

As described in 5.1.4, once the registration parameters were found, the same registration setting was used for any captured image. When the projector is projecting a full image of green, the resulting image was captured and registered in order to determine the projector display surface. Checking the white image uniformity A full white image was sent to projector and captured by the camera using HDR techniques in order to calculate the luminance values of the full white display on the screen. The resulting luminance is thus registered. It can be seen from Fig. 5.10 that the luminance of the projector is not uniform. This type of non-uniformity is called Intra-Projector Variation (explained in section 2.5.4). Whilst, the non-uniformity could be from the screen itself and from the camera; however, it is mainly caused by the projector. Compensating for this non-uniformity is the goal at this stage. When the maximum luminance is normalized to 1, the minimum luminance is 0.21 which means that there is a drop in the luminance of more than 80%. The standard deviation was found to be 0.14 and the mean is 0.57.

5.1.6

Achieving Photometric Uniformity

71

To make the luminance uniform and achieve photometric uniformity, we adopted a method from the literature that was originally designed to create seamless blending in multi-projection based tiled displays [35]. The general method of correcting the luminance is to calculate the Luminance Attenuation Map (LAM). The LAM is generated by dividing the minimum luminance (Lmin) by the non-uniform luminance (luminance surface). The LAM is acting like a dimmer in the bright region to bring the luminance down to Lmin and the maximum LAM of 1 will be on the edges so that photometric uniformity is achieved [35, 9]. Once the LAM is generated then it was processed through the projectors' ITF to calculate the right RGB values needed to create a uniform image luminance. This method was used to produce plain images of white while 50 pixels were ignored from around the edges in order to get a good luminance response and not to lose too much of the projector's luminance ability. The LAM was calculated based on the luminance of the green channel since the green channel has more luminance compared to the red and blue channels. The calculated LAM was then applied to other channels using ITF to find the required RGB values in a similar manner applied in [9, 35]. The luminance of the green channel was calculated using the camera based on HDR techniques as explained above. The camera gives an exposure of 2.5 second at an aperture of 29. Therefore, this exposure was used as the base neutral exposure along with 9 over exposed images and 9 under exposed images yielding to a total of 19 images. The standard deviation of the generated even white image after cutting 100 pixels from its edges after registration was 0.02 (mean=0.92). Calculating LAM based on full white image was also tested to get more accurate LAM and have the black offset issue compensated automatically. The resulted standard deviation in this case was 0.016 (mean=0.93) which is better than before. To conclude, using the green channel as base for other channels reduced the standard deviation by 85.8%; however, using the white image as a base to compensate reduced the standard deviation by 89.8%. Hence, the white performed slightly better because using the green channel is accompanied by some

72
Table 5.1: The results of making white uniform using green channel and a full white.

Case Before After using Green After using White

Max 0.8 0.77 0.76

Min 0.48 0.71 0.72

Mean 0.65 0.74 0.74

Std 0.065 0.0092 0.0066

Figure 5.11: The gray scaled image when projector displays full white before making it uniform (Left) and after making it uniform (Right).

leakage from the other two channels (red and blue). On the other hand, using the full white ensures that all RGB guns are turned on and the luminance measure is based on that. Since RGB uniformity is the ultimate goal once a uniform luminance is achieved (even RGB values across the illuminated area), an RGB comparison were made and summarized below in table 5.1. The results in table 5.1 were calculated based on images for non-uniform white, uniform white made based only on Green channel, and uniform white made based on full RGB channels (projector displays a full white). For each case, five images were taken and averaged to reduce the camera noise. Each image was then transferred to gray scale, registered and 100 pixels were cut from around the edge to ensure a valid comparison. The images were then normalized by dividing them to 255 to ensure a maximum intensity of 1. For each case, maximum, minimum, mean, and standard deviation were computed as shown in the table above. To conclude, a uniform white surface was accurately obtained with a standard deviation of 0.016 which is a very low RGB variability across the white image. A recent work by Majumder [9, 35, 8] measured multi display projection system consistency by taking images

73 when different images are being displayed and with some plain images. However, they did not measure the variability as was done in this thesis. In addition, they measured using one image of one exposure, however, in this thesis HDR techniques were used to measure the resulting uniformity over a range of exposures, and faithfully compared it to find the resulting improvements. Unlike the approach taken in [35], it was found that the projectors' non-uniformity was mainly due non-uniformity in all three RGB channels together, not the individual chrominance channel. Moreover, it was demonstrated that making the luminance uniform will lead to uniform RGB image as it can be seen from Fig. 5.11.

5.2

Viewing booth lighting

Large scale displays and projection systems are becoming more prevalent and integrated within our daily physical environments. The brightness, contrast, dimensions, and affordability of these displays is increasing, allowing them to be incorporated into immersive display environments that surround the user [62]. In the report of understanding the technical specification of color viewing stations [63], the author discussed the color consistency (printed or product) when viewed in the viewing booth. The report concluded that the light uniformity in the viewing booth determines the truthfulness of color appearance and any deviation from this uniformity will cause a distortion in the color appearance to the viewer. Therefore, in this section, the projector is being used as a uniform lighting source for the viewing booth.

5.2.1

Experimental setup

A new experimental setup was created in order to be able to use the same LCD projector as a light source to illuminate the viewing booth while using the camera as a measuring device as it can be seen from Fig. 5.12.

74

Figure 5.12: The experimental setup of the hybrid system.

5.2.2

Camera - Projector Registration in the Viewing Booth

The goal in this section is to use the projector to create uniform lighting on the white paper, to be able to measure the printed test chart on the same type of paper accurately. The same registration method that was used in section 5.1.4 is adopted here but with a slight change. The area of interest on the viewing booth is much smaller than the actual size of the projected image. For that reason, the image of the checkerboard sent to the projector was modified to fit within the ROI in the booth. The image was sent to the projector and the captured image of the booth is shown in Fig 5.13. It can be seen from Fig 5.13 that the checkerboard image displayed on the viewing booth is the ROI that is needed to be illuminated uniformly. The normalized cross correlation of ROI was found to be 97%. After registration, any plain image can be accurately registered using the same registration settings as long as the projector, the camera and the viewing booth are in the same location where the registration was performed.

75

Figure 5.13: The image sent to the projector for registration (Left) and the captured image of the booth with checkerboard image (Right).

Figure 5.14: The white image sent to the projector (Left) and the captured image of the booth when ROI is white (Right).

5.2.3

Uniform Viewing Booth Based on an LCD Projector

All the work in this section was performed while the viewing booth is turned off. A plain matte paper was placed in the viewing booth and the same paper was also used in the printer. Thus, having uniform lighting on the paper ensures uniform measure of the printed colors. Checking The Projector Uniformity A plain white image was sent to the projector in the ROI as it is shown on the left side of Fig 5.14 whereas the right image of Fig 5.14 shows the captured white image on the booth which was used to calculate the luminance. The luminance of the captured image was computed using the camera and normalized by dividing the luminance surface by the maximum luminance to make the maximum luminance 1. The standard deviation was found to be 0.02 with a maximum and minimum luminance of 1 and 0.8 respectively after cutting 10 pixels from the edges of the registered image. The

76

Figure 5.15: The RGB images sent to the projector to determine the LAM.

standard deviation of the RGB image was 2.2. The reason for the low variation in projector lighting in the booth is a small of area of the image is now being used for the ROI. Improving the Projector Uniformity in the Viewing Booth Making the projector uniform is needed to provide accurate color capture from the printed image in the viewing booth. The same methodology of making the projector uniform that was explained in section 5.1.6 was applied to make the ROI uniform. The LAM was calculated based on the white image which means the projector displayed full white in the ROI of the viewing booth as shown in Fig. 5.14. Once the image was captured and registered, 10 pixels were removed from edges to ensure not to include edge pixels which might cause some errors and to reduce any registration errors. The LAM was then passed through ITF for the three RGB channels of the projector to find the corrected values of the RGB needed to be sent to the projector to make the luminance of the ROI as even as possible. Another method was to use the LAM calculated based on the green channel by sending the green image and using it for red and blue channels since the luminance behavior is almost the same for all channels. The green image sent to the projector can be seen in the middle image of Fig. 5.15. The other way is to calculate the LAM based on RGB channels individually by sending each of the images in Fig. 5.15. These images were sent to projector and their luminance surfaces were calculated using HDR techniques. The built in photometer in the camera was used to determine the right exposure for each image with ISO of 100 and aperture was set to 29 to achieve neglectable camera non-uniformity. For each image, 15 exposures were taken, 7 over exposed and 7 under exposed with one neutral exposure (Fig 5.15). The neutral exposures were found to be 2.5, 1.6, and 2 for red,

77
Table 5.2: The results of making a white image in the booth uniform using green channel, RGB channels, and full white.

Case Min Original 0.81 After Using Green 0.89 After Using RGB 0.89 After Using White 0.89

Max 1 1 1 1

Mean 0.93 0.95 0.94 0.96

Std 0.028 0.015 0.01 0.009

green, and blue channels respectively. Table 5.2 summarizes the results of each method. It can be seen from table 5.2, using the white surface to find the LAM and compensate for luminance using the white surface led to better results. Using the green channel only reduced the standard deviation by 46% whereas using the white surface reduced the standard deviation by 68% compared to 64% using the three channels. It can be concluded that using the white surface as a base to calculate the LAM and compensate for the luminance leads to better results similarly as in section 5.1.6. The reason is that, when using a single channel such as Green, the other two channels are not completely off. There is some light leakage which affects the luminance measurement. Using all three channels together gives a brighter image with all RGB channels on. The measured luminance represents more accurate results in this case, and compensates for the black offset as well. The small difference between using the white which made improvements of 68% and using the three channels separately 64% has the added advantage of taking one third of the time and led to a bit more accurate results. Moreover, compensating for the luminance leads to uniform RGB measurement from the camera. Next, it was required to check the RGB uniformity by measuring the RGB from the camera using the white before and after compensation. For each case, 5 images were taken and averaged in order to minimize the camera's noise sensitivity . Then, the image was registered and 20 pixels were cut from the edges since the compensated image was based on the original minus 10 pixels to compare both cases. Each image was then converted to gray scale and divide by 255 to normalize it. The calculated standard deviation as well as the maximum and minimum values are summarized in table 5.3 It can be seen from table 5.3 that the standard deviation was reduced by 65% (2.2 to

78
Table 5.3: The results of making white in the booth uniform in RGB camera space.

Case Before After

Min 147 143

Max 162 150

Mean 157 147

Std 2.2 0.78

Std Norm 0.008 0.003

0.78 or 0.008 to 0.003 on a normalized scale). In color modeling, this result makes a quite enormous amount of difference when RGB patches are captured by the camera and used by the ANN to create a reliable model to map between desired and reproduction color spaces. Determining the Viewing Booth Uniformity While having the viewing booth light on and the projector light off, it was important to check the uniformity of the light in the viewing booth for the same area used in the projector (ROI). The intensity of the viewing booth was set to half and the same matte paper was used in the same position as before in order to compare the results with uniform light projector. An image was captured using the camera in order to determine the average RGB values when using the viewing booth light with matte paper and the projector turned off. The camera settings were 0.4 second shutter speed with aperture of 29 and ISO equal to 100 which are the same as before, in order to be comparable. Five images were taken and averaged to reduce noise from the camera. Thus, registration was implemented on the averaged image in the same method as the projector so that the same area of the paper was compared. The standard deviation was found to be 0.03 on gray scaled image and divided by 255. In other words, on 255 scale, this standard deviation was found to be 8 with a mean of 177 (a maximum of 186 and minimum of 143). This means that 64.2% of the data are within 1778 which is an enormous difference between RGB values. Consequently, the viewing booth did not produce reliable results numerically nor visually in some cases. The luminance was also measured using HDR techniques for the same ROI so that it can be compared with the projector and the same paper in the same position. The resulted measured luminance can be seen in Fig. 5.16 and it is very obvious that the color is not uniform.

79

Figure 5.16: The luminance channel of the viewing booth Measured by the camera before compensation.

The luminance surface was normalized by dividing it by the maximum luminance so that minimum and maximum luminance are 0.55 and 1 respectively while the standard deviation was calculated and found to be 0.09. The next goal is to compensate the viewing booth light to make it even using the projector as it is described in section 5.2.4.

5.2.4

Methodology of Creating a Uniform Viewing Booth

As it was shown in section 5.2.3, the projector was made uniform in the booth on the white paper and it performs very well in terms of color consistency within its own ROI. However, the goal in this section is to use a hybrid system which uses the viewing booth light as the main light source and only some of the projector's light to compensate for uneven areas where there is lack of viewing booth light to make it even. This hybrid system does not exist in the printing and imaging industry and it is very useful since it makes it easier and more robust to investigate colors. This unique work has been done by the following steps:  Step One: The viewing booth was turned ON while having the projector display full black. The reason is that the projector emits some light when displaying black (this is called black offset). This black offset needed to be taken into consideration while compensating for the light in the viewing booth.

80

Figure 5.17: The luminance of the viewing booth with projector displaying black (Left) and the LAM needed for the compensation (Right).

 Step Two: The registration has been done before as in section 5.2.2. Then, the luminance of the ROI in the booth was accurately measured when the booth is displaying full black. The luminance was measured by the camera using HDR techniques by taking a total of 19 exposures with 0.4 second as the neutral exposure. The luminance was normalized by dividing it by its maximum luminance so that the maximum luminance will be equal to 1 after cutting 10 pixels around the edges. The luminance surface is shown in Fig 5.17.  Step Three: In this step, the goal is to keep the areas of luminance equal to 1 unchanged by sending black pixels to that area and sending more light to the area that has luminance less than 1 to compensate for it. Therefore, the LAM is calculated by subtracting 1 from the luminance surface. The resulted LAM is shown in Fig. 5.17  Step Four: The LAM is then used by the projectors' ITF to find the right RGB values needed for the projector to compensate the viewing booth light as it can be seen in Fig. 5.18. The LAM has minimum value of 0 (where the light has a maximum luminance of 1) and maximum value of 0.49 (where the lowest luminance occurs). Unlike, when only the projector was used, the LAM had a maximum values of 1. In this case, it is dependent on the viewing booth.  Step Five: The resulted image from the previous step is applied to fit within the ROI using the registration settings as it can be seen from Fig. 5.18 and sent to the projector to enhance the booth uniformity.

81

Figure 5.18: The image sent to the projector to improve the uniformity of the viewing booth. Table 5.4: The results of using the projector to enhance the viewing booth.

Case Min Before 0.56 After 0.66 Results

Max 0.73 0.73

Mean 0.67 0.71

Std 0.04 0.01

The uniformity was compared before and after the compensation by measuring the luminance of the ROI after cutting 20 pixels from around the edges. The standard deviation of the measured luminance was reduced from 0.09 to 0.04 which means a 55% improvement. To compare the RGB captured by the camera before and after the compensation, 5 images were taken using shutter speed of 0.4 along with ISO equal to 100 and aperture set to 29 to reduce the affect from the camera lens as much as possible. These images were averaged to reduce the camera noise sensitivity and were also registered to fit within ROI. After the registration, 20 pixels were cut from the edges and images were converted to gray scaled image and divided by 255 for normalization purposes. The results of before and after the compensation are summarized in Table 5.4. It can be seen from the results in table 5.4 that the standard deviation was reduced from 0.032 to 0.01, which means an improvement by 75% which is very important when it comes to capture the colors printed on paper in order to produce reliable results.

82 The above judgements were all based on white paper in the viewing booth to determine its uniformity. On the other hand, it is very important to determine how reliable the new hybrid system is when printed color images are viewed in the viewing booth. The TC9.18 chart shown in Fig. 3.1 was chosen because it contains a wide range of RGB colors. This test chart was printed using the same matte paper via the printer ICC profile that is made for this type of paper. The test chart was attached at the viewing booth in two positions. Pos1 on the left and Pos2 on the right. For each position, there is two cases: without compensation (Booth Only) and with compensation (Booth and Projector). Therefore, in total, there are four different cases as shown in Fig. 5.19. For each case of Fig. 5.19, 5 images were taken and averaged to reduce the camera noise. Then, each image was registered in order to extract the test chart image accurately. The MSE was calculated between case#1 and case#3 and it was found to be 26.34 in the RGB space. This MSE was also calculated between case#2 and case#4 and found to be 5.23 which is the compensated case. This means that using the projector to compensate for the viewing booth reduced the MSE within the ROI field of view by 80%. This is a very important achievement when it comes to measuring/capturing color as well as visual judgment of colors. To make the projector more like a natural light source rather than a digital display, the projector lens was purposely defocused so that the projected light on the paper is very smooth and actual pixels are not visible anymore. In this case, the pixels of the projected plain white image were not noticeable anymore because all the pixels were blended compared to the focused lens where it is clearly visible to see the pixels on the paper. The standard deviation in this case was found to be 0.003 which unchanged from the focused case. However, defocusing the projector had visually a big impact on how the printed image appears in the viewing booth under different lighting conditions. Subsequently, we were able to create a uniform light source with a very wide variety of colors using the implemented GUI. This can be used to simulate more variety of the viewing conditions in generating soft proofs.

83

Figure 5.19: The four cases of evaluating the uniformity performance of the hybrid system. Case#1:Pos1 with booth only (upper left), Case#2: Pos2 with booth only (upper right), Case#3: Pos1 with booth and projector to compensate (bottom left), and Case#4: Pos2 with booth and projector to compensate (bottom right).

5.3

Soft Proofing Using Hybrid Viewing Booth

84

As it was shown in previous experiments, different printed colors appear differently depending on their location in the viewing booth because of the non-uniform nature of the illumination in the viewing booth. A method of compensating for this issue was introduced and tested. Preliminary results appear very robust as described in section 5.2.4. In this experiment, the same type of paper used to create the model before the compensation in section 4.2 is used to create the model using the hybrid viewing booth. This paper is ultra premium photo paper made for fast drying, soft gloss to provide vivid lifelike images and is ideally made for photographs. This paper gives some reflections in some areas when it is printed and viewed in the viewing booth. Moreover, adding light from the projector adds more reflections. However, it was investigated by our eyes that the reflections are visible from different viewing angles and are less visible from angles of around 45 degrees. As a result, the camera position was changed so that the camera is looking at the viewing booth in a 45 degree as it can be seen from Fig. 5.20. The uniformity of hybrid system did not get affected with this type of paper while the camera was in 45 degree as it was shown in Fig. 5.12. A new test chart has been customized based on the TC9.18 but the black and white strips that isolated between the color patches were removed so that it does not introduce some errors for the mapping between the digital image and printed version. It was also made with slightly bigger patches in order to get bigger printed area of each color for more accurate measure of each color patch. This customized test chart is shown in Fig. 5.21.

5.3.1

HDR for Modeling

The customized test chart was designed to provide a good modeling between the original and predicted image of the printed image. This was printed using the Epson stylus photo 1400 with the custom ICC profile that was made, as explained in section 2.3.2. The printed image was placed in the hybrid viewing booth which provides a uniform lighting condition in order to accurately capture the printed test chart. The goal here is to use HDR to capture

85

Figure 5.20: The set up of the capturing the color test chart with the camera at 45 degrees looking at the viewing booth with the LCD projector to compensate for light.

Figure 5.21: The customized test chart.

86

Figure 5.22: 15 differently exposed images of the customized test chart starting from the overexposed image with shutter speed of 1/4 second (Left Top) to the underexposed image with a shutter speed of 1/100 second (Bottom right).

the true/real colors and build a model that can predict the appearance of the printed image before printing it. It has been shown in chapter 4 that HDR provides more realistic images and reliable color reproduction of the captured scene. The camera used was Canon EOS Rebel T1i which came with EF-S 18-55mm IS lens. The HDR image was generated by taking 15 (1/3 f-stop between each exposure) exposures while setting the aperture to 8 to reduce the spatial variation of the lens , ISO to 100 and the camera's neutral exposure of 1/20 seconds as shown in Fig. 5.22. These 15 exposures were merged into a single HDR image using Photoshop. The resulted image was processed using exposure and gamma setting (the recommended settings by Photoshop) in Photoshop and saved as a TIFF image in order to be acquired by the MATLAB code. Different number of exposures were also experimented and it provided a good HDR reproduction without a noticeable difference. Therefore, 15 exposures were taken in order to reduce the camera sensitivity noise by taking more image to get more accurate results.

87 The color management was taken into consideration in MATLAB in order to be able to display the HDR correctly in the same appearance as Photoshop. That was achieved in MATLAB by processing the image using the monitor ICC profile that was made as explained in 2.3.1. In order to establish the data for training, the captured image needed to be registered to the original digital image. This was achieved using the same registration techniques as in section 5.1.4, but by using the captured image as input image and the original digital test chart as the base image to establish the registration in which 95% cross correlation was achieved. The registered image can be seen in Fig. 5.23. After the registration, a mapping can be established between the HDR captured image in Fig. 5.23 and the original digital image shown in Fig. 5.21. To establish such a mapping, same preprocessing that was used in section 4.2.2 was employed in this experiment which resulted in 6531 RGB samples. To clarify the use of HDR verses LDR for the captured image, an LDR image was captured by the camera using the neutral setting which are aperture of 8, ISO of 100 and an exposure set to 1/20 seconds. The same registration as in the HDR case was used here and the resulted LDR registered image of the customized test chart can be seen in Fig. 5.24. Preprocessing was done on the registered image in order to obtain accurate data for training the ANN model. Therefore, two models were created using ANN, one built based on the HDR data and the other one built based on the LDR data. A comparison between the two cases is shown to support the reasoning behind using HDR over LDR. Training the HDR model is explained in the next section.

5.3.2

Training process for the HDR based model

The original digital RGB was shown in Fig. 5.25 and the new RGB of the captured HDR image based of the printed image is shown in Fig. 5.27. The goal is to train the ANN model based on the original RGB as an input and HDR RGB of the printed image as an output for the ANN model. The same methodology and network structure as in section 4.2.3 was used to train the ANN in this section but based on the new HDR data from the previous section.

88

Figure 5.23: The captured HDR image of the customized test chart after registration.

Figure 5.24: The captured LDR image of the customized test chart after registration.

89

Figure 5.25: The original RGB of test chart TC9.18.

The training data samples were 6531 samples for only 911 unique samples of the original digital RGB. 80% of the data was used for training the ANN which is 5224 samples and 20% was used for both validation and testing which means 653 samples for each. It required a short training time of 132 seconds which led to MSE on the testing data equals to 0.008 with a maximum error of 0.05 on the normalized data (which means 2 and 12 on the 255 RGB scale). A correlation measure between the ANN prediction and the actual target was calculated by performing linear regression. This linear regression and correlation measure was plotted in Fig. 5.28 for training, validation, and testing for all data. The correlation measure was more than 99.9% which is a very good generalization of the model. Fig. 5.29 shows the target versus the ANN prediction for 653 samples of the testing data. The printed test chart when measured by the instrument will results in the gamut shown in Fig. 5.30 which is uniformly compressed and very similar to the prediction by the ANN model based on HDR imaging techniques.

90

Figure 5.26: The printed RGB of Test Chart TC9.18 (viewing booth only).

Figure 5.27: The printed RGB of test chart TC9.18 (hybrid viewing booth).

91

Figure 5.28: The correlation measure of target vs. predicted by the ANN for training, validation, testing, and all data set.

92

Figure 5.29: The printed RGB of test chart predicted by the ANN.

Figure 5.30: The printed RGB of Test Chart TC9.18 (measured by i1iO)

5.4

Results and Discussion

93

After the ANN was trained, it was tested with the Lena image that was used before. Fig. 5.31 shows the original digital image and its printed version predicted by the ANN model. The judgement has to be made in reality by visually looking at the hard copy printed image and compare it to the predicted image on the calibrated monitor. It was concluded that the predicted image in this case provided more realistic results and similar appearance to the hard copy printed image compare to the prediction by the model that was explained in section 4.3. The reason is that this model was built based on HDR image capturing techniques with the printed test chart being viewed in the hybrid viewing booth which provides a uniform lighting. The hybrid viewing booth made a big difference in the resulting model. The colorchecker image was also tested as it can be seen from Fig. 5.32 which shows both the original digital image and its printed version predicted by the ANN model. This model provided reliable results that are better than the model explained in section 4.3 as the image appearance very different from the hard copy printed image. It can be concluded that the main reason of the achieved accurate and reliable model is the uniformity of the Hybrid viewing booth which provided a consistent environment for colors to be captured trustworthy. The predicted image of the printed colorcheker image was also compared visually with the hard copy printed image and it was noticed that the model provided good prediction but is not perfect. For instance, when the predicted version of the proposed system is compared with original printed image in the viewing booth, it is very noticeable that the purple sweater has a more closer appearance to what is looks like in viewing booth. However, when the predicted printed version in Photoshop is compared to it does not give a true color. The reason is that the model was built based on the test chart which contains only 911 unique color samples. Therefore, as future work, more color patches should be included with a bigger test chart in order to build a better model. The beauty of this work is that when more color patches are included, the process should not be affected because the model only requires an HDR of the test chart. Therefore, adding more color

94

Figure 5.31: The original digital Lena image (top) and the prediction of the printed version of the Lena image by the ANN model (bottom).

95

Figure 5.32: The original digital colorchecker image (top) and the prediction of the printed version of the colorchecker image by the ANN model(bottom).

96 patches will not be an issue unlike the case with printer profiling in which more color patches require more time to measure the patches. These results were compared to Photoshop and it was noticed that with some colors, this model provides better color appearance compared to the hard copy printed image, because Photoshop predicts the colors based on the custom ICC profile of the printer. As it was mentioned earlier, to make an ICC profile, someone needs to measure color patches of a printed test chart which is very time consuming. An ICC profile uses LUT to predict colors which has some interpolation error issues. The printed media has a smaller gamut than the display media. For this reason, the RGB values shown in Fig. 5.25 will undergo gamut compression during the printing process. However, the gamut compression in the hybrid viewing booth shown in Fig. 5.27 is uniformly compressed as compared with the printed RGB in normal viewing booth shown in Fig. 5.26. This nonuniform compression in the normal viewing booth is likely to be the major factor in the color distortion discussed in chapter 4. It is clear from these figures that the uniformly lit booth overcomes this problem.

Chapter 6 Conclusions and Future Work

T
6.1

HE focus of this thesis was to create an automated soft proofing system that delivers better robustness and color consistency compared to existing systems. In attempting

to automate soft proofing process, the uniformity of current viewing booths and how to compensate using LCD projectors was investigated.

Conclusions

The conclusions and contributions of this thesis are summarized as follows:  A novel method that compensates for the non-uniform illumination in the viewing booth was achieved by using an LCD projector. This led to uniform viewing booth conditions which makes it easier for soft proofing purposes, as the uniformity of the viewing was an issue in getting accurate soft proofs. It was also found that HDR capture of the printed image will give an accurate perceptual representation of what the printed image will look like in the viewing booth on a calibrated monitor. Thus, having an accurate uniform viewing booth was combined with a closed loop technique and the use of (HDR) imaging to generate a black box model that can simulate the printed appearance of a given digital image. Adaptive techniques such as ANN were used to create the black box model, using the camera as a measuring device.  It was found that a DLP projector can not work for this application. Instead, the older 97

98 LCD projector was deemed more appropriate as a controllable light source. In order to blend its pixels to make it act more like a light source, the projector was purposely defocused. Defocused projectors were tested and resulted in a smoothed appearance when a printed image was viewed. The uniformity was tested after defocusing the projector and it was still uniform.  It was concluded that creating the LAM for projector based on the spatial intensity of the white surface provides better uniformity compared with using green channel to create the LAM. The reason is that using all the RGB channels to create the white will reduce the artifacts coming from black offset when only one channel is used because one can not guarantee that the remaining two channels will not emit any light. So leakage will exist there. It was also found that using HDR to measure and create the LAM will lead to more accurate uniformity.  To the best of our knowledge, we are the first to use HDR to capture and represent the printed image which led to representations that appear more in sync with the human visual system for better reproduction compared with LDR.  A new method based on ANN to learn and model mappings between RGB and L*a*b* was established and compared with conventional ICC profiles. The results demonstrate a back propagation LM neural network algorithm with higher accuracy for non-training data set compared to the custom ICC profile.  Using the LCD projector will make it possible to recover the CRC for the camera under the same conditions where the luminance will be measured using HDR. This allows to more accurate results since the CRC recovery was made under the same conditions. To conclude, one amazing thing about soft proofing is the use of a monitor which has a bigger gamut that sometime can simulate colors more than an inkjek proofer, plus with the use of the HDR techniques will make the hard copy look like the reality in more accurate and automated way. All the work in the literature is about multi projection display and

99 we are the first to implement viewing booth compensation using HDR. We also calculated LAM based on the luminosity of the white surface which led to more accurate reproduction. The reason is that using the white surface will reduce the noise caused by black offset. To the best of our knowledge, we are the first to put forward a new robust and efficient method that can well resolve the issue of uneven illumination in the viewing booth and achieve a consistent luminance intensity when print is viewed in the viewing booth.

6.2

Future Work

There are many potential directions for future work that can come out of this thesis. Some of these aspects are summarized in the following points:

6.2.1

Towards custom illuminants for proofing

It was also found that having a viewing booth with different light sources other than D50 is also useful. Therefore, the projector was used to uniformly create any illumination using a GUI with RGB sliders. It was possible to create any color of light with variable intensity using this GUI. A GUI was created to allow the user to select any color with the RGB sliders. This GUI first displays the color before compensation, and when a key is pressed, the uniform version of the selected color will appear. As a result, by using this GUI, it was possible to create a uniform light source with a very wide range of color choices. This algorithm can be used to view and/or simulate any printed image in order to see the effect of using different lighting conditions on the appearance of the image. The user can specify bluish, reddish, or yellowish light and get a uniform light source of any color using this type of the viewing booth. An example of different lighting conditions using this technology is shown in Fig. 6.1. The utility of such a function could be used in simulating and generating special lighting conditions representation of the clients need (eg. viewing a menu at a nightclub).

100

Figure 6.1: The example of projector based evenly illuminated viewing booths from right to left are bluish, reddish, and yellowish lights.

6.2.2

Embedding Intensity changes within the proof

Soft proofing is used to verify the print jobs on the monitor. Despite the successful development and use of current soft proofing systems, they still fail to deliver the same degree of utility as a hard copy proofing, especially since they lack the appearance of different illumination intensities and levels [23]. In demonstrating through this thesis that the HDR capture of the image will give an accurate reproduction on the calibrated monitor then it would be very useful to create a soft proofing system that simulates the appearance of the printed image with varying intensity level to act like a virtual viewing booth. It is also possible to simulate the appearance of the printed image under a wide range of illuminations using the LCD projector to uniformly create different illuminations. Such a tool should be particularly useful in the printing industry. For instance, it would very useful to view the appearance of the advertisement banners in a sunny day versus cloudy day.

6.2.3

Other Extensions and Practical Improvements

 A viewing booth based projector can be made mobile in which using the projector as a light source that can be automatically adjusted using a camera according to the viewing conditions. The uniform light source could then be projected on the printed image to see how job would appear.  Since the HDR image can not be directly displayed on the monitor, then HDR image was processed in Photoshop using tone compression techniques called exposure and gamma. However, there exists another tone compression that is based on human vision

101 system such as iCAM06 which tends to provide even better perceptual reproduction [64, 65]. Using such techniques will improve the soft proofing model proposed in this thesis.  Since it was possible to accurately obtain uniform light, and supplement this by using an inexpensive camera, the system can be treated as scanner that can easily generate HDR images. In other words, it can be used as an HDR scanner. Moreover, this system can be also used to capture images accurately with different illuminations by using the implemented GUI. This functionality is not available in scanners.  To increase the luminosity of the projector, this can be done by blending two projectors to achieve more luminosity.  In future, using LCOS projection technology will make the system it even better because smoother and higher resolution and more pixels are available to blend in the viewing booth.  As mentioned in section 2.3.3, the uniformity of light source is an essential element for camera calibration. Therefore, the implemented robust photometric calibration method could be used in camera calibration since calibrating the camera itself requires uniform illumination. Typically, this process is done manually with multiple light sources, and can take hours to get adequate uniformity across the field of view. Automated calibration with a uniform source can eliminate the tedium of a manual approach. A potential application could be calibrating the camera using the implemented GUI for various illumination conditions which will create different ICC profiles for each lighting condition.

Bibliography
[1] J. Sundell, Colour proof quality verification, 2005. [2] A. Sharma, Understanding color management, 2004. [3] "Soft White proofing Paper, a guide Sept. to 2008, benefits best practices," 2011. Magazines [Online]. Canada, Available:

accessed:March

http://www.magazinescanada.ca/advertising/production/softproofing [4] M. Klaman, "Aspects on colour rendering, colour prediction and colour control in printed media," Ph.D. dissertation, Stockholm University, 2002. [5] G. Johnson and M. Fairchild, "Visual psychophysics and color appearance," Digital color imaging handbook, 2003. [6] S. Bianco, F. Gasparini, and R. Schettini, "Consensus-based framework for illuminant chromaticity estimation," Journal of Electronic Imaging, vol. 17, pp. 023 0131023 013 9, 2008. [7] M. Fairchild, Color appearance models, 2nd ed., 2005. [8] A. Majumder and R. Stevens, "LAM: Luminance attenuation map for photometric uniformity in projection based displays," in Proceedings of the ACM symposium on Virtual reality software and technology, 2002, pp. 147154. [9] A. Majumder, Z. He, H. Towles, and G. Welch, "Achieving color uniformity across multi-projector displays," in Proceedings of the conference on Visualization, 2000, pp. 117124. 102

103 [10] J. Morovic and E. Corporation, Color gamut mapping, 2008. [11] E. Reinhard, E. Khan, A. Aky uz, and G. Johnson, Color imaging: fundamentals and applications. AK Peters Ltd, 2008. [12] I. Vallinkoski, "The design and implementation of a color management application. Gamut mapping algorithm," Ph.D. dissertation, Helsinki University of Technology, 1998. [13] E. Giorgianni, T. Madden, and K. Spaulding, "Color management for digital imaging systems," Digital color imaging handbook, 2003. [14] D. Wallner, "Building ICC profiles춗he mechanics and engineering," 1998. [15] M. Nielsen and M. Stokes, "The creation of the sRGB ICC profile," in Proceedings IS&T/SID 6th Color Imaging Conference, 1998, pp. 253257. [16] J. King, "Why color management?" in Proceedings-SPIE The International Society for Optical Engineering, 2002, pp. 439445. [17] A. Sharma, M. Gouch, and D. Rughani, "Generation of an ICC profile from a proprietary style file: Color imaging science," The Journal of imaging science and technology, vol. 46, no. 1, pp. 2632, 2002. [18] A. Sharma, "Methodology for Evaluating the Quality of ICC ProfilesScanner, Monitor, and Printer," Journal of Imaging Science and Technology, vol. 50, pp. 469480, 2006. [19] N. Zhang, B. Ma, and W. Lan, "Next Generation Color Management Process Modeling for Digital Printing," in Industrial Informatics, 2006 IEEE International Conference on, 2006, pp. 932937. [20] H. Kang, "Color technology for electronic imaging devices," 1997. [21] R. Bala and G. Sharma, "Digital Color Imaging Handbook," 2003.

104 [22] H. Kipphan et al., Handbook of print media, 2001, vol. 1067. [23] M. Ben-Chorin and D. Eliav, "Multi-primary design of spectrally accurate displays," Journal of the SID, pp. 667677, 2007. [24] B. Chai, N. Liao, D. Zhao, and W. Yang, "Media-dependent color appearance modeling based on artificial neural networks," Color Research & Application, vol. 31, no. 3, pp. 218228, 2006. [25] C. Edge, "Correction techniques for soft proofing," Dec. 8 2009, uS Patent 7,629,983. [26] R. Patil, M. Fairchild, and G. Johnson, "3D Simulation of prints for improved soft proofing," in Proc. Twelfth Color Imaging Conference, 2004. [27] T. Ogino, Y. Yasumuro, and M. Fuyuki, "Shape Data Registration based on Structured Light Pattern Direction," Service Robotics and Mechatronics, pp. 223228, 2010. [28] M. Grossberg, H. Peri, S. Nayar, and P. Belhumeur, "Making one object look like another: Controlling appearance using a projector-camera system," in In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), vol. 1, 2004, pp. 452459. [29] M. Brennesholtz and E. Stupp, Projection displays, 2008. [30] J. Sampsell, "Digital micromirror device and its application to projection displays," Journal of Vacuum Science & Technology B: Microelectronics and Nanometer Structures, vol. 12, no. 6, pp. 32423246, 1994. [31] M. Douglass, "DMD reliability: a MEMS success story," in Proceedings of SPIE, vol. 4980, 2003, pp. 111. [32] S. Narasimhan, S. Koppal, and S. Yamazaki, "Temporal dithering of illumination for fast active vision," in European Conference on Computer Vision, vol. 4, 2008, pp. 830844. [33] J. Thomas and A. Bakke, "A colorimetric study of spatial uniformity in projection displays," Computational Color Imaging, pp. 160169, 2009.

105 [34] A. Majumder, "Properties of color variation across multi-projector displays," Proceedings of SID Eurodisplay, 2002. [35] A. Majumder and R. Stevens, "Color nonuniformity in projection-based displays: Analysis and solutions," IEEE Transactions on Visualization and Computer Graphics, pp. 177188, 2004. [36] R. Yang, A. Majumder, and M. Brown, "Camera based calibration techniques for seamless flexible multi-projector displays," in Applications of Computer Vision Workshop, Proceedings of European Conference in Computer Vision (ECCV), 2004. [37] E. Goldstein, Sensation and perception, 2009. [38] R. De Valois and K. De Valois, Spatial vision, 1990. [39] C. Lloyd, "Quantifying edge blend quality: Correlation with observed judgements," in Proceedings of Image Conference, 2002. [40] L. MacDonald and R. Luo, Colour imaging: vision and technology, 1999. [41] P. Debevec and J. Malik, "Recovering high dynamic range radiance maps from photographs," in In SIGGRAPH97, 2008, pp. 369378. [42] R. Lukac and K. Plataniotis, Color image processing: methods and applications, 2006. [43] C. Connolly and T. Fleiss, "A study of efficiency and accuracy in the transformation from RGB to CIELAB color space," IEEE Transactions on Image Processing, vol. 6, no. 7, pp. 10461048, 2002. [44] R. Berns and M. Shyu, "Colorimetric characterization of a desktop drum scanner using a spectral model," Journal of Electronic Imaging, vol. 4, no. 04, pp. 360372, 1995. [45] K. Asakawa and H. Sugiura, "High-precision color transformation system," IEEE Transactions on Consumer Electronics, vol. 41, no. 2, pp. 304312, 2002.

106 [46] M. Vrhel, "Approximation of color characterization MLUTS with artificial neural networks," in In: Proc. Int. Conf. Image Processing, 2003, pp. 465468. [47] S. Abet and G. Marcu, "A neural network approach for RGB to YMCK color conversion," in Proc. of the IEEE Region 10 9th Annual International Conference TENCON94, vol. 1, 1994, pp. 69. [48] C. Congjun and S. Jing, "Study on Color Space Conversion between CMYK and CIE L* a* b* Based on Generalized Regression Neural Network," in International Conference on Computer Science and Software Engineering, vol. 6, 2008, pp. 275277. [49] Z. Chuan and Z. Shi-Sheng, "Research on color space transformation model between RGB and L* a* b* based on BP neural network," in International Conference on Computer Science and Software Engineering, vol. 6, 2008, pp. 306308. [50] A. Sharma and P. Fleming, "Measuring the quality of ICC profiles and color management software," The Seybold Report, vol. 4, no. 20, pp. 1016, 2005. [51] V. V. F. M.-V. S. O. E. Perales, E. Chorro and V. de Gracia, "New method for comparing colour gamuts among printing technologies," The Imaging Science Journal, vol. 56, no. 3, pp. 145152, 2008. [52] R. Duda, P. Hart, and D. Stork, Pattern classification, 2nd ed., 2004. [53] N. Fdhal, M. Kyan, D. Androutsos, and A. Sharma, "Color Space Transformation from RGB to CIELAB Using Neural Networks," Advances in Multimedia Information Processing-PCM 2009, pp. 10111017, 2009. [54] E. Reinhard et al., High dynamic range imaging: acquisition, display, and image-based lighting, 2006. [55] M. Brown, A. Majumder, and R. Yang, "Camera-based calibration techniques for seamless multiprojector displays," IEEE Transactions on Visualization and Computer Graphics, pp. 193206, 2005.

107 [56] R. Juang and A. Majumder, "Photometric self-calibration of a projector-camera system," in Proc. of IEEE International Workshop on Projector-Camera Systems, 2007. [57] A. Raij, G. Gill, A. Majumder, H. Towles, and H. Fuchs, "Pixelflex2: A comprehensive, automatic, casually-aligned multi-projector display," in IEEE International Workshop on Projector-Camera Systems, 2003. [58] A. Majumder, "A practical framework to achieve perceptually seamless multi-projector displays," Ph.D. dissertation, University of North Carolina at Chapel Hill, 2003. [59] R. Raskar, J. van Baar, and J. Chai, "A low-cost projector mosaic with fast registration," in In Fifth International Conference on Computer Vision, 2002, pp. 161168. [60] R. Yang, D. Gotz, J. Hensley, H. Towles, and M. Brown, "Pixelflex: A reconfigurable multi-projector display system," in Proceedings of the conference on Visualization'01, 2001, pp. 167174. [61] M. Hereld, I. Judson, R. Stevens et al., "Dottytoto: A measurement engine for aligning multi-projector display systems," Argonne National Laboratory preprint ANL/MCSP958-0502, vol. 502, 2002. [62] Y. Sheng, T. Yapo, and B. Cutler, "Global illumination compensation for spatially augmented reality," in Computer Graphics Forum, vol. 29, no. 2, 2010, pp. 387396. [63] D. Reid, "Color viewing booths provide critical color evaluation environment," Digital Output Magazine, Tech. Rep., March 2002. [64] M. Fairchild and G. Johnson, "The iCAM framework for image appearance, image differences, and image quality," Journal of Electronic Imaging, vol. 13, no. 1, pp. 126 138, 2004. [65] J. Kuang, G. Johnson, and M. Fairchild, "iCAM06: A refined image appearance model for HDR image rendering," Journal of Visual Communication and Image Representation, vol. 18, no. 5, pp. 406414, 2007.

