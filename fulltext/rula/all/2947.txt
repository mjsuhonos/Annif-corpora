Radiometric Correction and Normalization of Airborne Lidar Intensity Data for Land Cover Classification

by

Wai Yeung Yan B.Sc.(Hons), The Hong Kong Polytechnic University, Hong Kong, 2002 M.Sc., Middlesex University, London, U.K., 2006

A thesis presented to Ryerson University

in partial fulfillment of the requirements for the degree of Doctor of Philosophy in the Program of Civil Engineering (Geomatics Engineering)

Toronto, Ontario, Canada, 2012 ©Wai Yeung Yan 2012

I hereby declare that I am the sole author of this dissertation. This is a true copy of the dissertation, including any required final revisions, as accepted by my examiners. I authorize Ryerson University to lend this dissertation to other institutions or individuals for the purpose of scholarly research.

I further authorize Ryerson University to reproduce this dissertation by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

I understand that my dissertation may be made electronically available to the public.

iii

Radiometric Correction and Normalization of Airborne Lidar Intensity Data for Land Cover Classification Doctor of Philosophy 2012 Wai Yeung Yan Civil Engineering (Geomatics Engineering) Ryerson University

Abstract
Airborne Light Detection And Ranging (LiDAR) has been used extensively to model the topography of the Earth surface by emitting laser pulses and measuring the distance (range) between the LiDAR sensor and the illuminated object as well as the backscattered laser energy (intensity). Nowadays, airborne LiDAR systems operating in near-infrared spectrum are also gaining a high level of interest for surface classification and object recognition. Nevertheless, due to the system- and environmental- induced distortions, airborne LiDAR intensity data requires certain correction and normalization schemes to maximize the benefits from the collected data. The first part of the thesis presents a correction model for airborne LiDAR intensity data based on the radar (range) equation. To fill the gap in current research, the thesis introduces a set of correction parameters considering the attenuation due to atmospheric absorption and scattering which have not been previously considered. The thesis further derives a set of equations to compute the laser incidence angle based on the LiDAR data point cloud and GPS trajectory. In the second part of the thesis, a normalization model is proposed to adjust the radiometric misalignment amongst overlapping airborne LiDAR intensity data. The model is built upon the use of a Gaussian mixture modeling technique for fitting the intensity histogram which can then be partitioned into several sub-histograms. Finally, sub-histogram equalization is applied to calibrate the LiDAR intensity data. To evaluate the effects of the proposed methods, a LiDAR dataset covering an urban area with three different scans was used for experimental testing. The results showed that the coefficient of variance of five land cover features were sigv

nificantly reduced by 70% to 82% and 33% to 80% after radiometric correction and radiometric normalization, respectively. Land cover classification was conducted on the LiDAR intensity data where accuracy improvements of up to 15% and 16.5% were found on the classification results using the radiometrically corrected intensity data, and radiometrically corrected and normalized intensity data, respectively. With the improved land cover homogeneity and classification accuracy, the effectiveness of the proposed approach was demonstrated. The outcome of the thesis fills the gap in existing airborne LiDAR research and paves the way for the future development of LiDAR data processing system.

vi

Acknowledgements
Completing this thesis is a big milestone I would never have achieved without the support and encouragement from all the individuals and parties mentioned in this section. I've started to note everything that I would like to put here since the end of my 2nd year study. I am so thankful for all of you going along with me during the last four years, which were not easy for me. This thesis somehow had its roots planted in 2002 when I first met my current supervisor Dr. Ahmed Shaker. Dr. Shaker is an extremely nice and decent person with whom to share and work with. With his encouragement and guidance, we set up a kind of informal collaboration before he left HKPolyU in 2006, and I was so glad he became a faculty member at a university (that I never heard about) in Canada after one year. Through a number of family meetings, long distance calls and struggles, I finally came to Ryerson and became his first Ph.D. student in Fall 2008. Over the last couple of years, though we went through the crunch time as new members at Ryerson, we've gradually made some achievements which were unbelievable to both of us. Dr. Shaker gave me advice not only on the study, but also regarding everything that he found which was important to me. I couldn't have asked for a better role model in my life since he is a person of excellent character, no matter being as a professor, mentor, friend, father, husband, or son. I deeply appreciate his physical and spiritual support particularly allowing me to travel back to Hong Kong during each break and for my grandmother's funeral. I also extend my appreciation to Naglaa, Basem, Omar, and the little new member Zain, for taking good care of me as a family member here. I am so indebted to have a number of senior professors in the department who gave me guidance throughout the study and shared the joy of my research life. Without questioning, the early joint research with Prof. Said Easa gradually set up a foundation which turned into the base of this thesis. Apart from his guidance in research, I appreciate his regards and praises very much, all of which made me feel warmly accepted at school. I am so fortunate to have Prof. Ahmed El-Rabbany as the graduate program director during my last two years at Ryerson. He made significant changes in the graduate program for students' great benefit. His door was open for consultation almost every day, which was understandably quite demanding for him. The courses he offered were not easy (one of them I took two times), but all these lectures opened my eyes to look at a research problem in frequency domain which inspired part of this Ph.D. work. I do also appreciate Prof. David Coleman (Department of Geodesy and Geomatics Engineering, University of New Brunswick), Prof. Sri Krishnan (Department of Electrical and Computer Engineering, Ryerson University) and Prof. Mike Chapman for being in the examination committee; this thesis is in a much better shape as a result of their vii

expertise, for which I am grateful. I have three young professors in the department who always shared their philosophy on research and life in the third floor of Monetary Times. I am a fan of Dr. Arnold Yuan since he is a dedicated researcher who always goes down to the Earth. I appreciate Dr. Jinyuan Liu's sharing the story of his youth and university studies, which inspired me I should not be afraid of any change. An ad-hoc research project with Dr. Darko Joksimovic in hydrologic modeling has widened my research area out of remote sensing. His way of guidance and chatting makes anyone feel comfortable, for sure, with his British sense of humor. I owe a number of thanks to the following individuals at Ryerson who lent me a hand throughout the study. I would like to thank Ms. Cathy Faye and Ms. Galina Maliouta from the Yates School of Graduate Studies who kindly revised my application package of scholarship and funding proposal. Thanks also goes to the former and current graduate program administrator, Ms. Mary Neelands and Ms. Rachel Trozzolo, whose instances of help are too numerous to list. I am thankful to Ms. Maria Medeiros and Ms. Xue-Li Robinson from the Faculty of Engineering, Science and Architecture for their help and guidance regarding those complicated research-related administrative process. Though I never met Dr. Jason V. Lassaline from the Department of Aerospace Engineering, I would like to thank him for creating the great Ryerson
A L TEX thesis template and sharing it on his website for academic use.

I am so fortunate to participate in the GEOIDE collaborative research project which was led by Prof. Ayman Habib and Dr. Derek Litchi from the University of Calgary (U of C). I would like to thank them for providing the LiDAR data through their connections as well as their constructive comments on the research work. I do also thank Ana Paula B. Kersting and Sherif Ibrahim, who were Ph.D. students from U of C, for the collaborative work in data processing and preparation of research manuscripts, presentation and conference poster. The LiDAR data presented in this thesis was provided by McElhanney Consulting Services Ltd., which is also acknowledged. I always believe it is not easy to get to know true friends when we are grown up. I am so glad to have Houda Bechraoui and Akram Afifi at Ryerson who are my good friends indeed. Houda's short exchange period in the department injected magical energy towards the work and created many fun moments. Still, her French-tone distance calls and emails always come at the right time when I need her. Akram and I have similar characters and that's why we share almost the same view on study, life, family, politics, humanity, food and sports. We helped and "timmed" each other and we went through lots of tough time during the study. I deeply appreciate his speech towards low profile which cleaned my mind before I got mad. I also thank Robin Luong who acted like my elder brother in the school particularly his concerns and special cares during the dark days. I have to specifically mention Dr. Ernest Wong for many illuminating discussions viii

on the philosophy of research. I am glad to know a diverse range of graduate students from different parts of the world, in particular Zheng Niu, Nagwa El-Ashmawy, Zhongsheng Chen, Kamil Fasial, Shahryar Rafiei, Mohammed Elsobeiey, Hassan Ibrahim, Lisa Kadoury, Amir Poshnejad, Amirreza Ghaemmaghami, Abdullah Albourae, Prathees Mahendrarajah, Valeriy Bekmuradov and Amit Joshi. I am very thankful to have a few close friends who really care about me and my family. Mostly, we recognized and grew up together in school, and their support and care from Hong Kong were indispensable to complete this study. They are M.H. Kwan, M.K. & Tammy Tong, Andy Chung, Rebecca Tse, Larry & Karan Kwok, Frances Wan, Kevin Kwan, Weibao Zou, Daniel Lo, Yat-Lun Ngai, Mandy Tang and Stanley Leung. I have to specially mention Donald Choi for his regular calls, books, accessories and wit which helped a lot to relieve my home sick; Ida Cheung for being like a psychotherapist who listened to everything from me; Fun Tang for letting me share everything whenever I wanted to talk; Ben Fan for his regular emails, updates and the delightful BGY trips. I have had an unforgettable time while working in the Information Systems and Land Supply Section, Planning Department (PlanD), the Government of Hong Kong Special Administrative Region before my Ph.D. study. I am gratitude to my seniors Silas Liu and Ernest Fung who gave me the chance to work on a number of huge Government projects which added valuable experience to my career. Ernest's tough tasks have progressively trained me to be an all-around employee; his heartfelt encouragement towards doctoral study was one of the reasons that I left the team and came to Canada. For sure, I still remember the joyful days with my colleagues Brian Lau, Patrick Lau, Stanley Tsoi, T.M. Kong, Chris Chan, Sam Chan, W.K. Leung, Esther Cheung, Sophia Yu, H.Y. Yeung and Eddie Lee in these three years. Last but not least, I would like to acknowledge PlanD for allowing me to publish the data and results for the research that I partially did in PlanD regarding image classification. The education from the schools that I attended created the knowledge foundation which formed the basis of this thesis. I would like to especially thank the teachers, nuns and priests for their enthusiasm in teaching and ethical education from Tak Sun Primary School and Tang King Po School. I would like to thank Prof. Esmond Mok who was the first to guide me to do research at the HKPolyU. My master thesis instructor, Dr. Beta Yip from the University of Hong Kong, must also be acknowledged for many constructive discussions on research. The research work was financially supported by the Ryerson ATOP Award, Ryerson Graduate Award, Ryerson International Student Scholarship, Ontario Graduate Scholarship in Science and Technology (OGSST), Ontario Graduate Scholarship (OGS), Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery Grant, GEOIDE Canadian Network of Excellence Strategic Investment Initiative (SII) project SII P-IV #72 and Canadian ix

Remote Sensing Doctoral Scholarship. Indirect financial support was provided through the student competitions organized by the Association of Ontario Land Surveyor (AOLS), Ontario Association for Impact Assessment (OAIA), Joint Canadian Institute of Transportation Engineers (Hamilton, Southwestern Ontario and Toronto) Chapters, GEOIDE Annual Scientific Conference, Canadian Association of Geographers - Ontario Division (CAGONT) and Canadian Remote Sensing Society. In particular, I would like to specifically mention Ms. Maureen V. Mountjoy from AOLS whose enthusiasm and effort in organizing and supporting different events for promoting geomatics education, from which I benefited. The core of the thesis was built by the continued moral support from my family thousands of miles away. I wish to thank my family in Hong Kong for providing a loving environment in which I can focus on my study. I fully understand it was not easy for all of them to take care of my grandmother when I was not at home. I especially thank my mother and sister for their selflessness and sacrifices in travelling between home and hospital almost everyday. I am grateful to my uncle and aunt who provided the home stay in my first year study and lots of gatherings, lunches and dinners with my aunt's sister's and brother's family here. Lastly, I want to say something about my grandmother. My grandmother is a lovely, honest, courteous, brave and devoted family lady who suffered from feudality, wars, separation, poverty and hunger in her early life. Though she was uneducated, she had the purest heart and the greatest passion towards the people nearby. She was always thankful for what she had and she never cheated to get better. And, she certainly never complained. She was the roof of the family supporting through her selfless dedication. She raised me with my brother and sister and she guided us on the beautiful way to be a good human being. She took good care of us when we got sick and she never blamed us when we did something inappropriate. Just right after I started my Ph.D., she was diagnosed with metastatic carcinoma of colon. Still, she strongly encouraged me to stay in Canada and took the opportunity for the foreign study as simply she knew it would be something good for me. In the first two years of study, I did my best to fly back during break, and we had quality family times with amazing cakes for birthdays. The last time I saw her was June, and I accompanied her most of the time in the hospital and the elderly home. She kept remembering those bad things happened in the old days and telling us what we should do after she left. After a long battle with cancer, she passed away peacefully on August 6, 2010 at the age of 94 with my family at the bedside, except me. This thesis is humbly dedicated to her. Wai Yeung Yan September 10th , 2012

x

Dedication
In loving memory of my grandmother (1916 to 2010)

xi

Contents
Abstract Acknowledgements Dedication 1 Introduction 1.1 1.2 1.3 Research Motivation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Research Objectives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Organization of the Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . v vii xi 1 1 5 6 7 7 7 9 10 12 14 16 17 19 21 21 21 22 26 28

2 Literature Review 2.1 Airborne LiDAR System . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.1.1 2.1.2 2.1.3 2.1.4 2.1.5 2.2 2.3 2.4 Historical Development . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Laser Construction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Laser Ranging and Scanning . . . . . . . . . . . . . . . . . . . . . . . . . . Positioning and Orientation . . . . . . . . . . . . . . . . . . . . . . . . . . . LiDAR Intensity Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Land Cover Classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Radiometric Calibration, Correction and Normalization . . . . . . . . . . . . . . . Discussion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

3 Radiometric Correction 3.1 Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.1.1 3.1.2 3.1.3 3.1.4 Overall Workflow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Computation of Incidence Angle . . . . . . . . . . . . . . . . . . . . . . . . Atmospheric Correction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Radiometric Correction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiii

3.2

Experimental Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.2.1 3.2.2 Study Area and Dataset . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Design of Experiment and Evaluation . . . . . . . . . . . . . . . . . . . . . Visual Inspection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Coefficient of Variation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

29 29 33 36 36 36 43 45 45 47 47 48 50 51 53 60 60 62 65 67 67 68 70 70 71 71 72 73 73 75 82 85 85 87

3.3

Results and Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 3.3.1 3.3.2

3.4

Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4 Radiometric Normalization 4.1 4.2 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.2.1 4.2.2 4.2.3 4.2.4 4.3 4.4 Overall Workflow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Gaussian Mixture Model . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Histogram Partition . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Sub-histogram Matching . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Experimental Testing . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Results and Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.4.1 4.4.2 Visual Inspection . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Coefficient of Variation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

4.5

Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

5 Land Cover Classification 5.1 5.2 5.3 Overall Workflow . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . LiDAR datasets . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Land Cover Classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.3.1 5.3.2 5.3.3 5.3.4 5.4 5.4.1 5.4.2 5.5 Design of Land Cover Classes . . . . . . . . . . . . . . . . . . . . . . . . . . Training Data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Classification Technique . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Accuracy Assessment . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Effect of Radiometric Correction on Land Cover Classification . . . . . . Effect of Radiometric Normalization on Land Cover Classification . . . .

Results and Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

Chapter Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

6 Conclusions and Future Work 6.1 6.2 Conclusions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Future Work . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xiv

References

119

xv

List of Tables
3.1 3.2 3.3 3.4 4.1 4.2 4.3 5.1 5.2 5.3 5.4 5.5 5.6 Airborne LiDAR system settings (left) and data specification (right) . . . . . . . Data Configuration of the three LiDAR data strips . . . . . . . . . . . . . . . . . Coefficient of variation of five land cover features generated from the original and corrected intensity data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Percentage change in coefficient of variation . . . . . . . . . . . . . . . . . . . . . . Computed intersection points for all the datasets . . . . . . . . . . . . . . . . . . . Coefficient of variation of five land cover features generated from the OI, ONI and RCNI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Percentage change in coefficient of variation . . . . . . . . . . . . . . . . . . . . . . Design of the land cover classes for experimental testing . . . . . . . . . . . . . . Overall accuracy of land cover classification . . . . . . . . . . . . . . . . . . . . . . Overall accuracy of land cover classification in sub-area 1 . . . . . . . . . . . . . Overall accuracy of land cover classification in sub-area 2 . . . . . . . . . . . . . Overall accuracy of land cover classification in sub-area 3 . . . . . . . . . . . . . Overall accuracy of land cover classification in sub-area 4 . . . . . . . . . . . . . 63 65 70 73 76 78 79 81 40 42 58 31 31

xvii

List of Figures
1.1 1.2 An example of land cover GIS data available at Canadian GeoBase . . . . . . . An example of aerial photo vs airborne LiDAR data (a) High resolution aerial photo with effects of shadows and tilted buildings and (b) Airborne LiDAR derived terrain surface fused with intensity image . . . . . . . . . . . . . . . . . . 1.3 2.1 2.2 2.3 2.4 2.5 3.1 3.2 3.3 3.4 3.5 3.6 3.7 3.8 3.9 Spectral reflectance of different materials across visible to infrared wavelengths Schematic diagram of airborne LiDAR system . . . . . . . . . . . . . . . . . . . . Schematic diagram of a typical laser with three components . . . . . . . . . . . . Illustration of airborne laser scanning . . . . . . . . . . . . . . . . . . . . . . . . . LiDAR system configuration and the positioning and orientation systems . . . . Illustration of the laser pulse return signal and the recorded signal strength . . Overall workflow for radiometric correction . . . . . . . . . . . . . . . . . . . . . . Illustration of the geometric relationship between the airborne LiDAR system (L) and the illuminated object (P ) . . . . . . . . . . . . . . . . . . . . . . . . . . . Study area in the British Columbia Institute of Technology, Vancouver, B.C., Canada . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2D view of the airborne LiDAR data . . . . . . . . . . . . . . . . . . . . . . . . . . 3D view of the airborne LiDAR data . . . . . . . . . . . . . . . . . . . . . . . . . . Distribution of homogeneous sample areas for computing the coefficient of variation in (a) data strip 1, (b) data strip 2 and (c) data strip 3 . . . . . . . . . . . Airborne LiDAR intensity images (data strip 1) before and after radiometric correction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Airborne LiDAR intensity images (data strip 2) before and after radiometric correction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Airborne LiDAR intensity images (data strip 3) before and after radiometric correction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . xix 39 38 37 35 30 32 33 23 4 5 8 9 11 13 15 22 2

3.10 Coefficient of variation of five land cover features generated from the original and corrected intensity data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.1 4.2 4.3 4.4 4.5 4.6 4.7 4.8 4.9 Result of combining intensity data acquired from two overlapping scans . . . . . Overall workflow for radiometric normalization . . . . . . . . . . . . . . . . . . . . Distribution of polygons for generating intensity histograms in the overlapping regions of LiDAR data strips . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 53 54 55 56 57 57 58 59 60 60 61 62 62 62 64 68 Intensity histograms generated using polygons located at the overlapping region of LiDAR data strips 1 and 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Intensity histograms generated using polygons located at the overlapping region of LiDAR data strips 2 and 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Statistics of GMM generated from the OI and RCI intensity histograms generated from the LiDAR data strips 1 and 2 . . . . . . . . . . . . . . . . . . . . . . . . . . Statistics of GMM generated from the OI and RCI intensity histograms generated from the LiDAR data strips 2 and 3 . . . . . . . . . . . . . . . . . . . . . . . . . . Fitted Gaussian components in the OI and RCI intensity histograms generated from LiDAR data strips 1 and 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.10 Fitted Gaussian components in the OI and RCI intensity histograms generated from LiDAR data strips 2 and 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.11 Histogram equalization of (a) data strips 1 and 2 and (b) data strips 2 and 3 . . 4.12 (a) Aerial Photo, (b) OI, (c) ONI and (d) RCNI in an area located at the overlapping region of LiDAR data strips 1 and 2 . . . . . . . . . . . . . . . . . . . . . 4.13 (a) Aerial Photo, (b) OI, (c) ONI and (d) RCNI in an area located at the overlapping region of LiDAR data strips 1 and 2 . . . . . . . . . . . . . . . . . . . . . 4.14 Effects of radiometric correction on the same roof surface with opposite inclined orientation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4.15 (a) Aerial Photo, (b) OI, (c) ONI and (d) RCNI in an area located at the overlapping region of LiDAR data strips 2 and 3 . . . . . . . . . . . . . . . . . . . . . 4.16 (a) Aerial Photo, (b) OI, (c) ONI and (d) RCNI in an area located at the overlapping region of LiDAR data strips 2 and 3 . . . . . . . . . . . . . . . . . . . . . 4.17 Distribution of land cover samples for computing the coefficient of variation . . 4.18 Coefficient of variation of five land cover features generated from the OI, ONI and RCNI . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 5.1 Overall workflow for land cover classification . . . . . . . . . . . . . . . . . . . . . xx 41 46 47

An example of GMM and sub-histogram matching from LiDAR data strip A to B 52

5.2 5.3 5.4 5.5 5.6 5.7 5.8 5.9

(a) Aerial photo and (b) shaded DEM generated from the LiDAR data in the 1st case . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . (a) to (d) Aerial photo of sub-areas 1 to 4, (e) to (h) Shaded DEM generated from the LiDAR data of sub-areas 1 to 4 in the 2nd case . . . . . . . . . . . . . . Accuracy improvement of land cover classification results using radiometrically corrected intensity data . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . Kappa statistics of land cover classes . . . . . . . . . . . . . . . . . . . . . . . . . . Kappa statistics of land cover classes in sub-area 1 . . . . . . . . . . . . . . . . . Kappa statistics of land cover classes in sub-area 2 . . . . . . . . . . . . . . . . . Kappa statistics of land cover classes in sub-area 3 . . . . . . . . . . . . . . . . . Kappa statistics of land cover classes in sub-area 4 . . . . . . . . . . . . . . . . . 74 74 76 78 80 81 94 95 96 97 98 99 69 69

B.1 Land cover classification results using OI and five RCI data: 2-classes scenario . B.2 Land cover classification results using OI and five RCI data: 3-classes scenario . B.3 Land cover classification results using OI and five RCI data: 4-classes scenario . B.4 Land cover classification results using OI and five RCI data: 5-classes scenario . B.5 Land cover classification results in sub-area 1 . . . . . . . . . . . . . . . . . . . . . B.6 Land cover classification results in sub-area 2 . . . . . . . . . . . . . . . . . . . . .

B.7 Land cover classification results in sub-area 3 . . . . . . . . . . . . . . . . . . . . . 100 B.8 Land cover classification results in sub-area 4 . . . . . . . . . . . . . . . . . . . . . 101

xxi

List of Appendices
A Glossary of Acronyms B Land Cover Classification Results 91 93

xxiii

Chapter 1

Introduction
1.1 Research Motivation

Land cover is defined as the physical composition and characteristics of land elements on the Earth surface (Cihlar, 2000). Since distribution of land cover has significant impact on the climate and environment, mapping the land cover patterns from global, regional, to local scales are important for scientists and authorities to yield better monitoring of the changing world. The Climate Research Committee of the National Research Council (2005) stressed that distribution of land cover has pronounced impact on the Earth's radiation balancing since any changes in land cover would affect the evaporation, transpiration and heat flux on the ground surface. For instance, tree canopies absorb solar radiation resulting in a reduction of land surface temperature on the ground. On the other hand, increase of impervious land cover in urban area (e.g., asphalt, concrete, paving stones, etc.) prevents infiltration of groundwater which may cause potential floods. Therefore, precise monitoring of land cover becomes indispensable for decision makers in dealing with public policy planning and Earth resources management. Satellite remote sensing has been demonstrated as an efficient tool to acquire the Earth's topography for a large spatial extent. Remote sensing sensors record the spectral reflectance of different land cover features from visible to infrared wavelength, and from moderate to very high spatial resolution. Since the launch of Landsat Multispectral Scanner System (or Landsat 1) in 1972, the first Earth observation remote sensing system, scientists have extensively explored the use of these satellite images to derive land cover patterns by different computer-aided processing techniques. Pattern classification techniques are commonly used to find out the land cover patterns based on the spectral signatures from the remote sensing images. Currently, national and international agencies have successfully created land cover classification systems and land cover maps at national scale, for instance, United States Geological Survey's (USGS) Global Land 1

CHAPTER 1. INTRODUCTION

2

Cover Characteristics Database 1 , European Environmental Agency's (EEA) Coordination of Information on the Environment (CORINE)2 , European Commission's Joint Research Centres GLC20003 , Canadian Council on Geomatics and Natural Resources Canada's GeoBase4 (see Fig. 1.1), etc. These regional/global land cover maps were produced from the satellite remote sensing data such as AVHRR (Loveland et al., 2000), MODIS (Friedl, 2002), Landsat (Tucker et al., 2004) and SPOT (Bartholom´ e and Belward, 2005). In addition, hierarchical land cover/use classification systems were established and reviewed by national agencies including USGS (Anderson et al., 1976) and United Nation (UN) / Food and Agriculture Organization (FAO) (Gregorio and Jansen, 2000).
540000
4960000

580000

620000

660000

700000
4960000

Water Barren Land

Georgian Bay
4920000 4920000

Lake Simcoe
Barrie Peterborough

Exposed Land Development Land Shrubland Wetland Grassland
4880000

4880000

Newmarket Oshawa

Cropland Coniferous Forest Mixed Woodland

4840000

4840000

Toronto

Guelph Waterloo
4800000

Lake Ontario
4800000

Hamilton Brantford
540000 580000 620000

µ
0 5 10 20 30 40 50 km

Niagara Falls
660000 700000

 

Figure 1.1: An example of land cover GIS data available at Canadian GeoBase

1 2

http://edc2.usgs.gov/glcc/glcc.php http://www.eea.europa.eu/publications/COR0-landcover 3 http://bioval.jrc.ec.europa.eu/products/glc2000/glc2000.php 4 http://www.geobase.ca

2

3

CHAPTER 1. INTRODUCTION The demand on land cover maps at finer scale, especially in urban areas, was raised with

evidence by numerous biophysical and socio-economic studies in urban heat island (Streutker, 2002; Streutker 2003; Tran et al., 2006; Liu and Weng, 2008; Zhang and Wang, 2008; Liu and Weng, 2009; Nichol, 2009; Rajasekar and Weng, 2009; Buyantuyev and Wu, 2010; Onishi et al., 2010; Zhou and Wang, 2011; Li et al., 2011; Weng et al., 2011; Chen et al., 2012; Mitraka et al., 2012), urban sprawl pattern (Yeh and Li, 2001; Epstein et al., 2002; Herold et al., 2003; Sudhira et al., 2004; Liu and Zhou, 2005; Zeng et al., 2005; Ji et al., 2006; Sun et al., 2007; Tian et al., 2007; Xu et al., 2007; Yu and Ng, 2007; Durieux et al., 2008; Jat et al., 2008; Bhatta, 2009; Bhatta et al., 2010a, 2010b; Rahman et al., 2011a; Kumar et al., 2011; Tewolde et al., 2011), urban environmental quality (Nichol and Wong, 2005; Pauleit et al., 2005; Nichol et al., 2006; Li and Weng, 2007; Nichol and Wong, 2009; Liang and Weng, 2011; Rahman et al., 2011b), urban rainfall-runoff modeling (Van Der Sande et al., 2003; Thanapura et al., 2007; Chormanski et al., 2008; Han and Burian 2009; Ravagnani et al., 2009; Berezowski et al., 2012), urban anthropogenic heat (Kato and Yamaguchi, 2005 and 2007; Xu et al., 2008; Weng, 2009; Zhou et al., 2012), and urban air pollution (Weng and Yang, 2006; Xian, 2007; Jiang et al., 2008; Chattopadhyay et al., 2010; Superczynski and Christopher, 2011). Very high spatial resolution optical satellite sensors, such as GeoEye and Worldview, now provide less than half-meter pixel resolution in the acquired remote sensing images. Theoretically, users can derive larger scale of land cover maps from these high resolution satellite images. Nevertheless, the problem of between-class spectral confusion and within-class spectral variation in high spatial resolution imagery would degrade the separabilities amongst different land cover features. Though intelligent image segmentation and object-based classification techniques have been proposed to replace pixel-based classification to deal with these data (Benz et al., 2004; Walter, 2004; Carleer et al., 2005; Yu et al., 2006; Zhou and Troy, 2008; Blaschke, 2010; Pu et al., 2011), the effects of shadowing and relief displacement still pose considerable challenges in the derived products (Myeong et al., 2001; Dare, 2005; Zhou et al., 2009), see Fig. 1.2(a). A survey conducted by Wilkinson (2005) addressed this issue by studying 574 classification experiments from 138 scientific papers over the past fifteen years. Surprisingly, the development of remote sensing image classification techniques did not show a significant upward trend in terms of the overall accuracy in the last two decades. With respect to the demand of land cover maps at finer scales, one of the ways forward is to change the research direction from algorithmic development into multi-sensor data fusion (Benediktsson et al., 2007; Zhang, 2010). That need thus inspires this thesis research which investigates the use of topographic airborne LiDAR intensity data for land cover classification. Airborne LiDAR is a laser profiling and scanning system for bathymetric and topographic applications, which emerged commercially in mid-1990s. With the aid of direct geo-referencing 3

CHAPTER 1. INTRODUCTION

4

technique, the laser scanning equipment installed in the aircraft collects a cloud of laser range measurements for calculating the 3D coordinates (xyz ) of the survey area. In contrast to the 2D planimetric remote sensing data, the explicit LiDAR data point cloud thus describes the 3D topographic profile of the Earth surface. Other benefits of airborne LiDAR include no effects from relief displacement, penetration of tree canopy, and insensitivity to light conditions. All these merits have promoted the proliferation of airborne LiDAR system. Recently, airborne LiDAR technology is being deployed in commercial markets rapidly (Cary and Associates, 2009), the technique has been effectively used for generating digital terrain models, construction of digital 3D buildings, natural hazards assessment and deriving forestry parameters, etc.

(a)

(b)

Figure 1.2: An example of aerial photo vs airborne LiDAR data (a) High resolution aerial photo with effects of shadows and tilted buildings and (b) Airborne LiDAR derived terrain surface fused with intensity image In addition to the geometric information (xyz ), airborne LiDAR sensors are capable of recording intensity (I ) which is based on the measurement of laser energy backscattered from the illuminated object. An example of LiDAR intensity image is shown in Fig. 1.2(b) compared to the aerial photo in Fig. 1.2(a). As commercial topographic LiDAR sensors usually utilize the Nd:YAG laser which operates at wavelength 1.064 µm, high separability of spectral reflectance can always be found amongst different land cover materials in the near-infrared spectrum (see Fig. 1.3). In this regard, the peak laser energy backscattered from different objects (intensity data) can be utilized to distinguish different land cover features. In order to maximize the benefits of using the intensity data for land cover classification, certain data processing scheme should be applied to the aiborne LiDAR intensity data. Similar to any active remote sensing sensors, such data processing scheme should be able to remove the attenuation due to the system settings, topographic variation and atmospheric condition. 4

5
 VisibleRange

CHAPTER 1. INTRODUCTION
 LiDARat1.064m  
AsphaltRoad Brick DryGrass LimeStone SeaWater

0.6 0.5 Reflectance 0.4 0.3 0.2 0.1 0 0.4 0.6 0.8



1 1.2 1.4 Wavelength(m)

1.6

1.8

2



Figure 1.3: Spectral reflectance of different materials across visible to infrared wavelengths

1.2

Research Objectives

The ultimate goal of this thesis research aims to maximize the benefits of using airborne LiDAR intensity data for land cover classification. Due to the environmental- and system- induced distortions, airborne LiDAR intensity data has a certain level of noise which degrades the land cover homogeneity. In this thesis, a data processing scheme is proposed for radiometric correction and normalization of airborne LiDAR intensity data. After applying the data processing scheme, the intensity amongst different land cover features should be corrected in a relative sense, which is capable of improving the accuracy of land cover classification. Specifically, the objectives of the research are:1. To formulate a correction model for airborne LiDAR intensity data so as to remove the laser energy attenuation due to the environmental- and system- induced distortions; 2. To propose a normalization approach for overlapping intensity data acquired by different airborne LiDAR scans; and 3. To assess the effects of radiometric correction and normalization of airborne LiDAR intensity data on land cover classification. To meet the first objective, a radiometric correction model extended upon the well-established radar (range) equation is proposed. Although a few research groups have begun to carry out similar work, the thesis further introduces a set of methods, which have not been considered, 5

CHAPTER 1. INTRODUCTION

6

for computing laser incidence angle and atmospheric attenuation coefficients in the correction model. The research investigates the effects of different correction parameters (range, scan angle, incidence angle and atmospheric attenuation factor) by assessing the land cover homogeneity on the corrected intensity data. The second objective is achieved by proposing a radiometric normalization model based on matching the intensity sub-histograms amongst overlapping LiDAR data strips. The underlying principle of the model is to adjust the radiometric misalignment of intensity data in the overlapping region so that an intensity transformation model (histogram equalization) can be established. The transformation model is then used to calibrate the intensity of a LiDAR data strip with reference to the intensity of another LiDAR data strip. The proposed normalization model can be applied to both original intensity data and radiometrically corrected intensity data. Finally, the research examines the radiometrically corrected intensity data and radiometrically normalized intensity data by carrying out land cover classification on these data. Different classification scenarios were applied and tested on the intensity data to investigate the effects of the corrected and normalized intensity data on the classification accuracy. A comparative study is presented to determine the effectiveness of the proposed models on the intensity data classification under different scenarios.

1.3

Organization of the Thesis

The thesis is organized as follows: Chapter 2 presents a literature review of the state-of-theart development in topographic airborne LiDAR sensors as well as the research of radiometric correction and land cover classification using airborne LiDAR data. Chapter 3 presents a radiometric correction model for single strip airborne LiDAR intensity data with emphasis on the atmospheric correction model and the laser incidence angle. Experimental results are presented to assess the land cover homogeneity before and after radiometric correction. Chapter 4 presents a radiometric normalization model for overlapping airborne LiDAR intensity data based on Gaussian mixture model and sub-histogram matching techniques. Comparisons on the land cover intensity data are carried out on the original intensity data, the normalized intensity data and the corrected and normalized intensity data. Chapter 5 examines the corrected and normalized intensity data for different land cover classification scenarios. A comparative study of the classification accuracy is presented for the land cover classification results achieved by using the intensity data before and after correction and/or normalization. Conclusions of the research are drawn in Chapter 6, along with directions for future work.

6

Chapter 2

Literature Review
This chapter provides an overview of existing literature related to airborne LiDAR system. As shown in Fig. 2.1, the major components of an airborne LiDAR system include a laser ranging unit for emitting and recording laser beams, an optical scanning mechanism (e.g., rotating mirror) for cross laser track scanning, a computer processing system and storage media, a positioning and orientation system (including Global Positioning System (GPS), Inertial Measurement Unit (IMU), a hardware platform for mounting the system components, a software for mission planning and post processing, and other optional sensors like digital camera and temperature / humidity control (Baltsavias, 1999a). The background literature pertaining to the system components, including the historical development, laser construction, laser ranging and scanning, positioning and orientation system, and LiDAR intensity are presented in Section 2.1. The associated LiDAR research on land cover classification and radiometric calibration/correction are provided in Sections 2.2 and 2.3, respectively. Finally, Section 2.4 summarizes and points out the current gap in airborne LiDAR research which justifies the need for this study.

2.1
2.1.1

Airborne LiDAR System
Historical Development

LASER is an acronym for Light Amplification by Stimulated Emission of Radiation. The development of lasers can be traced back from the invention of a solid-state laser, gas laser and semiconductor laser in the mid-19th century. The Nobel Prize-winning physicists, Dr. Charles Townes and Dr. Arthur Schawlow, first suggested the potential use of intense monochromatic radiation for long distance measurement (Schawlow and Townes, 1958), where the idea forms the core of the current laser-based measurement tools. Though early laser-based instruments were mainly used for laboratory testing, various types of laser instrument were devised for 7

CHAPTER 2. LITERATURE REVIEW

8

surveying purposes afterwards. Examples are not limited to the electronic distance measuring (EDM) devices, rangefinders, total stations and survey robots which are commonly used in construction and surveying tasks.
GPS Receiver
Z

GPS Satellite

Y X

GPS Satellite

Pitch

IMU
Roll Yaw

Laser Ranging Unit

Figure 2.1: Schematic diagram of airborne LiDAR system

The first LiDAR system, which was proposed for Earth surface mapping, emerged as early as 1965 using gas/semiconductor laser (Petrie and Toth, 2009a). The first commercial aircraft LiDAR system proposed for topographic mapping operations was jointly developed by the Spectra Physics Company and a major aerial surveying company, named Aero Service Corporation (Petrei and Toth, 2009b). Steady and continuous development in airborne LiDAR system was carried on throughout the 1970s to 80s with respect to the development of Nd:YAG laser and GaAs laser. These solid-state and semiconductor lasers are capable of issuing high and stable laser energy, which can overcome long distance measurement. In the 1970s, Avco-Everett (from Everett, Massachusetts) produced its airborne LiDAR instrument using the Nd:YAG laser. In the 1980s, the Dynatech Scientific (from Salem, Masschusetts) developed the PRAMIII laser profiler using GaAs semiconductor diode laser where the system was applied for sea ice mapping (Lewis et al., 1993). The first airborne LiDAR from Canada was developed by Optech Inc. (Toronto, Ontario) with an improved pulse width (15 ns) in a similar period. More details can be found in Petrei and Toth (2009b). NASA has played an important role in the development and commercialization of airborne LiDAR system and the related techniques through its activities in Arctic topographic mapping since the 1960s (Petrie and Toth, 2009a). A number of experimental airborne and spaceborne LiDAR systems were devised to assess the characteristics of natural land cover. For instance, 8

9

CHAPTER 2. LITERATURE REVIEW

the Scanning LiDAR Imager of Canopies by Echo Recovery (SLICER5 ) is a medium footprint LiDAR for modeling the vertical structure of tree canopy with the returned full-waveform; the Shuttle Laser Altimeter (SLA6 ) is a satellite-based LiDAR for general land cover mapping; the Laser Vegetation Imaging Sensor (LVIS7 ) is a full-waveform LiDAR for measuring woodland with an embedded real-time classification algorithm; and finally the Geoscience Laser Altimeter System (GLAS8 ) was designed to study the land and sea glacial masses in the Antarctic and Greenland. A comprehensive summary of NASA laser altimeter can be found in the summary sheet prepared by Mallet and Bretar (2009).

2.1.2

Laser Construction

A laser is discharged in reaction to different media (gas, liquid, chemical reaction or solid material), and can be operated at different wavelengths. There are different types of lasers including a gas laser, chemical laser, dye laser, metal vapor laser, solid-state laser and semiconductor laser, where each can be applied in a diverse range of applications. Some lasers generate low energy pulses which are used for reading digital bar codes while high energy lasers are applied in industrial cutting or even military weapons.
Highly reflecting mirror Highly reflecting mirror

Nd:YAG crystal (laser medium) Flashlamp (pump source)

Electric Supply Laser Output

Nd:YAG solid-state laser

Figure 2.2: Schematic diagram of a typical laser with three components

A laser is constructed with three principal parts (See Fig. 2.2) including an energy source (or pump source), a gain medium (laser medium) and an optical resonator (Silfvast, 1996). The pump source (e.g., arc lamps, flash lamps, chemical reactions and, even, explosive devices) provides energy to the laser system. Selection of a pump source is usually dependent on the
5 6

NASA NASA 7 NASA 8 NASA

SLICER: http://denali.gsfc.nasa.gov/sla/slicer/slicer.html SLA: http://denali.gsfc.nasa.gov/sla/sla/sla1.html LVIS: http://lvis.gsfc.nasa.gov/index.php GLA: http://glas.gsfc.nasa.gov

9

CHAPTER 2. LITERATURE REVIEW

10

gain medium, and also determines how the energy is transmitted through the medium. The gain medium is the major determining factor of the operating wavelength and other properties of the laser. Examples of gain medium include liquid (for dye laser), gas (e.g., carbon dioxide), solid (e.g., crystal and glass) and semiconductor. Finally, the optical resonator includes two parallel mirrors placed around the gain medium. The mirrors are given optical coatings which determine their reflective properties. The laser action is activated from the pump source and it energizes a large number of atoms in an excited state. The electrons of the atoms are raised from their normal ground state to a much higher but unstable energy level where photons are spontaneously emitted. This process is also called stimulated emission. Other atoms from the pump source are then stimulated to emit photons with the same frequency and phase. Thus amplification of the radiation can be produced through the stimulated emission process. The light energy in the form of photons may be reflected between the highly reflective mirror and the partially reflective mirrors through the gain medium over hundreds of times before exiting the partially reflective mirror. For an airborne LiDAR sensor, since the laser beam travels a long distance between the aircraft and the ground, the laser system is capable of generating a very high energy level where solid-state and semiconductor lasers are commonly utilized. Solid state crystalline material such as Nd:YAG and semiconductor material like GaAs are commonly used as gain medium in which the electrons can be excited and raised to a much higher energy level (Petrie and Toth, 2009a).

2.1.3

Laser Ranging and Scanning

A rangefinder (or laser ranger) is the instrument that constructs and emits laser pulses and records the returned laser pulses in order to derive the distance between the aircraft and the ground. To determine the range measurement, the time pulse method and phase comparison method are commonly used (Wehr and Lohr, 1999a; Baltsavias, 1999b). In the time pulse method, the distance between the laser ranger and the point of the illuminated ground feature can be determined using the following equation:t=2 r c (2.1)

where t is the laser pulse two-way traveling time between the laser ranger and the reflected ground object, c is the speed of the light and r is the range distance. If the laser transmits continuous waveform (sinusoidal signal), the phase comparison method can be used. The mathematical expression of phase comparison method is:t=  T + nT 2 10 (2.2)

11

CHAPTER 2. LITERATURE REVIEW

where n is the number of full waveforms recorded, T is the period of the signal,  is the phase difference between the received and transmitted signal. By obtaining the value t, the range distance can be solved by Eq. (2.1). With rapid development of laser transmitters and receivers, current airborne LiDAR instrument can record the laser travelling time up to the nearest nanosecond (ns). This is also the reason why digitization of full waveform LiDAR is recently gaining significant interest. Nowadays, a laser scanning device uses an optical scanning mechanism with rotating mirror for cross track scanning (perpendicular to the flight direction) and illuminates a small footprint on the ground for each laser emission. Fig. 2.3 illustrates the concept of airborne laser scanning.

Scan Angle ( ) Flying height () Beam Divergence () Laser footprint ( )

Swath Width ( )

Figure 2.3: Illustration of airborne laser scanning The flying height of airborne LiDAR, defined as h, is usually within several hundred meters to few kilometers. The size of laser footprint AL depends on the beam divergence  and the scan angle . Nowadays, airborne LiDAR sensor can be operated with scan angle up to 75 and flying height up to 5 km so as to cover a wide area during a single flight. The narrowest divergence of the laser beam defines the instantaneous field of view (IFOV) as:IF OV = 2.44  D (2.3)

where  is the wavelength of the laser and D is the aperture of the laser ranger. The area of the laser footprint AL varies when it hits on flat or rugged terrain. However, the general form of the laser footprint can be represented as:AL = h  cos2 (inst ) 11 (2.4)

CHAPTER 2. LITERATURE REVIEW

12

where inst is the instantaneous angle of the field of view. A detail explanation of the general form in flat and rugged terrain can be found in Baltsavias (1999b). Finally, the swath width for the LiDAR survey, defined as SW , depends on the scan angle  can be expressed as:SW = 2h tan  2 (2.5)

In common practice, the 3D LiDAR point clouds are used to generate an intensity image and DEM in raster format. To determine an optimal image resolution for the output images, the mean point spacing can be used as a reference. First of all, the surveyed area rate can be computed by multiplying the flying speed of the aircraft with the swath width:SA = 2vh tan  2 (2.6)

where v is the flying speed of the aircraft which can be determined from the trajectory data file. Then the mean point spacing (PS ) can be approximated by first determining the mean point density (PD ) with reference to the pulse repetition frequency:1 PS =  PD where PD = P RF SA (2.7)

(2.8)

2.1.4

Positioning and Orientation

Apart from the laser ranging unit, airborne LiDAR system are equipped with Global Positioning System (GPS) and Inertial Measurement Unit (IMU) integrated unit for determining the position and monitoring the orientation (see Fig. 2.4). The GPS receiver records the instantaneous 3D position of the aircraft in WGS84 geodetic coordinate system while the IMU aims to monitor the rotation of the three local axes of the aircraft. As the laser ranging unit and the GPS/IMU integrated unit are installed in different locations inside the aircraft, offsets amongst these instruments (lever arm) should be measured and fixed so that exterior orientation can be solved. To compute the ground coordinates of the illuminated object, the LiDAR point positioning equation is used by modeling the spatial relationships amongst the measurements from the equipment (Habib et al. 2010 and 2011) as shown in Eq. 2.9.  0       XG = Xo + R,, PG + R,, R,, RS S   0   -(r + r)  12        

(2.9)

13

CHAPTER 2. LITERATURE REVIEW

  where XG is the 3D ground coordinates of the illuminated object, Xo is the vector from the origin of the ground reference frame to the origin of the IMU coordinate system, R,, refers to the  rotation matrix relating the ground coordinate system and IMU coordinate system, PG refers to the offset between the laser ranging unit and the IMU coordinate system, R,, R,, refers to the rotation matrix relating the laser ranging unit and the IMU coordinate system, RS S  refers to the rotation matrix relating the laser unit and laser beam coordinate systems with  and  being the mirror scan angles, S and S are the scale factors of the angles measured by the scanner, r is the range vector whose magnitude is equivalent to the distance from the laser firing point to its footprint and r is a systematic error in the measured range.
GPS/IMU Laser Ranger

Scan Angle Flying Direction

  

Flying Height

  0

0  0 0

Figure 2.4: LiDAR system configuration and the positioning and orientation systems

The coordinates of the LiDAR points are the result of combining the derived measurements from each of its system components and the mounting parameters relating such components.    The position of an object point XG is derived through the summation of three vectors (Xo , PG and r) after applying the appropriate rotations (R,, , R,, , RS S  ). In this equation,  Xo is the vector from the origin of the ground reference frame to the origin of the IMU coordinate system (with respect to the IMU body frame), and r is the laser range vector whose magnitude is equivalent to the distance from the laser firing point to its footprint. It should be noted  that Xo is derived through the GPS/INS integration process while considering the lever arm vector between the IMU body frame and the phase centre of the GPS antenna. The term R,, stands for the rotation matrix relating the ground and IMU coordinate systems which is derived 13

CHAPTER 2. LITERATURE REVIEW

14

through the GPS/INS integration process. The term R,, represents the rotation matrix relating the IMU and laser unit coordinate systems which is defined by the boresight angles (considering the y-axis of the IMU body frame aligned along the flight direction), while the term RS S  refers to the rotation matrix relating the laser unit and laser beam coordinate systems with  and  being the mirror scan angles. s and s are the scale factors of the angles measured by the scanner, while r is a systematic error in the measured range. One should note that, for a linear scanner, the mirror is rotated in one direction only, leading to zero values for  and S . The involved quantities in the LiDAR point positioning equation are all measured during the acquisition process except for the mounting parameters (i.e., the lever arm and boresight angles), the scan angles scale factors and the range error; these parameters are usually determined through a calibration procedure.

2.1.5

LiDAR Intensity Data

When an airborne LiDAR system flies over the survey area, the LiDAR sensor emits a laser pulsed at a specific pulse repetition frequency, illuminates a footprint on the surface object, and finally records the returned laser pulse signal after backscattered from the surface objects. Single return of laser pulses can always be found in impenetrable surfaces like roofs, roads, etc. while multiple returns of laser pulses are usually obtained from tree canopies where portion of the laser footprint is illuminated on and backscattered from the leaves, stems and branches before encountering the ground surface (Chasmer et al., 2006). For a discrete return LiDAR sensor, the laser intensity represents the peak amplitudes recorded in the laser backscattering beam return from the illuminated object where the intensity is usually linearized into an 8 bit or 11 bit data scale. For the latest full-waveform LiDAR, the sensor records not only a discrete number of echoes, but also digitizes the entire waveform of the emitted pulse and the backscattered echoes (Wagner, 2010) as illustrated in Fig. 2.5. To have a better understanding on the physical meaning of LiDAR intensity data, the signal strength of the laser pulse return should be modeled. As the airborne LiDAR system operates in similar principle to radar remote sensing system, the radar (range) equation is adopted to explain the signal strength of the laser pulse (Jelalian, 1992) as below:Pr = PT GT  D2 sys atm 4r2 4r2 4 (2.10)

The effects on the physical properties of the received laser beam energy (Pr ) are considered using the radar (range) equation presented in Eq. (2.10), which takes into account the sensor configuration and different environmental parameters. The received laser beam energy (Pr ) depends on two groups of parameters: a) system parameters and b) environmental parameters. 14

15

CHAPTER 2. LITERATURE REVIEW

The system parameters refer to the configuration and the characteristics of the laser scanning system including the emitted laser energy PT , the gain factor of the antenna GT , the aperture diameter D, the range of each laser pulse r, and the loss due to system inefficiency sys . Some of the factors such as PT , D and sys can be assumed to be constant during the flight (H¨ ofle and Pfeifer, 2007). The environmental parameters include the atmospheric attenuation atm (which is covered in Chapter 3) and the laser target cross section  .  = 4s Atarget cos(r )
Power Emitted Laser Pulse Power

(2.11)

Atmospheric Scattering

Figure 2.5: Illustration of the laser pulse return signal and the recorded signal strength

The target cross section presented in Eq. (2.11) is one of the key parameters to be considered in the radar (range) equation. It depends on the characteristics of the target surface (slope and aspect) with respect to the direction of the laser pulse. The s in Eq. (2.11) refers to the spectrum reflectance at the specific wavelength and Atarget refers to the target area which is illuminated by the footprint of the laser beam. The scattering from the target area is usually not uniform because almost all surfaces are rough by nature. The Lambertian assumption is adopted to model the surface reflectance. Following this assumption, the scattered laser pulse is constant at all reflected angles and the target cross section is proportional to the cosine of the reflected angle r (Steinvall, 2000). The r (the angle between the incidence laser beam and the surface normal of the ground object) can be assumed equal to the scan angle (), in cases where the ground surface is relatively flat. However, this is not always the case particularly in 15

Time
Backscattered Intensity

Time
1 Return
st

Returned Laser Pulse(s)

2 Return

nd

3 Return

rd

CHAPTER 2. LITERATURE REVIEW

16

urban areas and rugged terrain. A better estimate of the angle r (which is covered in Chapter 3) can be calculated using the scan angle () and surface slope as defined by the LiDAR point cloud. With the assumption that the intensity (I ) represents the peak value of Pr (H¨ ofle and Pfeifer, 2007), data providers linearly transformed Pr into 8 bit values to represent the intensity data which is used in the radar (range) equation (H¨ ofle and Pfeifer, 2007).

2.2

Land Cover Classification

Since airborne LiDAR permits accurate probing of the topography which is almost impossible using passive remote sensing techniques (Korpela et al., 2010), a number of recent research studies investigated the use of airborne LiDAR data for land cover classification. Charaniya et al. (2004) and Bartels and Wei (2006) introduced supervised pixel-based classifiers on a set of feature vectors (such as height, luminance, difference of multiple returns, etc.) derived from the airborne LiDAR data. The classification strategies were mainly based on the use of geometric information of the LiDAR data point cloud only. Unlike optical remote sensing data, airborne LiDAR data does not have multi-spectral data which provide sufficient separabilities of spectral reflectance amongst different land cover features. Therefore, fusion of airborne LiDAR data with other remote sensing data were investigated to compensate for the lack of spectral data, for example, fusion of LiDAR data with CASI data for classification of floodplain vegetation (Geerling et al., 2007), multispectral images for classification of rangeland vegetation (Bork and Su, 2007), hyperspectral images for classification of complex forests (Dalponte et al., 2008), Quickbird data for mapping surface fuel models (Mutlua et al., 2008) and urban areas (Chen et al., 2009). To further maximize the benefits of using airborne LiDAR data in land cover classification, introduction of the intensity data or even the entire backscattered waveform signal becomes a viable approach to improve the classification results. Song et al. (2002) interpolated the intensity data of the point cloud into grid data and applied image filters to remove noise within the intensity data. The separability amongst four land cover classes (grass, house, road and tree) was assessed and low separability was found between grass and tree classes. To enhance the quality of the intensity data classification, similar studies have been conducted by incorporating ancillary data. Beasy et al. (2005) classified near shore materials (bedrock, cobble and sand) on the Fundy coast of Nova Scotia using intensity data, texture data and luminance data (the average digital numbers of ortho-rectified aerial image). Fairly high separability was found in the experiment amongst the classes with average Bhattacharrya distance near to 1.9. Goodale et al. (2007) utilized LiDAR intensity and elevation data to classify coastal estuaries and beach habitats (such as mudflat, sand, cobble, tree and shrub) with a logical filter classification model. It was found that LiDAR intensity 16

17

CHAPTER 2. LITERATURE REVIEW

data was useful in distinguishing coastal features. Object-oriented image segmentation has been proposed for land cover classification using LiDAR range and intensity data. Approximate 90% overall accuracy was reported by Brennan and Webster (2006) and Antonarakis et al. (2008). Yoon et al. (2008) assessed the intensity data from the singular returns of LiDAR signal of Optech ALTM 3070 sensor. The study compared the LiDAR intensity signal with the reflectance measured from field spectroradiometer (GER 2600). The findings revealed that there was no significant separability amongst land cover classes including vegetation and manmade structures. Compared to the field spectroradiometer measurement, vegetation cover did not show higher reflectance than other land cover classes in the LiDAR intensity. Also, artificial structures such as asphalt, unpaved roads and concrete had similar reflectance patterns with low intensity. In order to improve classification accuracy, knowing the physical property of land cover classes is necessary and correction of intensity data should be applied with respect to the system settings for each of the recorded laser pulse (Bretar et al., 2008).

2.3

Radiometric Calibration, Correction and Normalization

The importance of radiometric calibration and correction of active remote sensing data has been emphasized for Japan Earth Resources Satellite-1 Synthetic Aperture Radar (Shimada, 1996), RADARSAT (Small et al., 1997), European Remote-Sensing Satellite Synthetic Aperture Radar (Riegler et al., 1998) and Advanced Land Observation Satellite Phased Array type L-band Synthetic Aperture Radar (ALOS PALSAR) (Shimada et al., 2009). Different rigorous radiometric correction models were developed by considering the scanning geometry, backscattering mechanism and terrain induced distortions (Loew and Mauser, 2007). In case of the lack of ground calibration reference or sensor information, radiometric normalization is recommended for multi-temporal data analysis. The purpose of normalization aims to reduce the radiometric differences amongst the multi-temporal dataset by building a relationship (or transformation) across the image scenes. Applications of radiometric normalization in satellite remote sensing can be found in change detection (Yan and Lo, 2000; Heo and FitzHugh, 2000; Du and Cihlar, 2002), image mosaicking (McGovern et al., 2002), and gap filling (Helmer and Ruefenacht, 2007; Roy et al., 2008). Based on the aforementioned studies, it has been shown that radiometric calibration, correction and normalization have significant influence on the derived data products. Airborne LiDAR systems have similar operational principles to RADAR and SAR systems. Laser energy is emitted and the backscattered energy from the illuminated object is recorded by the airborne LiDAR system. The backscattered energy and the time delay between the signal emission and reception are used to derive a 3D point cloud, which is represented by the xyz coordinates while 17

CHAPTER 2. LITERATURE REVIEW

18

the intensity I represents the peak backscattered laser energy from the object. Due to the atmospheric effects and the object surface backscattering, radiometric correction of the airborne LiDAR intensity data should be carried out to remove the effects of laser energy attenuation. Radiometric correction of the LiDAR intensity data can be performed using empirical or physical approaches (H¨ ofle and Pfeifer, 2007). The empirical approach does not consider the physical properties of the laser backscattering energy. Instead, it introduces statistical methods to minimize the noise in the intensity data. Fang and Huang (2004) introduced a discrete wavelet transform approach for noise reduction in LiDAR signal, the results demonstrated that the proposed method outperformed the traditional digital filters by improving the signal-to-noise ratio. Lai et al. (2005) investigated mean filtering algorithm to fuse the LiDAR intensity range data and remove different types of signal noise. The results showed that the proposed filtering algorithm merely improves the quality of the data. Boyd and Hill (2007) attempted to validate the intensity data with HyMap sensor data (Band 42), which has a similar spectral wavelength, over a forested area. Correlation can be found in a few forest species between the two datasets but a practical correction method is still required. H¨ ofle and Pfeifer (2007) introduced an empirical approach by deriving a polynomial model based on the range and intensity data. A least squares adjustment was conducted to fit the model by selecting homogenous backscattered areas in the LiDAR dataset. The results achieved showed reduction of the intensity variation over areas with the same land cover surface. On the other hand, the physical approach relies on the use of radar (range) equation (Jelalian, 1992), and it was first proposed for radiometric correction of LiDAR intensity data by Coren and Sterzai (2006), H¨ ofle and Pfeifer (2007) and Kaasalainen et al. (2007). The correction process aims at converting the recorded intensity data into the spectral reflectance of the illuminated object by studying the physical properties of the parameters involved in the equation. The following studies were conducted to calibrate the LiDAR intensity data acquired from a number of commercial LiDAR sensors using artificial targets (Kaasalainen et al., 2009a) and natural targets (Vain et al., 2009). The effects of the flying height (Vain et al., 2009), range (Kaasalainen et al., 2009b), incidence angle (Kukko et al., 2008), sensor aperture size (Kaasalainen and Kaasalainen, 2008), surface moisture (Kaasalainen et al., 2010), automatic gain control on the backscattered intensity (Vain et al., 2010) and reflection model (Jutzi and Gross, 2010) have been studied. The objective of these studies aims to investigate the effects of sensor operation parameters (e.g., range, incidence angle), backscattering properties, and the relationship between the recorded intensity data from the field and the intensity data measured from the laboratory using the same reference targets. To prepare reference targets for radiometric calibration, different sand and gravel samples, and brightness tarps made of PVC were used as reference targets for the airborne LiDAR 18

19

CHAPTER 2. LITERATURE REVIEW

survey (Kaasalainen et al., 2009a). The reflectance of the targets was measured by Spectralon using 785 nm terrestrial laser scanner (TLS), 1.064 µm Nd:YAG laser instrument and CCD camera in the laboratory. The findings in the study revealed that: 1) variation of intensity data was found for targets like redbrick with rough surface (Kukko et al., 2008); 2) the effect of moisture on the targets was demonstrated as a factor towards the surface reflectance in an outdoor environment, where it varied by 30% to 50% in the reflectance measurement carried out by Kaasalainen et al. (2009a); 3) the variation of reference targets between the field and laboratory measurement should be minimized (i.e., the measurement geometry, selection of gravel samples, the uniformity of the color and surface roughness of the samples should be similar.) After considering all these factors, the results between the field and laboratory measurements were found more consistent owing to the consideration of the above factors in the second round of the experimental testing (Kaasalainen et al., 2009a). Kaasalainen et al. (2009b) measured the intensity recorded by FARO and Leica TLSs with different distances towards the known reference targets. Reduction of backscattered intensity was found when the measurement distance increases. Yoon et al. (2008) conducted similar in situ spectrum reflectance measurements, and range effect was obvious only in road features (concrete, unpaved and asphalt roads) whereas vegetation cover got a high standard deviation of intensity. This can be explained by the effects of observation geometry and how the surface properties (e.g., roughness, moisture) are much obvious in materials with higher reflectance in near-infrared red spectrum (1.064 µm).

2.4

Discussion

In 1999, the ISPRS Journal of Photogrammetry and Remote Sensing published a special theme issue on airborne laser scanning (Wehr and Lohr, 1999b) which has made a significant impact on the LiDAR development in both industry and academic communities. One of the top cited papers in this theme issue, published by Ackermann (1999), pointed out the expected future development of airborne laser scanner in three different areas: 1) more and extended applications, 2) additional information about the surface characteristics analyzed from the returned signal, and 3) consolidation and extension of LiDAR data processing methods. After ten years, the growth in the LiDAR market has been justified by an industrial survey (Cary and Associates, 2009). The survey indicated that there has been an increase of 75% in the number of LiDAR systems in use, 53% in LiDAR operators, and 100% in the number of end users between 2005 and 2008. According to the same survey, such an upward trend is expected to continue in the next several years. Despite this positive outlook, the respondents to the survey indicated that 19

CHAPTER 2. LITERATURE REVIEW

20

there are some barriers that could hinder the expected growth. Two of the top three barriers are the quality of data and the shortage of experienced analysts. More specifically, the bulky and explicit 3D data obtained from the airborne laser scanning makes data processing more complex in extracting useful information. The lack of intelligent processing algorithms also limits further exploration and applications. So far, intelligent algorithms related to the collection and processing of airborne LiDAR data have been applied to the fields of digital elevation/surface model generation (Lohr, 1998; Lloyd and Atkinson, 2002; Shan and Sampath, 2005; Loyd and Atkinson, 2006), topographic mapping (Vosselman et al., 2005; Matikainen et al., 2010), building/road features recognition (Zhang et al., 2006; Vu et al., 2009), powerline extraction (Li et al., 2012) and 3D city modeling (Brenner, 2005; Elberink and Vosselman, 2009; Kim and Shan 2011; Lafarge and Mallet, 2012). All these mentioned work mainly rely on the analysis of geometric components of 3D LiDAR data point clouds (xyz ), where few of the previous work explore the use of LiDAR intensity data (I ), which echoes the argument mentioned by Ackermann as early as 1999. The limited use of the intensity data can be ascribed to the environmental- and system- induced distortion. Low classification accuracy using LiDAR intensity data is always found when compared to the results achieved by using near-infrared red band in optical remote sensing. Therefore, a certain correction scheme should be applied to the airborne LiDAR intensity data in order to maximize the benefits of using it in surface classification and object extraction. As reviewed in Section 2.3, practical methods were developed to eliminate the effects of some system parameters and target characteristics through absolute correction and relative calibration approaches. However, some of the factors, such as the atmospheric absorption and scattering, combining overlapping intensity data, etc., have not yet been fully investigated where a practical approach to integrate all the factors without in situ or laboratory measurements is still desired. In addition, very few authors investigated the impacts of radiometric correction of airborne LiDAR intensity data on surface classification and object recognition. In this regard, this thesis research attempts to fill the current gap by proposing a radiometric correction model and radiometric normalization model, and studying the effects of these models on land cover classification results using airborne LiDAR intensity data.

20

Chapter 3

Radiometric Correction
This chapter presents the approach for radiometric correction of airborne LiDAR intensity data. The correction model extends upon the well-established radar (range) equation (as reviewed in Section 2.1.5) which has been preliminarily investigated on the correction of LiDAR intensity data. This thesis further consolidates the correction model by incorporating a set of empirical equations for computing atmospheric attenuation and laser incidence angle. The proposed approach was applied to a real airborne LiDAR dataset for experimental testing. Five rounds of correction were conducted on the intensity data in order to evaluate the impacts of scan angle, incidence angle and atmospheric attenuation factor on the results. Land cover homogeneity was then assessed by studying the coefficient of variation in different land cover features before and after correction. Finally, the chapter ends with a short summary of the proposed method and results.

3.1
3.1.1

Method
Overall Workflow

Fig. 3.1 illustrates the overall workflow for radiometric correction of LiDAR intensity data. Since raw LiDAR data (without post-survey processing) are mostly unavailable to end users, a time-tagged 3D data point cloud is usually delivered in LAS file format together with a GPS trajectory file (optional) after an airborne LiDAR survey. In this study, the LAS file containing the 3D coordinates (xyz ) and the backscattered intensity (I ) of each laser pulse was converted into ASCII format for data processing. With the GPS trajectory data and the time tagged 3D data point cloud, instantaneous GPS coordinates were interpolated for each of the laser pulse. After that, system parameters (range, horizontal angle and scan angle) which describe the geometric relationship between the instantaneous position of the aircraft 21

CHAPTER 3. RADIOMETRIC CORRECTION

22

and the illuminated object were computed (refer to Section 3.1.2). The incidence angle, which is the angle between the incidence laser pulse and the surface normal from the topography, was computed so as to consider the topographic induced distortion. Atmospheric attenuation was determined from the weather information (temperature, pressure and meteorological visibility) before radiometric correction (refer to Section 3.1.3). Finally, the intensity, range, atmospheric attenuation and incidence angle for each laser pulse were imported into the radar (range) equation to determine the spectral reflectance of illuminated object, which was regarded as the radiometrically corrected intensity (RCI) (refer to Section 3.1.4).
GPSTrajectory TimetaggedLiDARData HITRAN xyz Intensity(I)
Temperature Pressure

ComputeRange&Angles

GenerateTIN

Range

HorizontalAngle

ScanAngle

Slope

Aspect

Visibility

ComputeIncidenceAngle

BeerLambertLaw

IncidenceAngle

AtmosphericAttenuation

RadiometricCorrection

CorrectedIntensity(RCI)

Figure 3.1: Overall workflow for radiometric correction

3.1.2

Computation of Incidence Angle

Fig. 3.2 presents the geometric relationship between the instantaneous position of the LiDAR sensor (L) and the object on the ground (P ) in a XYZ Cartesian coordinate system. The scan 22

23

CHAPTER 3. RADIOMETRIC CORRECTION

angle denotes as  and the distance between the sensor and the ground object is represented by the range r. In case of flat terrain, the incidence angle is described between two vectors   which are the vertical vector from the ground object ( P V ) and the range vector ( P L), where the incidence angle is equivalent to the scan angle . In the case of rugged terrain, the ground object (P) is located on a surface with slope () and aspect ( ) where the incidence angle   should be described with the range vector (P L) and the surface normal vector (P N ) to the ground object.
Z

Flying Direction

(a)
ScanAngle

L

(b)

L
V
VerticalVector

SurfaceNormal N

Flying Angle Height

Scan

N Y

IncidenceAngler

P

Slope() O
Range


Y

Y'

(c)
Aspect() X'

P

V

SurfaceNormal



X

Horizontal Angleh
L

N X

Figure 3.2: Illustration of the geometric relationship between the airborne LiDAR system (L) and the illuminated object (P )

In common practice, the range data are usually not included in the LAS file, the range  vector P L should be calculated by the instantaneous 3D coordinates of the aircraft and the 3D coordinates of the illuminated object for each laser pulse. Since the laser pulse is recorded in nanoseconds (ns), which is not synchronized with the GPS measurement (measured in seconds), the instantaneous 3D coordinates of the aircraft (XL , YL , ZL ) can be projected on the LiDAR 3D data point cloud (XP , YP , ZP ) by interpolating the GPS time into the corresponding time of LiDAR data. Finally, the range and scan angle can be derived from the Eqs. (3.1) and (3.2). P L = r = (XL - XP )2 + (YL - YP )2 + (ZL - ZP )2  = cos-1 ZL - ZP r 23 (3.1)

(3.2)

CHAPTER 3. RADIOMETRIC CORRECTION

24

   In order to compute the incidence angle (r or LP N ), three vectors (P L, P N and LN ) in  the triangle LP N should be used. The computation of range vector P L has been described in the aforementioned paragraph. The slope () and aspect ( ) can be derived directly from   a TIN model generated from the 3D data point cloud. Then, vectors P N and LN can be calculated using following equations. In LV P : V P = r  cos  In N V P : PN = Subs.(3.3) into (3.4) PN = VP cos  (3.3)

(3.4)

r  cos  cos 

(3.5)

 Then, vector LN can be calculated from the following equations: In LV P : LV = r  sin  In N V P : N V = V P tan  Subs.(3.3) into (3.7) N V = r  cos  tan  In N V L (See Fig. 3.2(c) bottom right): N V L = Y  V L -  Y  V N (3.9) (3.8) (3.7) (3.6)

where angle Y  V N is an obtuse angle which is equal to the aspect ( ) of the ground object P on the terrain. The angle Y  V L and Y LV are interior angles where Y LV is the projected horizontal angle between the Y-axis and the laser pulse. The projected horizontal angle Y LV (or h ) can be computed using the plane coordinates of the laser pulse and the instantaneous position of the aircraft as follows:h = Y LV = tan-1 According to the cosine law: LN = N V 2 + LV 2 - 2(N V )(LV )(cos N V L) 24 (3.11) XP - XL YP - YL (3.10)

25 Subs. (3.6) and (3.8) into (3.11):

CHAPTER 3. RADIOMETRIC CORRECTION

LN = (r  cos  tan )2 + (r  sin )2 - 2(r  cos  tan )(r  sin )(cos( - h ))

(3.12)

   Finally, the incidence angle LP N can be calculated using the three vectors (P L, P N , LN ) in LP N in accordance to the cosine law: In LP N : LP N = r = cos-1 P N 2 + P L2 - LN 2 2(P N )(P L) (3.13)

   where P L is the range vector from Eq. (3.1), P N can be obtained from Eq. (3.5), and N L can be obtained from Eq. (3.12). By combining all the equations, Eq. (3.13) becomes:

r = cos-1

cos  2 2 2 2 ( rcos  ) + r - (r  cos  tan ) - (r  sin  ) + 2(r  cos  tan )(r  sin  )(cos( - h )) cos  2( rcos  )(r )

(3.14) Eliminating the range vector r, Eq. (3.14) becomes: r = cos-1
cos  2 2 2 ( cos  ) + 1 - (cos  tan ) - sin  + 2(cos  tan )(sin  )(cos( - h )) cos  2( cos )

(3.15)

Multiplying cos2  in denominator and numerator, Eq. (3.15) becomes: r = cos-1 cos2  + cos2  - cos2  sin2  - sin2  cos2  + 2(sin )(cos )(sin )(cos )(cos( - h )) 2 cos  cos  (3.16)

r = cos-1

cos2 (1 - sin2 ) + cos2 (1 - sin2 ) + 2(sin )(cos )(sin )(cos )(cos( - h )) 2 cos  cos  (3.17)

r = cos-1

cos2 (cos2 ) + cos2 (cos2 ) + 2(sin )(cos )(sin )(cos )(cos( - h )) 2 cos  cos 

(3.18)

Finally, the incidence angle is represented as:r = cos-1 [cos  cos  + sin  sin  cos( - h )] 25 (3.19)

CHAPTER 3. RADIOMETRIC CORRECTION

26

3.1.3

Atmospheric Correction

Atmospheric attenuation atm is one of the major factors affecting the radar (range) equation (Jenn, 2005). Although some previous studies assumed this factor as constant for short range laser scanning or clear atmospheric conditions (Soudarissanane et al., 2007; Roncat et al., 2011), this thesis research attempted to model this factor by studying the physical basis since the latest LiDAR sensor can be operated up to a 4 km flying height. The atm follows the Beer-Lambert Law where the laser energy is attenuated in an exponential manner as presented below. atm = e-2 r where  = as () + ms () + aa () + ma () (3.21) (3.20)

 refers to the power of the extinction coefficient, and  is the summation of: a) the aerosol scattering (as ), b) the molecular (Rayleigh) scattering (ms ), c) the aerosol absorption (aa ) and d) the molecular absorption (ma ). A number of studies have been conducted to model the atmospheric extinction for the troposphere. It was found that extinction is wavelength dependent, and the attenuation varies spatially and temporally (Hayes and Latham, 1975). As the atmospheric extinction of Nd:YAG laser is not fully investigated in radiometric correction, the effects of scattering and absorption are modeled using the following formulas and empirical models. Aersol scattering Aerosol scattering (or Mie scattering) is mainly due to the short wavelength scattering caused by small particles suspended in the air such as dust, smoke or droplets of salt water. The aerosol scattering is difficult to model due to the lack of instantaneous aerosol measurements including the composition, concentration and distribution in the air. Therefore, empirical approach was developed to model the aerosol extinction in the atmosphere based on the wavelength and visibility. The model developed by Filippov (1982) was commonly used where aerosol extinction is formulated as as = 3.91(n0 + n1 -n2 ) v where v is the meteorological visibility range measured in km, and n0 , n2 and n2 are fitting coefficients. In this study, the revised model proposed by Ferdinandov et al. (2009) was used to characterize the aerosol scattering for near Earth surface as shown in Eq. (3.22). as () = (-2.565ln() + 2.499)v -0.199ln()+1.157 (3.22)

where  is the wavelength in µm and v is the meteorological visibility range measured in km. 26

27

CHAPTER 3. RADIOMETRIC CORRECTION

This model was claimed to be suitable for close to ground troposphere. In addition, the model was evaluated using different data acquired from the previous research published from 1957 to 2008. In practice, aircraft may not be equipped with a visibility sensor (e.g., transmissometer) for measuring the meteorological visibility; therefore, the visibility data can be obtained by accessing the weather data archive provided by the closest airport or weather station.

Rayleigh scattering Rayleigh scattering is caused by small air particles and clusters in the atmosphere. The scattering is significant for electromagnetic radiation with short wavelengths. Bucholtz (1995) introduced a set of formulas for the Rayleigh Scattering Cross-Section calculation with reference to one standard atmospheric model (the 1962 U.S. Standard) and five supplementary models (Tropical, Mid-latitude Summer, Mid-latitude Winter, Subarctic Summer and Subarctic Winter). To calculate the extinction coefficient, the total Rayleigh scattering cross section per molecule r for a wavelength () is given by: r () = 24 3 (ns ()2 - 1)2 F 2 (n ()2 + 2)2 k 4 Ns s (3.23)

where Ns is the molecular density (2.54743 × 1019 cm-3 ) for standard air, Fk is the King correction factor where Fk = (6 + 3n ) (6 - 7n ), and n is the depolarization factor which accounts for the anisotropy of the air molecule (Bates, 1984). Although Fk was not provided for wavelength greater than 1 µm in Bucholtz (1995), the corresponding value of Fk in 1.064 µm can be retrieved from the recent re-calculation of Rayleigh scattering in Tomasi et al. (2005). The term ns () is the refractive index for standard air for a specific wavelength (). It can be calculated using Eq. (3.24) for wavelengths greater than 0.23 µm:(ns () - 1)108 = 5, 791, 817 167, 909 + 1 2 1 2 238.0185 - (  ) 57.362 - (  ) (3.24)

The total Rayleigh scattering coefficient ms for a specific wavelength () is the product of the total Rayleigh cross section per molecule r () calculated from Eq. (3.23) and the molecular density N at a given pressure and temperature (i.e., ms () = N r ()). As N is practically difficult to be measured for most of the applications, the total Rayleigh volumescattering coefficient ms () can be derived by normalizing the pressure (P ) and temperature (T ) with respect to the corresponding values at standard air Ns in Eq. (3.25). The atmospheric model for the standard air used in this study is the mid-latitude summer model with standard 27

CHAPTER 3. RADIOMETRIC CORRECTION pressure (Ps ) = 1013 mbars and standard temperature (Ts ) = 294 K. ms () = Ns r () Aerosol and molecular absorptions P Ts Ps T

28

(3.25)

Aerosol and molecular absorption may cause energy loss of a laser beam through propagation due to the existence of water vapour, carbon dioxide, oxygen, etc. (Zuev, 1976). The absorption attenuates the energy of the laser beam when it travels from the sensor to the ground and vice versa. Referring to the atmospheric transmission windows, the major contributor to the absorption at wavelength 1.064 µm (Nd:YAG laser) is water vapor. To find the extinction coefficient, public (free) molecular absorption database such as the HITRAN 2008 database (Rothman et al., 2009) can be used. The HITRAN database contains 2.7 million spectral lines for 42 different molecules. By selecting the specific molecules, range of spectral lines, temperature and pressure, the absorption coefficient can be retrieved from the database. In this study, the absorption coefficient of water vapor at the operating wavelength (1.064 µm) of the airborne LiDAR sensor was retrieved from the HITRAN database.

3.1.4

Radiometric Correction

We substitute Eq. (2.11) into in Eq. (2.10), and the radar (range) equation becomes: Pr = PT GT 4s Atarget cos(r ) D2 sys atm 4r2 4r2 4 (3.26)

where Pr is the received laser energy, PT is the emitted laser energy, GT is the gain factor of the antenna, s is the spectral reflectance of the illuminated target, Atarget is the illuminated laser footprint on the target area, r is the incidence angle, D is the diameter of the aperture, r is the range, sys is the loss due to system inefficiency, and atm is the atmospheric attenuation factor. Since some of the system parameters were not disclosed by commercial manufacturers, a number of assumptions were made here. First, it is understood that the received laser energy Pr is conceptually equivalent to the LiDAR intensity data; however, the method of how the LiDAR sensor transformed Pr into I remains unknown. Therefore, a linear approach, which has been previously mentioned by Coren and Sterzai (2006), was assumed for the transformation from Pr into I . Before the launch of fullwaveform LiDAR sensors, most of the discrete return sensors did not record the emitted laser energy PT (H¨ ofle and Pfeifer, 2007); therefore, PT was assumed as constant together with the system inefficiency factor sys and the aperture diameter D. The gain factor GT is used to keep 28

29

CHAPTER 3. RADIOMETRIC CORRECTION

the intensity measurements within the radiometric resolution (e.g., 8 bit). This is particularly useful when the LiDAR sensor flies over a land surface with very low (e.g., dark asphalt road) or very high reflectance surfaces. Though some attempts were conducted to model the pattern of gain factor in Vain et al. (2010), this factor is sensor dependent and the mathematical model is a black box unless proprietary LiDAR data processing software is used (e.g., Leica ALS Post Processor). Up to this point, the gain factor was assumed as constant for a single strip airborne LiDAR data. Nevertheless, such an assumption may induce systematic error on the LiDAR intensity data when overlapping strips are combined. In Chapter 4, a statistical approach is proposed to radiometrically normalize the overlapping strips of LiDAR intensity data so as to remove the line stripping noise. The remaining factors including incidence angle r , range r and atmospheric attenuation factor were already covered in the previous sub-sections. Finally, the spectral reflectance s can be derived from Eq. (3.26) where s is regarded as the radiometrically corrected intensity data (RCI). Effects of over-correction have been reported by Ria~ no et al. (2003) and Soenen et al. (2005) while using the incidence angle in topographic correction of passive remote sensing images. Since the cosine of incidence angle is assumed to be indirectly proportional to the corrected intensity (or the spectral reflectance) in the correction process, the excessive correction is most pronounced at the incidence angles approaching 90 (Soenen et al., 2005). This phenomenon has also been justified in our previous experiment in radiometric correction of airborne LiDAR intensity data (Shaker et al., 2011) where most of the trees and building boundaries receive excessive correction. To resolve this problem, we imitated the technique proposed by Richter et al. (2009) which incorporated threshold angle values to decide the use of different parameters in the correction model. In this study, we used the slope to control the selection of angle in the correction process. When the slope was less than 40 , then the incidence angle was used in the radar (range) equation; while the slope exceeded 40 , the scan angle was used. The reason for using 40 as the threshold was mainly due to the inclined surfaces in the study area, which were found to be mostly less than this value.

3.2
3.2.1

Experimental Testing
Study Area and Dataset

The study area covers the British Columbia Institute of Technology (BCIT) located in Burnaby, British Columbia, Canada (122 59'W, 49 15'N), see Fig. 3.3. A LiDAR dataset was acquired to test the feasibility of the proposed radiometric correction method. The LiDAR mission was conducted on July 17, 2009 at local time 14:55. The survey day was a sunny day 29

CHAPTER 3. RADIOMETRIC CORRECTION

30

with temperature of 29.8  C. The vertical visibility and pressure were 48.3 km and 101.81 kPa, respectively, as delivered by the National Climate Data and Information Archive from Environment Canada. As the airborne LiDAR survey did not acquire any information regarding the atmospheric conditions, these archived climate data were used for atmospheric correction.

Canada

Strip 1 (East to West)

USA
Strip 2 (West to East)

North Vancouver

Vancouver

Burnaby

Strip 3 (East to West)

Richmond Surrey
0 125 250 500 750 1,000 Meters

  Figure 3.3: Study area in the British Columbia Institute of Technology, Vancouver, B.C., Canada

Table 3.1 summarizes the LiDAR system configuration and data specification, and Table 3.2 summarizes the information of the three LiDAR data strips. The LiDAR sensor used was Leica ALS50 operating with 1.064 µm wavelength, 0.33 mrad beam divergence, and 83 kHz pulse repetition frequency. Three LiDAR data strips were acquired where the 1st and the 3rd strips were scanned from East to West and the middle strip (2nd strip) was scanned in reverse direction (West to East). The overlapping area of the first two scans (strips 1 and 2) and the last two scans (strips 2 and 3) were about 30% and 25%, respectively. The average flying height of all scans was approximate 600 m resulting in a point density of 4 to 5 points per meter square. The acquired data consisted of a 3D point cloud with multiple returns (up to 4 returns at maximum) in LAS format together with the trajectory data. The LAS data file stored the xyz coordinates, the linearized intensity value in 8 bit, the number of the given return, the total number of returns, and the time of each pulse of the point cloud. The LAS 30

31

CHAPTER 3. RADIOMETRIC CORRECTION

file was converted into an ASCII file using Lastools 9 . The trajectory data stored the time and the xyz coordinates of the LiDAR sensor when the LiDAR data was captured during the flight. The dataset also contained an ortho-rectified aerial imagery which was produced using the aerial photos captured during the same flight mission. The ortho-rectified aerial imagery consisted of three bands (Red, Green and Blue) with 0.5 m spatial resolution. Figs. 3.4 and 3.5 show the collected airborne LiDAR data in 2D and 3D views, respectively. Table 3.1: Airborne LiDAR system settings (left) and data specification (right) System Parameters LiDAR Sensor Pulse Repetition Frequency Beam Divergence Wavelength () Flying Height (h ) Flying Speed (v ) Settings Leica ALS50 83 kHz 0.33 mrad 1.064 µm 600 m 40 ms-1 Data Specification Number of Strips Mean Point Density (PD ) Mean Point Spacing (PS ) Number of Returns Intensity (I ) Aerial Photos Settings 3 4.3 points/m2 0.48 m 4 0 - 255 (8 bit) RGB in 0.5 m

Table 3.2: Data Configuration of the three LiDAR data strips Strip 1 Direction Number of Points Time East to West 1,705,016 14:52:00 to 14:52:23 Strip 2 West to East 1,362,273 14:55:40 to 14:55:59 Strip 3 East to West 1,325,717 15:04:46 to 15:05:06

The "Quasi-Rigorous" method was implemented for geometric calibration of the LiDAR data point cloud by our research collaborator from the University of Calgary (Habib et al., 2010). This procedure utilized the LiDAR data in overlapping strips together with control points for estimating the biases in the system parameters so as to reduce the discrepancies between conjugate surface elements. The estimated biases in the system parameters were then used to reconstruct the adjusted LiDAR point cloud coordinates in different strips and an iterative process was conducted to make a better estimate of the system biases. After convergence, the adjusted coordinates were used to compute the corrected ranges (r ) and scan angles (). For the geometrically calibrated LiDAR data, the vertical and horizontal accuracies were about ±20cm and ±8cm, respectively. For more details regarding the implementation of "Quasi-Rigorous" calibration procedure, interested readers can refer to Habib et al. (2010).
9

http://www.cs.unc.edu/ isenburg/lastools/

31

CHAPTER 3. RADIOMETRIC CORRECTION

32

  airborne LiDAR data Figure 3.4: 2D view of the Fig.3.4.2DviewoftheairborneLiDARdata 32

33

CHAPTER 3. RADIOMETRIC CORRECTION







 

Figure 3.5: 3D view of the airborne LiDAR data
Fig.3.5.3DviewoftheairborneLiDARdata

3.2.2

Design of Experiment and Evaluation

Following the method in Section 3.1, radiometric correction was applied to the airborne LiDAR intensity data based on the radar (range) equation. The LiDAR dataset was displayed in the ESRI® ArcGISTM 9.3 platform where the core of the correction model was built by using ArcObjects and Visual Basic Applications (VBA). To evaluate the effects of the proposed atmospheric attenuation and the incidence angle in the correction model, five rounds of correction were conducted on the intensity data with different settings as stated below:1. Radiometric correction using range and scan angle, the corrected intensity is named as RCI R SA hereafter; 2. Radiometric correction using range, scan angle and atmospheric correction, the corrected intensity is named as RCI R SA AC hereafter; 3. Radiometric correction using range and incidence angle, the corrected intensity is named as RCI R IA hereafter; 4. Radiometric correction using range, incidence angle and atmospheric correction, the corrected intensity is named as RCI R IA AC hereafter; and 33

CHAPTER 3. RADIOMETRIC CORRECTION

34

5. Radiometric correction using range, scan angle, incidence angle and atmospheric correction where the selection of either scan angle or incidence angle is controlled by the slope with 40 , the corrected intensity is named as RCI R SA IA AC hereafter. In terms of computational complexity, there was no significant difference in the data processing time amongst the five trials since all parameters were appeared in the radar (range) equation regardless of the trials. By interpolating the LiDAR data points in ArcGIS using "void filling" method, intensity images were generated and exported in TIFF format with 0.4 m resolution. After that, we assessed the homogeneity of the intensity data before and after radiometric correction. So far, there is no established standard method in remote sensing for evaluating the homogeneity of intensity data. Ground truth is a desirable approach for the evaluation, but in situ measurements by spectroradiometer were not available in this study. Though aerial photos were acquired during the same flight of the LiDAR survey, the aerial photos were not captured in the same wavelength as the LiDAR sensor did. Therefore, the aerial photos were used as a reference for (a) visually selecting samples and (b) accuracy assessment of land cover classification, which is covered in Chapter 5. Since identical reference was not achievable, we imitated the statistical evaluation methods adopted in the correction of magnetic resonance image (MRI) as summarized in Hou (2006) and Vovk et al. (2007). A number of approaches were proposed to evaluate the MRI correction. The first approach is to assess the variance of the entire or partial dataset, which is supposed to be reduced after correction. Nevertheless, the results could be misleading as the units of the intensity are different before and after correction (i.e., original intensity is equivalent to the received laser power where correction intensity is related to the spectral reflectance of the illuminated object). The second approach is to assess the coefficient of variation which is computed by dividing the variance of a class  i (e.g., a number of selected areas representing grassland) by its mean. This approach is scale-invariant which can overcome the limitation of the first method. cv (i ) =  2 (i ) µ(i ) (3.27)

In this context, smaller cv (i ) corresponds to a smaller variation of intensity within the land cover class. This thus acts as an indicator of better radiometric correction performance. Other approaches such as classification/segmentation can be used to indirectly evaluate the effects of the intensity correction. As such, we assessed the accuracy of different land cover classification scenarios, which are discussed in Chapter 5. In this study, ten evenly distributed target areas were identified for each of the land cover features (building, grass, road, soil and tree) in each LiDAR data strip for computing the coefficient of variation (cv ). These target areas were intentionally selected in homogeneous surface with reference to the ortho-rectified 34

35

CHAPTER 3. RADIOMETRIC CORRECTION

aerial imagery. Fig. 3.6(a) to 3.6(c) shows the distribution of the target sample areas for the five land cover features for data strip 1 to 3, respectively.

 

(a)

 

(b)

 

(c)

Figure 3.6: Distribution of homogeneous sample areas for computing the coefficient of variation in (a) data strip 1, (b) data strip 2 and (c) data strip 3 35

CHAPTER 3. RADIOMETRIC CORRECTION

36

3.3
3.3.1

Results and Analysis
Visual Inspection

Figs. 3.7(a) to 3.7(f) show the original intensity (OI), RCI R SA, RCI R SA AC, RCI R IA, RCI R IA AC and RCI R SA IA AC, respectively, in LiDAR data strip 1. Figs. 3.8(a) to 3.8(f) show the OI, RCI R SA, RCI R SA AC, RCI R IA, RCI R IA AC and RCI R SA IA AC, respectively, in LiDAR data strip 2. Figs. 3.9(a) to 3.9(f) show the OI, RCI R SA, RCI R SA AC, RCI R IA, RCI R IA AC and RCI R SA IA AC, respectively, in LiDAR data strip 3. As shown in the OI images (Figs. 3.7(a), 3.8(a) and 3.9(a)), the ground features were displayed in darker tone (lower intensity) while the grass covers showed brighter tone (higher intensity) compared to the ground. Though small dots of peak intensity were found along the main roads and parking lots; these can be explained due to the existence of vehicles and road markings which have high reflectance in near-infrared spectrum (Berdahl and Bretz, 1997; Yang et al., 2012). The intensity values of building rooftops were homogeneous; however, the intensity of a few BCIT campus buildings were mixed with the intensity of the road features due to the same paved material (i.e., asphalt). Tree clusters, particularly those situated in the West of the study area, were easily distinguished according to the morphology; however, the texture of canopies within the intensity image was found to be non-uniform (rough). Therefore, high variance of intensity values would be expected in the tree features. By visually comparing the intensity images, the patterns and magnitudes of the corrected intensity data using scan angle (RCI R SA and RCI R SA AC) and the proposed dataset (RCI R SA IA AC) were similar to OI. On the other hand, it is apparent that the intensity data corrected using the incidence angle (RCI R IA and RCI R IA AC) showed significant difference compared to the original intensity. The tree clusters showed high intensity values after radiometric correction. The boundaries of BCIT campus buildings were discernible in these two types of imagery. The contrast amongst other features (such as grass, road, sidewalks, etc.) was decreased, but distinguishable. However, the effects of atmospheric correction were not noticeable in the results, regardless of using scan angle or incidence angle in radiometric correction. Therefore, qualitative analysis was carried out for in-depth comparison.

3.3.2

Coefficient of Variation

Table 3.3 and Fig. 3.10 show the cv for the five land cover features (building, grass, road, soil and tree) on the original intensity data and the five different corrected intensity data, and Table 3.4 shows the percentage change in cv of the corrected intensity data. Amongst all the LiDAR data strips, the cv of building generated from OI was the smallest (from 0.962 to 36

37

CHAPTER 3. RADIOMETRIC CORRECTION

(a) OI



(b) RCI R SA

 


(c) RCI R SA AC

 

(d) RCI R IA

  

(e) RCI R IA AC

(f) RCI R SA IA AC

Figure 3.7: Airborne LiDAR intensity images (data strip 1) before and after radiometric correction 37

CHAPTER 3. RADIOMETRIC CORRECTION

38

(a) OI

 

(b) RCI R SA




(c) RCI R SA AC





(d) RCI R IA

 
(e) RCI R IA AC



(f) RCI R SA IA AC

Figure 3.8: Airborne LiDAR intensity images (data strip 2) before and after radiometric correction 38

39

CHAPTER 3. RADIOMETRIC CORRECTION

(a) OI



(b) RCI R SA

 


(c) RCI R SA AC

 

(d) RCI R IA

  

(e) RCI R IA AC

(f) RCI R SA IA AC

Figure 3.9: Airborne LiDAR intensity images (data strip 3) before and after radiometric correction 39

CHAPTER 3. RADIOMETRIC CORRECTION

40

2.144) amongst all the land cover types. Reduction of cv between 0.4% to 11.3% was found on the intensity data corrected by using range and scan angle only (RCI R SA). By adding the atmospheric attenuation factor, the cv was further reduced by 45% in data strips 1 to 3. Such argument was valid in the rest of land cover types amongst the three datasets. For instance, the cv of grass samples decreased 17% to 35% in the RCI R SA and the values were further reduced by 52% to 61% in RCI R SA AC; the cv of road samples were reduced 3% to 11% in RCI R SA and the values were further dropped by 44% to 48% in RCI R SA AC . Although the cv of tree samples were relatively higher (7.781 to 9.737) than the others, the RCI R SA and RCI R SA AC still demonstrated a reduction of 10% to 21% and 48% to 53%, respectively, in this sample. Up to this point, it is proven that radiometric correction using the range and scan angle increases the land cover homogeneity as inferred by the modified LiDAR intensity readings. With the proposed atmospheric attenuation, further reduction of cv can be achieved which proves the effectiveness of such factor in the radiometric correction process. Table 3.3: Coefficient of variation of five land cover features generated from the original and corrected intensity data Building OI RCI R SA RCI R SA AC RCI R IA RCI R IA AC RCI R SA IA AC OI RCI R SA RCI R SA AC RCI R IA RCI R IA AC RCI R SA IA AC OI RCI R SA RCI R SA AC RCI R IA RCI R IA AC RCI R SA IA AC Grass Road Soil 3.566 2.663 0.799 1.077 0.799 0.783 3.925 3.154 1.837 7.435 9.756 0.963 2.815 2.244 1.326 5.954 6.482 0.719 Tree 9.737 7.730 4.546 83.075 82.624 2.525 8.990 8.064 4.674 86.116 84.957 2.437 7.781 6.904 4.021 75.206 74.344 2.076

LiDAR Data Strip 1 1.192 3.415 3.992 1.057 2.204 3.554 0.611 1.327 2.062 4.270 5.234 6.486 2.965 3.691 4.634 0.307 0.626 1.029 LiDAR Data Strip 2 0.962 1.659 1.538 0.910 1.208 1.498 0.522 0.700 0.857 0.370 0.930 0.600 0.265 0.677 0.429 0.265 0.371 0.429 LiDAR Data Strip 3 2.144 8.120 2.395 2.136 6.735 2.253 1.220 3.938 1.302 4.086 2.772 2.598 2.904 2.026 1.893 0.654 1.999 0.668 40

41
10 Coefficient ofVariation Coefficient Coefficient ofVariation ofVariation 9 10 10 8 9 9 7 8 8 6 7 7 5 6 6 4 5 5 3 4 4 2 3 3 1 2 2 0 1 1 0 0 10 Coefficient ofVariation Coefficient Coefficient ofVariation ofVariation 9 10 10 8 9 9 7 8 8 6 7 7 5 6 6 4 5 5 3 4 4 2 3 3 1 2 2 0 1 1 0 0 10 Coefficient ofVariation Coefficient Coefficient ofVariation ofVariation 9 10 10 8 9 9 7 8 8 6 7 7 5 6 6 4 5 5 3 4 4 2 3 3 1 2 2 0 1 1 0 0 Building Building Building Grass Grass Grass Building Building Building Grass Grass Grass Building Building Building Grass Grass Grass

CHAPTER 3. RADIOMETRIC CORRECTION
83.075 82.624 83.075 82.624 83.075 82.624

OI OI RC_R_SA OI RC_R_SA RC_R_SA_AC RC_R_SA RC_R_SA_AC RC_R_IA RC_R_SA_AC RC_R_IA RC_R_IA_AC RC_R_IA RC_R_IA_AC RC_R_SA_IA_AC RC_R_IA_AC RC_R_SA_IA_AC RC_R_SA_IA_AC Road Soil Tree

(a)

Road LiDAR Road

data

Soil strip Soil

1

Tree Tree 84.957 86.116
86.116 84.957 86.116 84.957

     
OI OI RC_R_SA OI RC_R_SA RC_R_SA_AC RC_R_SA RC_R_SA_AC RC_R_IA RC_R_SA_AC RC_R_IA RC_R_IA_AC RC_R_IA RC_R_IA_AC RC_R_SA_IA_AC RC_R_IA_AC RC_R_SA_IA_AC RC_R_SA_IA_AC

Road Road Road

Soil Soil Soil

Tree Tree Tree 74.344 75.206
75.206 74.344 75.206 74.344

(b) LiDAR data strip 2

     
OI OI RC_R_SA OI RC_R_SA RC_R_SA_AC RC_R_SA RC_R_SA_AC RC_R_IA RC_R_SA_AC RC_R_IA RC_R_IA_AC RC_R_IA RC_R_IA_AC RC_R_SA_IA_AC RC_R_IA_AC RC_R_SA_IA_AC RC_R_SA_IA_AC

Road Road Road

Soil Soil Soil

Tree Tree Tree

     

(c) LiDAR data strip 3

Figure 3.10: Coefficient of variation of five land cover features generated from the original and corrected intensity data

In the results of corrected intensity using range and incidence angle, the argument of cv reduction was no longer stood. In the RCI R IA datasets from LiDAR data strips 1 to 3, most of the results were recorded with an increase of cv . In the building samples, the cv was raised 41

CHAPTER 3. RADIOMETRIC CORRECTION Table 3.4: Percentage change in coefficient of variation Building RCI R SA RCI R SA AC RCI R IA RCI R IA AC RCI R SA IA AC RCI R SA RCI R SA AC RCI R IA RCI R IA AC RCI R SA IA AC RCI R SA RCI R SA AC RCI R IA RCI R IA AC RCI R SA IA AC Grass Road      Soil 25.3% 77.6% 69.8% 77.6% 78.0% Tree  20.6%  53.3%  753.2%  748.6%  74.1%  10.3%  48.0%  857.9%  845.0%  72.9%  11.3%  48.3%  866.5%  855.4%  73.3%

42

LiDAR Data Strip 1  11.3%  35.5%  11.0%  48.7%  61.2%  48.4%  258.2%  53.3%  62.5%  148.7%  8.1%  16.1%  74.2%  81.7%  74.2% LiDAR Data Strip 2  5.3%  27.2%  2.6%  45.7%  57.8%  44.3%  61.5%  43.9%  61.0%  72.4%  59.2%  72.1%  72.4%  77.6%  72.1% LiDAR Data Strip 3  0.4%  17.1%  6.0%  43.1%  51.5%  45.6%  90.6%  65.9%  8.5%  35.5%  75.1%  21.0%  69.5%  75.4%  72.1%

 19.6%  53.2%  89.4%  148.5%  75.5%  20.3%  52.9%  111.5%  130.2%  74.5%

by two to three times in data strips 1 and 3, while contradictorily, a decrease of cv (61.5%) was recorded in the building samples obtained from data strip 2. This can be explained by considering that the samples acquired in data strips 1 and 3 were mostly located on inclined rooftops of small houses where the samples of data strip 2 were mainly located on the flat rooftops of BCIT campus buildings. Such large fluctuations in cv also appeared in the grass samples (from 66% to 53%), road samples (from 61% to 62%) and soil samples (from 70% to 111%). It is worth noting that the elevation in the South of the study area is higher than the elevation in the North of the study area (See Fig. 3.4), the change in slope would cause the increase of incidence angle resulting in the over-correction effects as reported in the previous literatures for satellite remote sensing sensors (Ria~ no et al., 2003; Soenen et al., 2005). In the tree samples, the cv even spiked from 10 (in OI) to 80 in RCI R IA and RCI R IA AC datasets. Adding the atmospheric attenuation factor slightly relieved the over-correction effects or further reduced the cv , the ultimate solution of radiometric correction should combine the use of both scan angle and incidence angle together with the proposed atmospheric attenuation factor. As such, a new processing scheme was proposed in Section 3.1.4 by using the slope as a threshold value in selecting either using the incidence angle (when slope 40) or scan angle (when slope 42

43

CHAPTER 3. RADIOMETRIC CORRECTION

> 40) in the radiometric correction process. The cv obtained from the results derived by this approach (RCI R SA IA AC) reached the smallest values as shown in Tables 3.3 and 3.4. The cv values decreased ranging from 70% to 82% in the five land cover types where the results yielded the best amongst all trials and datasets. With respect to the significant reduction in cv , the proposed approach can counteract the over-correction effects that occur when the incidence angle approaches 90 , and thus produce improvement of land cover homogeneity for all the land cover types after radiometric correction.

3.4

Chapter Summary

In this chapter, a radiometric correction model based on the radar (range) equation was presented. The proposed model included a set of empirical models for the computation of atmospheric attenuation and formulas for computing the incidence angle based on the GPS trajectory and LiDAR derived TIN model. As over-correction has been previously reported when using incidence angle in radiometric correction (Shaker et al., 2011), this thesis research proposed to utilize the slope as a threshold to control either using scan angle (when slope > 40) or incidence angle (when slope  40) in the radiometric correction process. Five rounds of correction were conducted on the intensity data in order to evaluate the impacts of scan angle, incidence angle and atmospheric attenuation on the results. The coefficient of variation was assessed in five different land cover samples (building, grass, road, soil and tree) generated from the original and corrected intensity data. Regardless of the land cover features, most of the cv values were significantly reduced by an average of 15% and 52% in RCI R SA and RCI R SA AC, respectively. In the radiometrically corrected intensity dataset using incidence angle (RCI R IA and RCI R IA AC), reduction of cv was not guaranteed. Increase of cv was found in a few land cover samples ranging from 8% to 866%. The significant increase of cv was mostly found in tree samples. In the proposed RCI R SA IA AC, experimental results demonstrated that the cv within the same land cover feature was reduced by 70% to 82%. To conclude, the proposed approach combines the merits of using the scan angle and incidence angle in the radiometric correction process. All the cv values were significantly reduced across all land cover features. In addition, the proposed atmospheric attenuation factor demonstrated its usefulness in further reducing the cv . As the intensity homogeneity within the same land cover type was improved, it is expected to achieve higher accuracy of land cover classification when using the corrected intensity data, which is covered in Chapter 5.

43

Chapter 4

Radiometric Normalization
This chapter presents the approach for radiometric normalization of multiple airborne LiDAR intensity data strips. Though radiometric correction was applied to the LiDAR intensity data, and intensity discrepancy still appeared when combining the overlapping LiDAR data strips. Such a discrepancy represents a source of noise which may degrade classification accuracy. To resolve the radiometric misalignment, the thesis proposes a normalization model to match the sub-histograms amongst the multiple LiDAR intensity data. The criterion to split the entire intensity histogram into sub-histograms was based on the Gaussian mixture modeling technique. Radiometric normalization was implemented by matching the corresponding sub-histogram between the LiDAR data strips using histogram equalization. The proposed normalization was applied to original intensity data and radiometrically corrected intensity data for the entire block of LiDAR data strips. Four study areas were identified in the overlapping regions for analysis of results. Finally, land cover homogeneity was again assessed by studying the coefficient of variation of different land cover features before and after radiometric normalization.

4.1

Introduction

Recalling the research goal as stated in Chapter 1, this thesis aims to improve the intensity homogeneity within the same type of land cover features. After radiometric correction, variability in single strip LiDAR intensity data at nadir and maximum swath were significantly reduced as demonstrated in the previous chapter. A question now arises, "How would the results appear when combining multiple overlapping LiDAR intensity?" Fig. 4.1 shows an intensity image combined by two different scans of LiDAR flight. Obviously, the result of combining intensity data included a significant line stripping problem which represented a source of systematic noise. Radiometric correction did not perfectly reduce the discrepancy between the two LiDAR data 45

CHAPTER 4. RADIOMETRIC NORMALIZATION

46

strips where line stripping problem occurred in the result intensity image. The main reason for such discrepancy was mainly due to the assumption of gain factor as constant in the radar (range) equation.
1stScan 2ndScan Flying Direction Flying Height 2ndScan IntensityImage  1stScan LaserFootprints 

LineStripping Noise 

Figure 4.1: Result of combining intensity data acquired from two overlapping scans The gain factor (or automatic gain control, AGC) aims to control the range of the recorded intensity within the radiometric resolution, for example, 0 to 255 for an 8 bit intensity data. Vain et al. (2010) discussed the principal of AGC as follows: when the LiDAR sensor emits laser pulse on a low reflective object (e.g., water bodies), a null return may be recorded and thus the AGC would be automatically increased. When the LiDAR sensor flies over highly reflective objects, intensity values over 255 may be obtained, and thus the AGC would be adjusted. Although few proprietary software bundled with LiDAR sensor are used to normalize the intensity value from AGC on to AGC off, the method of AGC is not disclosed by the sensor manufacturer where the technique to remove the effects of AGC remains questionable. Recently, Korpela et al. (2010) and Vain et al. (2010) attempted to model the effects of AGC by using two different linear empirical models which shed the light on the black box of AGC. Based on the empirical formulas, the effects of AGC are controlled by a scale factor and a shift (offset). As a result, the transformation equation between the intensity data with AGC-on and AGC-off should be in a form of piecewise linear function. Though fitting a piecewise linear function in a joint intensity histogram (or comparagram) between two identical images has been demonstrated for color mapping in computer science studies (Mann 2000; Candocia, 2003; Candocia 2005; Wu et al., 2010), such an approach is not viable in airborne LiDAR intensity data since the LiDAR data points between two strips are not suited at the exact location. Therefore, this thesis proposes to radiometrically align the intensity data amongst different strips based on a sub-histogram matching technique. 46

47
1stStrip(Reference)

CHAPTER 4. RADIOMETRIC NORMALIZATION
2ndStrip nthStrip .................

Intensity(I1)

Intensity(I2)

Intensity(In)

Histogram(H1)

Histogram(H2)

Histogram(Hn)

GMM(1)
Iteration

GMM(2)
Iteration

GMM(n)
Iteration

Mean

Variance

Weight

Mean

Variance

Weight

Mean

Variance

Weight

ComputeIntersectionPoints

ComputeIntersectionPoints

ComputeIntersectionPoints

IntersectionPointsP11...P1k1

IntersectionPointsP21...P2k1

IntersectionPointsPn1...Pnk1

SubhistogramMatching(Strips1&2)

SubhistogramMatching(Strips1&n)

NormalizedIntensity(NI2)

NormalizedIntensity(NIn)  

Figure 4.2: Overall workflow for radiometric normalization

4.2
4.2.1

Method
Overall Workflow

Fig. 4.2 shows the overall workflow for radiometric normalization of multiple LiDAR intensity data. The intensity data here refers to the radiometrically corrected intensity data. Nevertheless, the method can also be applied to the original intensity data if radiometric correction cannot be achieved (e.g., GPS trajectory data is not available). Firstly, overlapping areas for the 1st to the nth LiDAR data strips were identified in which the area is preferable to have a variety of land cover features covering a wide range of intensity values. Histograms (H1 to Hn ) of the overlapping LiDAR data strips were generated individually from the intensity data (I1 to In ). Gaussian mixture modeling technique was applied to the histogram in order to fit a Gaussian component for each individual sub-histogram. The intersection points, which were used to partition the histogram into sub-histograms, were derived by finding the intersection points 47

CHAPTER 4. RADIOMETRIC NORMALIZATION

48

of the adjacent Gaussian components. The process was then repeated for all the histograms generated from the overlapping LiDAR intensity data strips. Finally, sub-histogram matching was carried out based on the histogram equalization techniques so as to normalize the intensity of 2nd to nth LiDAR data strips with reference to the intensity of the 1st LiDAR data strip. In the coming section 4.2.2, we follow the notation of GMM as defined by Lai et al. (2012) for presenting the mathematical model of radiometric normalization.

4.2.2

Gaussian Mixture Model

Consider a LiDAR dataset X with N number of points; X = {x1 , x2 , , xn , , xN } where 1  n  N . For a 8 bit LiDAR data, the intensity value I lies between 0 to 255. The intensity of LiDAR data point xn is denoted as I (xn ). Let nI be the number of LiDAR data points with intensity I . The probability density function of nI over N is defined by: PI = nI N (4.1)

Given a histogram of the LiDAR dataset X , we need to partition the histogram into K subhistograms. Let i1 , i2 , . . . and iK -1 be the K -1 intersection points that partition the histogram with 2  K  255.The cumulative density function of each sub-histogram is calculated by:
i1 i2 255

c1 =
I =0

PI , c2 =

PI , . . . , c K =
I =i1 +1

PI
I =iK -1 +1

(4.2)

As such, the sum of the cumulative density functions would be:
K

ck = 1 and 0  ck  1
k =1

(4.3)

Based on Eq. (4.2), the mean of each sub-histogram can be expressed as:i1 i2 255

µ1 =
I =0

PI I , µ2 = c1

I =i1 +1

PI I , . . . , µK = c2

I
I =iK -1 +1

PI cK

(4.4)

The variance for each of the K sub-histogram can be calculated by:
i1
2 1

i2

255

=
I =0

( I - µ1 )

2 PI

c1

2 , 2

=

( I - µ2 )
I =i1 +1

2 PI

c2

2 , . . . , K

=
I =iK -1 +1

(I - µ K )2

PI cK

(4.5)

48

49

CHAPTER 4. RADIOMETRIC NORMALIZATION Commonly, a histogram is in a form of multi-modal distribution which can be regarded as

a Gaussian Mixture Model (GMM). GMM is a parametric statistical model that assumes the data originates from a weighted sum of several Gaussian components. The probability of the LiDAR data point xn , with respect to the k th Gaussian component, is defined as:2 G (I ( x n ), µ k ,  k )=

   -(I (xn ) - µk )2   exp   2 2k 2   2k   1

(4.6)

The Gaussian Mixture Model for the intensity of data point xn is a weighted sum of the individual Gaussian components, and GMM is defined as follows:K

P (I (xn )) =
k =1

2  k G (I (x n ) , µ k ,  k )

(4.7)

where k denotes the weight of the k

th

Gaussian function under the condition 1 + 2 + . . . + k +

. . . + K = 1 and 0  k  1. The expectation maximization (EM) algorithm is commonly used to
2 2 } and weight {1 . . . K } . . . K estimate the set of parameters: mean {µ1 . . . µK }, variance {1

in Eq. (4.7) through an iterative process. Step 1: Initialization Partition the entire histogram into K sub-histograms with equal range. 2 2 for each sub-histogram . . . K Compute the mean µ1 . . . µK and variance 1 1 using Eq. (4.4) and (4.5). Assume the weight k as K . Compute the new weight (k,new ) for each sub-histogram using the following equation:
N

Step 2: New weight

k,new

1 = N

2  k G (I ( x n ), µ k ,  k ) K k=1 2) k G(I (xn ), µk , k

(4.8)

n=1

Step 3: New mean

Compute the new mean (µk,new ) for each sub-histogram using the following equation:
N
2) k G(I (xn ),µk ,k K 2) k G(I (xn ),µk ,k k =1

I (x n ) (4.9)

n=1

µk,new =

N

2) k G(I (xn ),µk ,k K 2) k G(I (xn ),µk ,k k=1

n=1

49

CHAPTER 4. RADIOMETRIC NORMALIZATION Step 4: New variance

50

2 ) for each sub-histogram using the folCompute the new variance (k,new lowing equation: N
2) k G(I (xn ),µk ,k K 2) k G(I (xn ),µk ,k k =1 2) k G(I (xn ),µk ,k K 2) n=1 k G(I (xn ),µk ,k k =1

(I ( x n ) - µ k )2 (4.10)

n=1 2 k,new

=

N

Step 5: Check

Check the difference of the new and previous values; i.e., If k,new - k < 2 2 < threshold, then - k threshold and µk,new - µk < threshold and k,new the process stop, else go to step 2. The threshold in this study is 10-3 .

4.2.3

Histogram Partition

After fitting the Gaussian component for each sub-histogram, the next step is to partition the entire histogram based on the intersection of adjacent Gaussian components. The intersection point can be found by equaling the function of any pairwise adjacent Gaussian components. Mathematically, it can be solved by:2 2 k G(I, µk , k ) = k+1 G(I, µk+1 , k +1 )

(4.11)

or equivalently    -(I - µk )2  = exp   2 2k 2   2k   k k k+1 =  k +1  k exp exp    -(I - µk+1 )2   exp   2 2k 2   + 1 2k   +1  k +1
-(I -µk+1 )2 2 2k +1 -( I -µ k ) 2 2 2k

(4.12)

(4.13)

       k k+1   -(I - µk+1 )2   -(I - µk )2        ln = -  2 2 2k 2   k+1 k      +1 k         k  k +1  2 2  2k k+1 ln     k +1 k     
2 2 2 = -k (I - µ k + 1 )2 +  k + 1 (I - µ k )

(4.14)

(4.15)

    k  k +1  2 2 2 2 2 2 2 2 2 2 2  =0 ( k -  ) I + 2 ( µ  - µ  ) I +  µ -  µ - 2   ln k +1 k k k +1  +1 k k +1 k k k +1 k k +1   k+1 k    50

(4.16)

51

CHAPTER 4. RADIOMETRIC NORMALIZATION

Eq. (4.16) can be represented in the form of:aI 2 + bI + c = 0 where a=
2 k +1 2 - k ;b

(4.17)

=

2 2(µk+1 k

2 - µk  k + 1 ); c

=

2 2 k +1 µ k

2 2 - k µ k +1

 µk k+1  2 2  - 2k k+1 ln µ    k +1 k   



 (4.18)

The solution of Eq. (4.17) would be: -b b2 ± 4ac I= 2a (4.19)

4.2.4

Sub-histogram Matching

Finally, the intersection points of all the pairwise adjacent Gaussian components are computed. Recalling the notation as defined in Section 4.2.2, the entire histogram is partitioned into K histogram based on the intersection points {0, i1 , i2 , . . . , iK -1 , 255}. Assuming the intensity data (XA ) of LiDAR data strip A is normalized with reference to the intensity data of (XB ) LiDAR data strip B, the intersection points of both strips' histogram are denoted
A A B B B as {0, iA 1 , i2 , . . . , iK -1 , 255} and {0, i1 , i2 , . . . , iK -1 , 255}. The sub-histogram matching process

first computes the cumulative probability density function for each sub-histogram of XA based on the intersection points:
iA 1 iA 2 255

cA 1

=
I =0

PI , cA 2

=

PI , . . . , c A K
I =iA 1 +1

=

PI
I =iA K -1 +1

(4.20)

The intensity value in each sub-histogram of XA is transformed to the intensity of the corresponding sub-histogram of XB by using the histogram equalization technique:
A f1 [I (xn )] = 0 + (iB 1 - 0)c1 B B A f2 [I (xn )] = iB 1 + (i2 - i1 )c2

(4.21) (4.22)

......
B A fK [I (xn )] = iB K -1 + (255 - iK -1 )cK

(4.23)

Combining all the transformation functions, the entire histogram equalization model is 51

CHAPTER 4. RADIOMETRIC NORMALIZATION represented as:F [I (xn )] = f1 [I (xn )]  f2 [I (xn )]  . . .  fK [I (xn )]

52

(4.24)

Based on the transformation function F , the intensity data in XA are normalized with reference to the intensity data in XB where the normalized intensity of XA is computed by F [I (xn )]I (xn )  XA . Fig. 4.3 demonstrates a pictogram example for the entire radiometric normalization process.
Scan A     Plot histogram for the overlapping LiDAR scans - Scan B Gaussian distribution

 (, ,  2 ) =
3

1





2 2



-( - )2 2 2

Initialize the Gaussian Mixture Model

( ) =
 =1

2    ,  , 

After iterations

Find intersections
0 102 165 255 0

Find intersections
81 157 255
2 2 (3 , 3 , 3 ) (1 , 1 , 1 ) 2 (2 , 2 , 2 )

The Gaussian component for each sub-histogram Partition histogram based on the intersection points
255

Histogram equalization for each sub-histogram
102

Scan B

157

1 ( ) =
 =0

 ;  ( ) =  2

165

 =103

 ;  ( ) =  3

255

=166

 

81 0 102 165 255

  ( ) = 0 + (81 - 0)1 ( ); 0   ( )  81 ( ( )) = 82 + (157 - 82)2 ( ); 82  ( )  157 ( ( )) = 158 + (255 - 158)3 ( ); 158   ( )  255

Scan A Sub-histogram matching (from A to B)
0 81 157 255 0 81 157 255

Normalize intensity A with reference to intensity B

Overlay intensity A and B

.

Figure 4.3: An example of GMM and sub-histogram matching from LiDAR data strip A to B

52

53

CHAPTER 4. RADIOMETRIC NORMALIZATION

4.3

Experimental Testing

As reported in Chapter 3, three data strips were acquired during the airborne LiDAR flight survey. Since the LiDAR data strip 2 falls in between the data strips 1 and 3 (refer to Fig. 3.3), the experimental work attempted to normalize the intensity data of these two data strips with reference to the intensity of data strip 2. Before generating the intensity histograms, thirty-two polygons were selected in the overlapping regions, and the intensity histograms of these polygons were investigated so as to make sure they followed normally distributed. These polygons covered different land cover features in the study area with a wide range of intensity values. The upper part of Fig. 4.4 shows the polygons located at the overlapping region of data strips 1 and 2, where the lower part shows the polygons located at the overlapping region of data strips 2 and 3. A number of programs were developed to implement the normalization process in MATLAB R2011b. Though MATLAB offers the gmdistribution function for GMM fitting based on EM algorithm, the programs were built based on the equations as reported in Section 4.2 in order to have a better control over the initialization and iteration.

 
Figure 4.4: Distribution of polygons for generating intensity histograms in the overlapping regions of LiDAR data strips The intensity of LiDAR data points within these polygons were first extracted from the corresponding LiDAR data strip. Both original intensity data and corrected intensity data were utilized to generate intensity histograms so that radiometric normalization can be implemented on both datasets. Since it was proven that the RCI R SA IA AC yielded the best land cover 53

CHAPTER 4. RADIOMETRIC NORMALIZATION

54

1600 1600 1400 1400 1200 1200 1000 1000 800 800 600 600 400 400 200 200 0 00 0

1600 1600 1400 1400 1200 1200 1000 1000 800 800 600 600 400 400 200 200 0 00 10 100 20 10 20 10 30 20 40 30 50 40 30 20 40 30 50 40 Intensity Intensity Intensity Intensity 60 50 60 50 70 60 70 60 70 70

4500 4500 4000 4000 3500 3500 3000 3000 Frequency Frequency 2500 2500 2000 2000 1500 1500 1000 1000 500 500 0 00 0 Frequency Frequency

4500 4500 4000 4000 3500 3500 3000 3000 2500 2500 2000 2000 1500 1500 1000 1000 500 500 0 00 5 0 5 10 5 10 5 10 15 10 15 Intensity Intensity 15 20 15 20 Intensity Intensity 20 25 20 25 25 30 25 30 30 30

Frequency Frequency

Frequency Frequency

 (a) Histogram  of OI  from data strip 1
1500 1500 1500 1500

(b) Histogram of RCI from data strip 1
4500 4500 4000 4000 3500 3500 4500 4500 4000 4000 3500 3500 3000 3000 Frequency Frequency 2500 2500 2000 2000 1500 1500 1000 1000 500 500 0 00 5 0 5 5 10 5 10 1015 15 20 1015 15 20 Intensity Intensity Intensity Intensity 20 25 20 25 25 25

1000 1000 Frequency Frequency Frequency Frequency

1000 1000 Frequency Frequency 500 500 0 0 10 0 10 0 10 20 10 20 20 30 20 30 Intensity Intensity 30 40 30 40 Intensity Intensity 40 50 40 50 50 60 50 60 60 60

3000 3000 2500 2500 2000 2000 1500 1500 1000 1000 500 500

500 500

0 00 0

0 00 0

 of OI from data strip 2 (c) Histogram





(d) Histogram of RCI from data strip 2

Figure 4.5: Intensity histograms generated using polygons located at the overlapping region of LiDAR data strips 1 and 2

homogeneity as reported in Chapter 3, the RCI R SA IA AC datasets were used as the corrected intensity, denoted as RCI, in the rest of the experiment in this chapter. Figs. 4.5 and 4.6 show the intensity histograms (OI and RCI) generated using the polygons acquired in the overlapping areas located at data strips 1 and 2, and data strips 2 and 3, respectively. The intensity histograms were in tri-modal distribution in Fig. 4.5 and bi-modal distribution in Fig. 4.6 with similar shape and appearance between the histograms of OI and those of RCI. In the histograms of LiDAR data strips 1 and 2 (Fig. 4.5), the maximum intensity value in OI was found to be between 60 and 70, whereas the maximum intensity in RCI was within 20 to 25. The reason for the significant reduction of intensity range was because the values of RCI were in float data type (unlike OI in integer data type); therefore, the histograms shown 54

55

CHAPTER 4. RADIOMETRIC NORMALIZATION

in Fig. 4.5(b), 4.5(d), 4.6(b) and 4.6(d) were generated with a round-up process. However, in the experimental computations, the processes were conducted based on its corresponding data type. In Fig. 4.6, a slightly bigger difference in the intensity range between OI and RCI was observed. In the histograms of data strip 2, the maximum intensity reached to 56 and 34 in the OI and RCI respectively, while the maximum intensity values were 37 (OI) and 24 (RCI) in the histograms of data strip 3. Compared to the combined intensity in data strips 1 and 2, it is foreseen that the line stripping problem in the combined data strips 2 and 3 would be manifest since the range of the intensity was significantly different.
800 800 700 700 600 600 500 500 400 400 300 300 200 200 100 100 0 00 0 800 800 700 700 600 600 500 500 400 400 300 300 200 200 100 100 0 0 10 0 10 0 10 20 10 20 20 30 20 30 Intensity Intensity 30 40 30 40 Intensity Intensity 40 50 40 50 50 60 50 60 60 60 1400 1400 1200 1200 1000 1000 Frequency Frequency 800 800 600 600 400 400 200 200 0 00 0 Frequency Frequency 1400 1400 1200 1200 1000 1000 800 800 600 600 400 400 200 200 0 00 5 50

Frequency Frequency

Frequency Frequency

105 105

15 10 20 15 25 20 15 10 20 15 25 20 Intensity Intensity Intensity Intensity

30 25 30 25

35 30 35 30

35 35

 (a) Histogram  of OI  from data strip 2
4000 4000 3500 3500 3000 3000 2500 2500 2000 2000 1500 1500 1000 1000 500 500 0 00 0 4000 4000 3500 3500 3000 3000 2500 2500 2000 2000 1500 1500 1000 1000 500 500 0 5 00 5 0 10 5 10 5 15 10 15 10 20 15 20 15 Intensity Intensity 25 20 30 25 25 20 30 25 Intensity Intensity 35 30 35 30 40 35 40 35 40 40

(b) Histogram of RCI from data strip 2
5000 5000 4500 4500 4000 4000 3500 3500 Frequency Frequency Frequency Frequency 3000 3000 2500 2500 2000 2000 1500 1500 1000 1000 500 500 0 00 0 5000 5000 4500 4500 4000 4000 3500 3500 3000 3000 2500 2500 2000 2000 1500 1500 1000 1000 500 500 0 00 5 0 5 5 10 5 10 1015 15 20 1015 15 20 Intensity Intensity Intensity Intensity 20 25 20 25 25 25

Frequency Frequency

Frequency Frequency

 of OI from data strip 3 (c) Histogram





(d) Histogram of RCI from data strip 3

Figure 4.6: Intensity histograms generated using polygons located at the overlapping region of LiDAR data strips 2 and 3 All the above intensity histograms were fitted with Gaussian components using the method proposed in Section 4.2.2. Taking the intensity histogram of OI of data strip 1 as an example 55

CHAPTER 4. RADIOMETRIC NORMALIZATION

56

(see Fig. 4.5(a)), the intensity was in a form of tri-modal distribution which were fitted with three Gaussian components. Initial values of means and variances were assigned for the three Gaussian components with µ1 = 19.1, µ2 = 22.0, µ3 = 40.0, 1 = 15.6, 2 = 19.6, and 3 = 14.7 in the initialization stage. After 40 iterations, all the results started to converge to their optimal values without further changes. As shown in Fig. 4.7(a), µ1 dropped from 19.1 to 6.6 after 35 iterations, where both µ2 and µ3 slightly increased from their initial values and then reached steady state at 20.2 and 44.2, respectively. All the variance showed similar trends as µ1 where the values of 1 , 2 , and 3 started at its initial values and gradually decreased to 2.2, 5.8 and 6.6, respectively after 37 iterations. Figs. 4.7 and 4.8 show the statistics of GMM generated from the OI and RCI intensity histograms generated from the LiDAR data strips 1 and 2, and LiDAR data strips 2 and 3, respectively. Figs. 4.9 and 4.10 show the fitted Gaussian components generated from the OI and RCI intensity histograms generated from the LiDAR data strips 1 and 2, and LiDAR data strips 2 and 3, respectively.
70 70 1 60 70 1 50 60 Intensity 40 50 30 40 20 30 10 20 0 10 10 2010 30 20 4030 5040 Number of iterations Number of iterations 60 50 60 20 2 1 3 2 1 3 2 1 3 2 3 18 20 16 2 1 3 2 1 3 2 1 3 2 3 18 14 16 12 Intensity 14 10 12 8 10 6 8 4 6 2 4 0 2 0 10 Intensity 20 1 18 20 16 1 18 14 16 12 14 10 12 8 10 6 8 4 6 2 4 0 2 0 2010 30 20 4030 5040 Number of iterations Number of iterations 60 50 60 2 1 3 2 1 3 2 1 3 2 3

60 70 50 60 Intensity 40 50 30 40 20 30 10 20 0 10

2 1

3 2

1 3

2 1

3 2

3

Intensity

Intensity

Intensity

0 60

10 Statistics 2010 30 20 4030 5040 60 50 from 60 (b) Statistics 10 20 10 GMM 30 20 generated 4030 5040 from 60 50 (a) ofNumber GMM generated of Number of iterations of iterations Number of iterations Number of iterations 60 20 the OI histogram of data strip 1  the RCI20 histogram of data strip 1                  
1 2 1

0



 

Intensity

60 3

3

2

1 3

2 1

3 2

3

18 20 16

18 20 16 1 18 14 16 12 Intensity 14 10 12 8 10 6 8 4 6 2 10 4 0 2 10 0

1

2

1

3 2

1 3

2 1

3 2

50 60 40 50 Intensity Intensity 30 40 20 30 10 20 0 10

50 60 1 40 50

2 1

3 2

1 3

2 1

3 2

3

18 14 16 12 Intensity 14 10 12 8 10 6 8 4 6 2

2 1

3 2

1 3

2 1

3 2

3

30 40 20 30 10 20

Intensity

Intensity

Intensity

0 10 10

2010 30 20 4030 5040 Number of iterations Number of iterations

60 50

60

4 0 2

Intensity

2010 30 20 4030 5040 Number of iterations Number of iterations

60 50

60

0

10

0

2010 30 20 4030 5040 Number of iterations Number of iterations





60 50

60

0

2010 30 20 4030 5040 Number of iterations Number of iterations

60 50

60

 (c) Statistics of GMM generated from (d) Statistics of GMM generated from the OI histogram of data strip 2 the RCI histogram of data strip 2

Figure 4.7: Statistics of GMM generated from the OI and RCI intensity histograms generated from the LiDAR data strips 1 and 2

56

57

CHAPTER 4. RADIOMETRIC NORMALIZATION

40 35 40 30 35 25 30 20 25 15 20 10 15 5 10 0 5 0

40 1 35 40 30 35 25 30 20 25 15 20 10 15 5 10 0 5 5 0 10 5 1510 20 15 25 20 Number of iterations Number of iterations 30 25 30 1 2 1 1 2 2 1 2 2 1 1 2 2 1 2

25

25 1 2 1 1 2 2 1 2

25 20

25 20

1

2 1

1 2

2 1

2

20 15 Intensity Intensity Intensity Intensity 5

20 15

Intensity Intensity

Intensity Intensity

15 10

15 10

10 5

10 5

5 0

5 0

10 5

1510 20 15 25 20 Number of iterations Number of iterations

30 25

30

25

5 10 5 1510 20 15 25 20 30 25 30 5 10 5 1510 20 15 25 20 30 25 (a) Statistics of Number GMM generated from (b) Statistics ofNumber GMM generated from Number of iterations of iterations of iterations Number of iterations 25 16 16 the OI histogram of data strip 2 the RCI histogram of data strip 2 1  2 1 1 2 2 1 2 1 2 1 1 2 2 1 25 20 14 16 1 2 1 1 2 2 1 2 12 14 10 12 8 10 6 8 4 6 2 4 14 16 12 14 10 12 8 10 6 8 4 6 2 4 0 5 2 0 10 5 1510 20 15 25 20 Number of iterations Number of iterations 1510 20 15 25 20 Number of iterations Number of iterations 4500 4500
4000 3500 3000 2500 2000 1500 1000 4000 3500 3000 2500 2000 1500 1000





0

0

30

2

25 20

1

2 1

1 2

2 1

2

20 15 Intensity Intensity Intensity Intensity

20 15 Intensity Intensity

15 10

15 10

10 5

10 5

5 0

5

5 0

10 5

1510 20 15 25 20 Number of iterations Number of iterations 1510 20 15 25 20 Number of iterations Number of iterations

30 25

30

0 2 0
1600 1400 1200 1000 Frequency

Intensity Intensity

30 25

30

0

5

0

10 5

30 25

30
1600 1400 1200 1000 Frequency 800 600 400 200

5

10 5

30 25

30

(c) Statistics of GMM generated from (d) Statistics of GMM generated from the OI histogram of data strip 3 the RCI histogram of data strip 3
Frequency 800 600 400 200

Figure 4.8: Statistics of GMM generated from the OI and RCI intensity histograms generated from the LiDAR data strips 2 and 3
500 500 0 -10 0 0 -10 100 20 10 30 20 40 30 50 40 Intensity Intensity 60 50 70 60 70 0 -5 0 -5 0 5 0 10 5 15 10 20 15 Intensity Intensity 25 20 30 25 30


1600 1400 1200 1000 Frequency Frequency 800 600 400 200 0 -10 1600 1400 1200 1000 Frequency Frequency Frequency 2500 2000 1500 400 200 0 0 -10 1000 500 0 -5 2500 2000 1500 1000 500 0 -5 0 0 30 25 -10 0 30-10 0 800 600 500 500 4500 4000 3500 3000 4500 4000 3500 3000 1000 Frequency 1000 1500 1500


4500 4000 3500 3000 Frequency 2500 2000 1500 1000 500 Frequency 4500 4000 3500 3000 2500 2000 1500 1000 500 0 -10 -5

100

20 10

30 20 40 30 50 40 Intensity Intensity

60 50

70 60

70

5 0

10 5 15 10 20 15 Intensity Intensity

25 20

10 0

20 10 30 20 40 30 Intensity Intensity

50 40

60 50

60

0 -10

Frequency

-5 0

5 0 10 5 15 10 Intensity Intensity

20 15

25 20

25


1500 1500


4500 4000 3500 4500 4000 3500 3000 Frequency 2500 2000 1500 1000 500 0 -10 -5

(a) Histogram of OI from (b) Histogram of RCI from (c) Histogram of OI from (d) Histogram of RCI from data strip 1 data strip 1 data strip 2 data strip 2
1000 Frequency Frequency 3000 2500 2000 1500 1000 500





1000 Frequency

500

500

Figure 4.9: Fitted Gaussian components in the OI and RCI intensity histograms generated from LiDAR data strips 1 and 2
0 -10 0 10 0 20 10 30 20 40 30 Intensity Intensity 50 40 60 50 60 0 -10 -5 0 5 0 10 5 15 10 Intensity Intensity 20 15 25 20 25

0 -10





57

800 700 600 500 Frequency Frequency 400 300 200 100

800 700 600 500 Frequency

1400

1400

1200

1200

1000 Frequency

1000

800

800

400 300

600

600

400 200 100 200

400

CHAPTER 4. RADIOMETRIC NORMALIZATION
0 -10 0 -10 0 10 0 20 10 30 20 40 30 Intensity Intensity 50 40 60 50 60

200

58
10 0 20 10 30 20 40 30 Intensity Intensity 50 40 60 50 60

0 -10

0 -10 0


800 700 600 500 Frequency Frequency 400 300 200 100 0 -10 800 700 600 500 Frequency Frequency 800 Frequency 800 400 300 400 200 100 0 -10 0 200 200 400 1000 500 0 60 50 -10 1000 1400 1400 4000 3500 3000 2500 Frequency 2000 1500 4000 3500 3000


5000 4500 4000 5000 4500 4000 3500 Frequency 3000 2500 2000 1500 1000 500 0 -50 05 5 10 10 15 Intensity Intensity 15 20 20 25 25

1200

1200

1000

1000

3500
2500

Frequency
10 0 20 10 30 20 40 30 Intensity Intensity 50 40 60 50 60

3000 2500 2000 1500 1000

2000 1500

600

600

500 0 60-10 0

500 0 -5

10 0

20 10 30 20 40 30 Intensity Intensity

50 40

60 50

60

0 -10

0 -10 0

10 0

20 10 30 20 40 30 Intensity Intensity

50 40


4000 3500 3000 2500 Frequency Frequency 2000 1500 1000 500 0 -10 4000 3500 3000


5000 4500 4000 3500 5000 4500 4000 3500 Frequency 3000 2500 2000 1500 1000 500 0 -50 05 5 10 10 15 Intensity Intensity 15 20 20 25 25

(a) Histogram of OI from (b) Histogram of RCI from (c) Histogram of OI from (d) Histogram of RCI from data strip 2 data strip 2 data strip 3 data strip 3





Figure 4.10: Fitted Gaussian components in the OI and RCI intensity histograms generated from LiDAR data strips 2 and 3
Frequency
2000 1500 1000

2500

3000 2500 2000 1500 1000

500 0 -10 0

500
10 0 20 10 30 20 40 30 Intensity Intensity 50 40 60 50 60

After fitting the Gaussian components, the entire intensity histogram was partitioned into 

0 -5

sub-histograms based on the method proposed in Section 4.2.3. By equaling the functions of a pair of neighbor Gaussian components, the intersection point between the two components was derived and regarded as the point for splitting the histogram. Table 4.1 summarizes the intersection points derived from all the aforementioned datasets. Although most of the intensity histograms were ended at its maximum value (e.g., maximum intensity of OI in data strip 1 =66), the value 255 was used as the end of the last sub-histogram scan since there were a few intensity data appearing between the maximum value and 255. Table 4.1: Computed intersection points for all the datasets OI Start IP IP IP End Start IP IP End *IP = Data Strip 1 Data Strip 2 1 1 11 6 31 25 66 56 255 255 Data Strip 2 Data Strip 3 1 1 16 6 56 37 255 255 Intersection Point RCI Data Strip 1 1 3 9 18 255 Data Strip 2 1 9 34 255 Data Strip 2 1 5 9 17 255 Data Strip 3 1 4 24 255

The derived intersection points, which represented the intensity range of the sub-histograms, were used for implementing the sub-histogram matching. As mentioned in Section 4.2.4, the 58

59

CHAPTER 4. RADIOMETRIC NORMALIZATION

matching technique was based on the histogram equalization which implemented in each subhistogram. For example, in the histograms of OI in LiDAR data strips 1 and 2, the 1st subhistogram of data strip 1 (with intensity range from 1 to 11) was used to compute the cumulative density function, and then histogram equalization was implemented to map the cumulative density function into the range of the 1st sub-histogram of data strip 2 (with intensity range from 1 to 6). With the histogram equalization function computed in each sub-histogram, the combined function appeared in a form of piecewise linear function which transforms the intensity of data strip 1 to the intensity of data strip 2. Fig. 4.11 shows the transformation function from data strip 1 to data strip 2, and data strip 3 to data strip 2. One should note that there were a few number of LiDAR data points with intensity values beyond the range of the histograms as shown in Fig. 4.6; therefore, stepwise curves were appeared in later region of Fig. 4.11(b).
250 250

250 250

200 200

200 200 Intensity of Data Strip 3 Intensity of Data Strip 3

Intensity of Data Strip 1

Intensity of Data Strip 1

150 150

150 150

100 100

100 100

50 50 OI OI RCIRCI 0 0 50 50 100 100 150 150 Intensity Intensity of Data of Data Strip Strip 2 2 200 200 250 250

50 50 OI OI RCIRCI 0 0 50 50 100 100 150 150 Intensity Intensity of Data of Data Strip Strip 2 2 200 200 250 250

 (a) 

(b)

 

Figure 4.11: Histogram equalization of (a) data strips 1 and 2 and (b) data strips 2 and 3 Finally, all the intensity of LiDAR data points in data strip 1 and 3 were normalized into the intensity range of data strip 2 based on the above histogram equalization functions. After that, all the LiDAR data points were combined for results and analysis. The original intensity were directly combined which is denoted as OI. The normalized OI of data strips 1 and 3 were combined with the OI of data strip 2, which is denoted as ONI in the rest of this chapter. The normalized RCI of data strips 1 and 3 were combined with the data RCI of data strip 2, which is named as RCNI hereafter. Intensity images were generated by interpolating the data points in all the aforementioned datasets. Similar to Chapter 3, the results and analysis were conducted based on visual inspection of the intensity images and coefficient of variation of different land cover samples. 59

CHAPTER 4. RADIOMETRIC NORMALIZATION

60

4.4
4.4.1

Results and Analysis
Visual Inspection

Radiometric normalization was applied to the original intensity data and radiometrically corrected intensity data in the entire LiDAR data strips 1 and 3 with reference to data strip 2. Four sub-areas in these two overlapping regions were selected for further examination. Figs. 4.12(a) to 4.12(d) show the aerial photo, OI, ONI and RCNI of an area including different land cover types in the overlapping region of LiDAR data strips 1 and 2. Systematic stripping noises were found on the building rooftop in the OI image (Fig. 4.12(b)). Such noises were somehow reduced in the ONI (Fig. 4.12(c)) where these noises were further reduced in the RCNI images (Fig. 4.12(d)).

   (a)

   (b)

   (c)

(d)  

Figure 4.12: (a) Aerial Photo, (b) OI, (c) ONI and (d) RCNI in an area located at the overlapping region of LiDAR data strips 1 and 2

   (a)

   (b)

   (c)

(d)  

Figure 4.13: (a) Aerial Photo, (b) OI, (c) ONI and (d) RCNI in an area located at the overlapping region of LiDAR data strips 1 and 2 Figs. 4.13(a) to 4.13(d) show the aerial photo, OI, ONI and RCNI in another area, which was located in the overlapping region of LiDAR data strips 1 and 2. In this example, the 60

61

CHAPTER 4. RADIOMETRIC NORMALIZATION

line stripping noises were manifest on the grass cover and the building rooftop. The ONI image seemed to have slight reduction on the variability of intensity while these noises were less obvious in the RCNI image. One should note that the building rooftops in these two examples were inclined; radiometric correction demonstrated a positive influence in reducing the intensity difference between the inclined surfaces. Fig. 4.14 demonstrates an example of inclined building rooftops in the same study area as Fig. 4.13. As shown in the aerial photo, a building roof with opposite inclined orientation was located at the North of the flight line. In the original intensity data, the intensity value on surface B (close to the aircraft) was much higher than the surface A where the cv of the entire rooftop was 1.308. Difference of intensity was observed in the surfaces A and B on the building rooftop. After applying radiometric correction, the cv value reduced 27% and reached 0.948. Therefore, radiometric correction improved the normalized intensity results compared to the results of ONI.
Coefficient of Variation
ROI = 1.308 RCI = 0.948

Same Material

Surface A Surface B

Flying Height

255

Surface B

0

Surface A
Original Intensity Corrected Intensity

Figure 4.14: Effects of radiometric correction on the same roof surface with opposite inclined orientation In the example of Figs. 4.15 and 4.16, the study areas were located at the overlapping region of LiDAR data strips 2 and 3, the stripping noise problem was extremely serious (comparable to those scan line corrector problem in satellite remote sensing sensor). Unlike the previous examples, the noises appeared on the ground, grass cover and building rooftops in a vertical direction (see Figs. 4.15(b) and 4.16(b)). After radiometric normalization, such discrepancy was significantly reduced in ONI and RCNI, leaving a few low level noises in the result images. However, the difference between both normalized intensity data (Fig. 4.15(c) versus Fig 4.15(d) or Fig. 4.16(c) versus Fig. 4.16(d)) was not visually distinguishable. Statistical methods should be applied to reveal the difference. 61

CHAPTER 4. RADIOMETRIC NORMALIZATION

62

   (a)

   (b)

   (c)

(d)  

Figure 4.15: (a) Aerial Photo, (b) OI, (c) ONI and (d) RCNI in an area located at the overlapping region of LiDAR data strips 2 and 3

   (a)

  

   (b)

   (c)

(d)  

Figure 4.16: (a) Aerial Photo, (b) OI, (c) ONI and (d) RCNI in an area located at the overlapping region of LiDAR data strips 2 and 3

4.4.2

Coefficient of Variation

Following the way of analysis in Chapter 3, the coefficient of variation in each of the land cover samples was computed. Fig. 4.17(a) to 4.17(d) show the distribution of land cover samples in the four sub-areas as shown in Section 4.4.1.

(a)

   1 Sub-area

  
(b)

   2 Sub-area

(c)

   Sub-area 3

(d)

   Sub-area 4

  

Figure 4.17: Distribution of land cover samples for computing the coefficient of variation 62

63

CHAPTER 4. RADIOMETRIC NORMALIZATION Table 4.2 shows the cv of five land cover features generated from OI, ONI and RCNI, and

Table 4.3 shows the percentage change in cv of the five land cover features generated from ONI and RCNI with respect to the OI. Overall speaking, most of the cv values were reduced in the results of ONI and all the cv values of RCNI were decreased as shown in Fig. 4.18. In the building samples, the cv values ranged from 1.117 to 2.285, and reduction of cv values from 10% and 62% were found in the ONI generated from data strips 1 and 2 (sub-areas 1 and 2), while an increase of cv (34%) was observed in the building rooftop of sub-area 3. Since the cv value was around 2.5, the noisy effect was not obvious. In the grass samples, most of the results were recorded with a decrease in cv ranging from 12% to 80% in all the study areas, except the ONI in sub-area 2 recorded with an 8.7% increase in cv . The cv of road samples were the lowest compared to other land cover samples. Except the study area in sub-area 3, the cv values of road samples were lower than 1 in the OI datasets. Decreases of cv were consistently shown in the RCNI ranging from 44% to 76%. In the data strips 1 and 2 (sub-areas 1 and 2), 22% to 66% of reduction in cv was achieved in ONI, while the cv of ONI in the overlapping region of data strips 2 and 3 (sub-areas 3 and 4) did not show any significant improvement.

Table 4.2: Coefficient of variation of five land cover features generated from the OI, ONI and RCNI Building Grass Road Soil Tree

Sub-area 1 in Fig. 4.17(a) OI ONI RCNI OI ONI RCNI OI ONI RCNI OI ONI RCNI 1.117 0.898 0.855 Nil 1.001 0.790 0.288 Nil 0.747 0.564 0.202 Nil Sub-area 2 in Fig. 4.17(b) 2.285 1.401 0.732 Nil 0.878 1.523 0.569 Nil 0.667 0.592 0.334 Nil Sub-area 3 in Fig. 4.17(c) 1.878 1.447 1.882 2.466 2.517 1.185 1.777 1.506 1.012 0.826 0.692 0.903 Sub-area 4 in Fig. 4.17(d) Nil Nil Nil 2.954 0.980 0.566 0.191 0.195 0.108 2.108 1.692 1.011 5.697 5.071 3.429 6.996 5.529 3.812 4.875 6.278 3.105 6.589 6.778 3.973

63

CHAPTER 4. RADIOMETRIC NORMALIZATION

64

66 66 Coefficient Coefficient of  of Variation Variation Coefficient Coefficient of  of Variation Variation 55 55 44 44 33 33 22 22 11 11 00 00 Building Building Building Building Road Road Road Road Grass Grass Grass Grass Tree Tree Tree Tree OI OI OI OI ONI ONI ONI ONI RCNI RCNI RCNI RCNI

88 88 77 77 66 66 55 55 44 44 33 33 22 22 11 11 00 00 Building Building Building Building

Coefficient Coefficient of  of Variation Variation Coefficient Coefficient of  of Variation Variation

OI OI OI OI ONI ONI ONI ONI RCNI RCNI RCNI RCNI

Road Road Road Road

Grass Grass Grass Grass

Tree Tree Tree Tree

(a) sub-area 1
77 77 66 66 55 55 44 44 33 33 22 22 11 11 00 00 Building Building Grass Grass Road Road Building Building Grass Grass Road Road 88 88 77 77 66 66 55 55 44 44 33 33 22 22 11 11 00 00

(b) sub-area 2

     

Coefficient Coefficient of  of Variation Variation Coefficient Coefficient of  of Variation Variation

OI OI OI OI ONI ONI ONI ONI RCNI RCNI RCNI RCNI

Coefficient Coefficient of  of Variation Variation Coefficient Coefficient of  of Variation Variation

OI OI OI OI ONI ONI ONI ONI RCNI RCNI RCNI RCNI

Soil Soil Soil Soil

Tree Tree Tree Tree

Grass Grass Grass Grass

Road Road Road Road

Soil Soil Soil Soil

Tree Tree Tree Tree

(c) sub-area 3

(d) sub-area 4

     

Figure 4.18: Coefficient of variation of five land cover features generated from the OI, ONI and RCNI Only two soil samples were found in the overlapping regions of LiDAR data strips 2 and 3. Both study areas were consistently found with reduction in cv . In sub-area 3, the cv of soil sample was 2.466, 1.5606 and 0.903 in the OI, ONI and RCNI dataset. In sub-area 4, similar reduction of cv was recorded where the corresponding cv values of OI, ONI and RCNI were 2.108, 1.692 and 1.011, respectively. Finally, similar to the results in Section 3.3.2, the cv values of tree samples were the highest amongst all the land cover features. In this land cover type, the cv of ONI showed a diversity of results: the first two study areas were exhibited a decrease in cv by 11% and 21%, while the cv of tree samples in the remaining study areas were increased by 3% and 29% in the ONI. Again, the RCNI outperformed than the ONI; all the cv of tree samples were reduced by 36% to 46% leading to the cv values bounded between 3 to 4. 64

65

CHAPTER 4. RADIOMETRIC NORMALIZATION Table 4.3: Percentage change in coefficient of variation Building ONI RCNI ONI RCNI ONI RCNI ONI RCNI       Grass Road Soil Tree  11.0%  39.8%  21.0%  45.5%  28.8%  36.3%  2.9%  39.7%

Sub-area 1 in Fig. 4.17(a) 10.4%  12.0%  66.3% Nil 33.1%  37.1%  76.4% Nil Sub-area 2 in Fig. 4.17(b) 61.6%  8.7%  22.3% Nil 70.8%  57.7%  54.5% Nil Sub-area 3 in Fig. 4.17(c) 34.0%  18.2%  5.6%  38.9% 46.2%  42.9%  63.2%  63.4% Sub-area 4 in Fig. 4.17(d) Nil  66.8%  1.7%  19.7% Nil  80.8%  43.6%  52.0%

4.5

Chapter Summary

In this chapter, a radiometric normalization model based on sub-histogram matching technique was presented. The principle of the model aimed to align and match the intensity sub-histogram of a data strip with reference to the intensity sub-histogram generated from a reference LiDAR data strip. The criterion to split the histogram into sub-histograms was based on fitting the Gaussian mixture components in the multi-modal histogram acquired in the overlapping region of the two LiDAR data strips. The proposed radiometric normalization method was applied to the radiometrically corrected intensity data for the entire LiDAR data strips 1 to 3 with reference to the LiDAR data strip 2. Since radiometric correction may be inapplicable in common practice (for instance, lack of GPS trajectory data or LiDAR data without time tag), the normalization model was also investigated using the original intensity data. After radiometric normalization, the line stripping problems were obviously resolved or even removed. Regardless of the land cover features, the coefficient of variation was significantly reduced after radiometric normalization in a range of 33% to 80% in the corrected intensity data. In two-thirds of the land cover samples, the results of ONI showed a decrease of cv by 6% to 67%; however, reduction of cv was not guaranteed in ONI where the rest of the land cover samples were reported with a cv increase by 2% to 34%. Based on the experimental results, the proposed normalization model works effectively on the radiometrically corrected intensity data in improving the land cover homogeneity. In addition, the experiment further justifies the effectiveness of the proposed correction model, particularly in reducing the intensity discrepancy in inclined rooftops. 65

Chapter 5

Land Cover Classification
Given the proposed radiometric correction and radiometric normalization in Chapters 3 and 4, respectively, the objective of this chapter is to assess the impact of these techniques on the LiDAR intensity data classification. This chapter describes in detail the design and experiment of land cover classification using airborne LiDAR intensity data under different scenarios. Two case studies are presented in this chapter. The first case evaluated the classification results using the original intensity and five radiometrically corrected intensity datasets of LiDAR data strip 2 (as presented in Chapter 3) for land cover classification. The second case assessed the classification results using all the datasets (OI, ONI and RCNI) in the four sub-areas as presented in Chapter 4. Accuracy assessment was conducted on all the classification results with reference to the ortho-rectified aerial imagery. Finally, a comparative study is presented to evaluate the overall accuracy and the kappa statistics of individual land cover feature derived from the classification results.

5.1

Overall Workflow

Fig. 5.1 shows the overall workflow of experimental testing for land cover classification. A number of LiDAR dataset including original intensity data, radiometrically corrected intensity data and radiometrically normalized intensity data were used for experimental testing. Before land cover classification, training sites were selected with reference to the high resolution orthorectified aerial imagery acquired during the airborne LiDAR survey. Polygon-based training sites were selected for different combinations of land cover classes. A commonly used pixel-based classification technique, maximum likelihood classifier, was applied to all the intensity datasets. Accuracy assessment was carried out on the classification results by using evenly distributed checkpoints generated from the ortho-rectified aerial imagery. Finally, classification accuracies 67

CHAPTER 5. LAND COVER CLASSIFICATION

68

amongst all the results were compared so as to investigate the effectiveness of the proposed radiometric correction and normalization models on the airborne LiDAR intensity data.
Original Intensity Corrected Intensity Normalized Intensity

MaximumLikelihoodClassification

TrainingSites

ClassificationResults

SelectionofTrainingSites

AccuracyAssessment

OrthorectifiedAerialPhoto

 
Figure 5.1: Overall workflow for land cover classification

5.2

LiDAR datasets

Two case studies were conducted to investigate the effects of the proposed radiometric correction and normalization models towards the airborne LiDAR intensity data for land cover classification. The first case aimed to evaluate the classification results using the radiometrically corrected intensity data as reported in Chapter 3. A subset of LiDAR data strip 2 was clipped ( 1 million points) with the dimension of 500 m × 400 m for experimental testing. The reason for selecting this particular area of the BCIT campus was mainly due to the variety of the land cover features on the ground. The area has buildings, parking lots connected by sidewalks and pavements, shrubs and open spaces with grass coverage. Dense tree clusters are present in the West side of the study area. All the corrected intensity data (OI, RCI R SA, RCI R SA AC, RCI R IA, RCI R IA AC and RCI R SA IA AC) were utilized for land cover classification and comparison. Fig. 5.2 shows the aerial photo and the shaded DEM generated from the 3D LiDAR data point cloud of the study area. The second case aimed to test the effect of radiometric normalization of LiDAR intensity data on land cover classification. As reported in Section 4.4, the LiDAR data strips 1 and 3 were normalized with reference to the data strip 2 where four sub-areas were identified for experimental testing. Sub-areas 1 and 2 were located at the overlapping region of LiDAR data 68

69 

CHAPTER 5. LAND COVER CLASSIFICATION




(a) (b)



Figure 5.2: (a) Aerial photo and (b) shaded DEM generated from the LiDAR data in the 1st case       

(a)

(a) (a) (a) (a) (a) (a) (a) (a) 1 Sub-area

    

(b) (b) (b) (b) 2 (b) Sub-area

(b) (b) (b) (b)

(c) (c) (c) 3 (c) (c) Sub-area

(c) (c) (c) (c)

(d) (d) (d) 4 (d)(d) Sub-area

(d) (d) (d) (d)     

               1     2         (e) Sub-area (f) Sub-area (g) Sub-area 3 (h) Sub-area 4     (f) (f) (f) (f) (g) (g) (g) (g) (h) (h) (h) (h)    to (d) Aerial photo (f) (f) (f) (f) (g) (g) (g) (g) (h) (h) (h) (h) Figure 5.3: (a) of sub-areas 1 to 4, (e) to (h) Shaded DEM generated from nd (e) (e) (e) (e) (e) (e) (e) (e) the LiDAR data of sub-areas 1 to 4 in the 2 case Fig.5.3(a)­(d)Aerialphotoofsubareas1to4,(e)­(h)ShadedDEMgeneratedfrom Fig.5.3(a)­(d)Aerialphotoofsubareas1to4,(e)­(h)ShadedDEMgeneratedfrom Fig.5.3(a)­(d)Aerialphotoofsubareas1to4,(e)­(h)ShadedDEMgeneratedfrom Fig.5.3(a)­(d)Aerialphotoofsubareas1to4,(e)­(h)ShadedDEMgeneratedfrom Fig.5.3(a)­(d)Aerialphotoofsubareas1to4,(e)­(h)ShadedDEMgeneratedfrom Fig.5.3(a)­(d)Aerialphotoofsubareas1to4,(e)­(h)ShadedDEMgeneratedfrom Fig.5.3(a)­(d)Aerialphotoofsubareas1to4,(e)­(h)ShadedDEMgeneratedfrom Fig.5.3(a)­(d)Aerialphotoofsubareas1to4,(e)­(h)ShadedDEMgeneratedfrom theLiDARdataofsubareas1to4. theLiDARdataofsubareas1to4. theLiDARdataofsubareas1to4. theLiDARdataofsubareas1to4. theLiDARdataofsubareas1to4. theLiDARdataofsubareas1to4. theLiDARdataofsubareas1to4. theLiDARdataofsubareas1to4. strips 1 and 2 where sub-areas 3 and 4 were located at the overlapping region of LiDAR data         strips 2 and 3. The sub-area 1 (See Fig. 5.3(a)) includes mainly built-up areas where the 5.2.2.DesignofLandCoverClasses 5.2.2.DesignofLandCoverClasses 5.2.2.DesignofLandCoverClasses 5.2.2.DesignofLandCoverClasses 5.2.2.DesignofLandCoverClasses 5.2.2.DesignofLandCoverClasses 5.2.2.DesignofLandCoverClasses 5.2.2.DesignofLandCoverClasses sub-area 4 is mostly covered by vegetation (See Fig. 5.3(d)). An approximate 50/50 ratio of Severalclassificationscenarioswithdifferentnumberoflandcoverclasseswerecarried Severalclassificationscenarioswithdifferentnumberoflandcoverclasseswerecarried Severalclassificationscenarioswithdifferentnumberoflandcoverclasseswerecarried Severalclassificationscenarioswithdifferentnumberoflandcoverclasseswerecarried Severalclassificationscenarioswithdifferentnumberoflandcoverclasseswerecarried Severalclassificationscenarioswithdifferentnumberoflandcoverclasseswerecarried Severalclassificationscenarioswithdifferentnumberoflandcoverclasseswerecarried Severalclassificationscenarioswithdifferentnumberoflandcoverclasseswerecarried out out out out on on on on the the the the airborne airborne airborne airborne LiDAR LiDAR LiDAR LiDAR intensity intensity intensity intensity data data data data before before before before and and and and after after after after the the the the radiometric radiometric radiometric radiometric correction correction correction correction 69 out out out out on on on on the the the the airborne airborne airborne airborne LiDAR LiDAR LiDAR LiDAR intensity intensity intensity intensity data data data data before before before before and and and and after after after after the the the the radiometric radiometric radiometric radiometric correction correction correction correction and/orradiometricnormalizationtoevaluatetheimpactontheclassificationaccuracy. and/orradiometricnormalizationtoevaluatetheimpactontheclassificationaccuracy. and/orradiometricnormalizationtoevaluatetheimpactontheclassificationaccuracy. and/orradiometricnormalizationtoevaluatetheimpactontheclassificationaccuracy. and/orradiometricnormalizationtoevaluatetheimpactontheclassificationaccuracy. and/orradiometricnormalizationtoevaluatetheimpactontheclassificationaccuracy. and/orradiometricnormalizationtoevaluatetheimpactontheclassificationaccuracy. and/orradiometricnormalizationtoevaluatetheimpactontheclassificationaccuracy. The The The The classes classes classes classes design design design design followed followed followed followed the the the the standardized standardized standardized standardized national national national national United United United United States States States States Geological Geological Geological Geological Survey Survey Survey Survey The The The The classes classes classes classes design design design design followed followed followed followed the the the the standardized standardized standardized standardized national national national national United United United United States States States States Geological Geological Geological Geological Survey Survey Survey Survey (USGS)LandCoverClassificationScheme(LCCS)forremotesensingimageclassification (USGS)LandCoverClassificationScheme(LCCS)forremotesensingimageclassification (USGS)LandCoverClassificationScheme(LCCS)forremotesensingimageclassification (USGS)LandCoverClassificationScheme(LCCS)forremotesensingimageclassification (USGS)LandCoverClassificationScheme(LCCS)forremotesensingimageclassification (USGS)LandCoverClassificationScheme(LCCS)forremotesensingimageclassification (USGS)LandCoverClassificationScheme(LCCS)forremotesensingimageclassification (USGS)LandCoverClassificationScheme(LCCS)forremotesensingimageclassification atdifferentscalesandresolutions(Andersonetal.,1976).Thefirstscenarioclassified atdifferentscalesandresolutions(Andersonetal.,1976).Thefirstscenarioclassified atdifferentscalesandresolutions(Andersonetal.,1976).Thefirstscenarioclassified atdifferentscalesandresolutions(Andersonetal.,1976).Thefirstscenarioclassified atdifferentscalesandresolutions(Andersonetal.,1976).Thefirstscenarioclassified atdifferentscalesandresolutions(Andersonetal.,1976).Thefirstscenarioclassified atdifferentscalesandresolutions(Andersonetal.,1976).Thefirstscenarioclassified atdifferentscalesandresolutions(Andersonetal.,1976).Thefirstscenarioclassified

CHAPTER 5. LAND COVER CLASSIFICATION

70

built-up and natural lands is found in the sub-areas 2 and 3 (See Figs. 5.3(b) and 5.3(c)). Since these four sub-areas have different distribution of land cover features, a number of land cover classification scenarios were implemented by using OI, ONI and RCNI for experimental testing.

5.3
5.3.1

Land Cover Classification
Design of Land Cover Classes

Several land cover classification scenarios were carried out using the airborne LiDAR intensity data in order to evaluate the effects of the proposed radiometric correction and normalization on the classification accuracy. The reason for testing different classification scenarios is to avoid any biases of experimental testing towards a specific problem domain. Therefore, the classes design followed the standardized national United States Geological Survey (USGS) Land Cover Classification Scheme (LCCS) for remote sensing image classification at different scales and resolutions (Anderson et al., 1976). The first scenario classified the study area into two land cover classes: i) "Built-up Land" (Class 1 in Level I of USGS LCCS), and ii) "Natural Land". The second scenario sub-divided the "Natural Land" into "High Rangeland" (or "Tree") and "Low Rangeland", and remained the "Built-up Land" as unchanged. The third scenario comprised four classes: i) "Built-up Land", ii) "Tree", iii) "Grass Land" and iv) "Barren Land" (Class 7 in Level I of USGS LCCS) which is described as an area of thin soil, sand, or rocks where less than one-third of the area has vegetation or other cover. The last scenario contained five classes after sub-dividing the "Built-up Land" class into "Building" and "Road" (Level II of USGS LCCS). The five land cover classes were as follows: i) "Road", ii) "Building", iii) "Tree", iv) "Barren Land" (or "Soil") and v) "Grass Land". Table 5.1 summarizes the four classification scenarios and their corresponding land cover classes.

Table 5.1: Design of the land cover classes for experimental testing 2 Classes 1. Natural Land 3 Classes 1. High Rangeland (Tree) 2. Low Rangeland 3. Built-up Land 1. 2. 3. 4. 4 Classes Tree Grass Land Barren Land (Soil) Built-up Land 1. 2. 3. 4. 5. 5 Classes Tree Grass Land Barren Land (Soil) Building Road

2. Built-up Land

70

71

CHAPTER 5. LAND COVER CLASSIFICATION

5.3.2

Training Data

Reference data for training and accuracy assessment were obtained with reference to an orthorectified aerial imagery which was produced from a set of high resolution aerial photos. The aerial photos were captured by a digital aerial camera, Trimble AIC Pro 65+, during the same flight of the airborne LiDAR survey. Each aerial photo was taken with red, green and blue channels in a size of 8984 × 6732 pixels. The aerial photos were ortho-rectified by using an angle-based true orthophoto generation method proposed in Habib et al. (2007), named adaptive radial sweep. After ortho-rectification, the aerial imagery was resampled in TIFF format with 0.5 m resolution. When selecting training data, Chen and Stow (2002) tested three training strategies with a Gaussian maximum likelihood classifier (MLC) on multiple spectral images in five different spatial resolutions. Their study revealed that polygon or block type training sites with large numbers of pixels were likely to be required in order to extract representative training statistics, especially for spectrally heterogeneous classes. Therefore, polygon-based training sites were selected and distributed evenly on the intensity images. The training data were mostly selected at homogeneous areas with reference to the ortho-rectified aerial imagery. The polygons were re-drawn if the land cover type was mixed or questionable. In the first case, the training data for land cover classification included 1527 pixels for "Building", 1323 pixels for "Grass", 1289 pixels for "Road", 1389 pixels for "Soil", and 2280 pixels for "Tree". In the second case, since the distribution and area of land cover features were not identical, the same number of training pixels cannot be achieved. In sub-area 1, the training data for "Building", "Grass", "Road" and "Tree" were 514 pixels, 368 pixels, 441 pixels and 288 pixels, respectively. In sub-area 2, the training data for "Building", "Road", "Soil" and "Tree" were 1439 pixels, 334 pixels, 664 pixels and 395 pixels, respectively. In subarea 3, the training data for "Building", "Grass", "Road", "Soil" and "Tree" were 988 pixels, 307 pixels, 332 pixels, 644 pixels and 501 pixels, respectively. In sub-area 4, the training data for "Grass", "Road", "Soil" and "Tree" were 338 pixels, 970 pixels, 1123 pixels and 974 pixels, respectively.

5.3.3

Classification Technique

PCI Geomatica V10.3.2 was used for land cover classification in this study. The software provides a number of classification techniques including contextual classifier, k-Nearest neighbor classifier, MLC, minimum distance classifier, neural network classifier and parallelepiped classifier. Amongst these techniques, MLC was selected since it is a proven technique for remote sensing image analysis (Jensen, 2005; Yan and Shaker, 2011). The MLC technique relies on the computation of probability density function for the training statistics of each land cover class. 71

CHAPTER 5. LAND COVER CLASSIFICATION

72

The estimated probability function for class i can be determined for n dimensional space (or bands) as follows:P (X i ) = 1 (2 ) Vi
n 2 1 2

1 exp[- (X - Mi )T Vi-1 (X - Mi )] 2

(5.1)

where n is the number of bands, Vi is the covariance matrix for each class, the Mi is the mean vector of each class, and X refers to the pixel value of the image dataset in the n bands. All these input data can be computed when training sites are identified for each class. After computing the probability function for all the classes, the maximum likelihood decision rule decides X  i if and only if P (X i )  P (i )  P (X j )  P (j ) (5.2)

for all i and j out of 1, 2, . . ., m possible classes. Therefore, the pixel X will be assigned with the class i with the largest probability density function. Post-processing techniques, such as applying a majority filter for recoding the isolated pixels or noise removal (e.g., shadow) on the classification results, were usually undertaken in land cover mapping studies to improve the quality of the final product (Yuan et al., 2005). Nevertheless, the experiments in this thesis would ignore these steps since they may bias the evaluation of the effectiveness of the proposed correction and normalization models on the intensity data classification.

5.3.4

Accuracy Assessment

A total of 1010 and 510 random sample checkpoints were generated as reference data for accuracy assessment in the first case and in each of the sub-area of the second case, respectively. Identification of the reference land cover classes for these checkpoints was conducted using the ortho-rectified aerial imagery. All land cover features at the checkpoint locations could be clearly identified on that aerial imagery. Verification of the checkpoints was made visually by comparing each classification result with the reference aerial imagery. As the aerial imagery was acquired during the same LiDAR flight, assessment error due to the seasonal effect was not taken into account in this study. By comparing the classified land cover classes of different scenarios and the reference land cover classes for all the checkpoints, a confusion matrix and a random sample list were generated for each classification result using PCI Geomatica V10.3.2 Focus module. Kappa statistic (KS), overall accuracy, user accuracy and producer accuracy were generated in each confusion matrix. Finally, comparisons of the classification accuracies derived from the original and the corrected/normalized airborne LiDAR intensity data were carried out. 72

73

CHAPTER 5. LAND COVER CLASSIFICATION

5.4
5.4.1

Results and Analysis
Effect of Radiometric Correction on Land Cover Classification

In the first case, 24 trials of land cover classification were carried out for the original and corrected intensity data with different combinations of land cover classes. Table 5.2 summarizes the overall accuracy of the classification scenarios derived from the OI and five radiometrically corrected intensity data, Fig. 5.4 shows the accuracy improvement of overall accuracy in the results of radiometrically corrected intensity data classification, and Fig. 5.5 shows the KS of the land cover features in all the classification scenarios. The classified images are shown in Figs. B.1 to B.4 in Appendix B. In the 2-classes scenario ("Built-up Land" and "Natural Land"), the overall accuracy of OI was 72.5%. The accuracy increased to 74.6% in the classification result of RCI R SA. Adding the atmospheric attenuation factor led to a small improvement in the classification result of 0.3%. When using incidence angle in radiometric correction, the classification results were improved by more than 6% in both RCI R IA and RCI R IA AC. In terms of KS, the values of OI derived "Natural Land" and "Built-up Land" were 0.624 and 0.362, respectively. An increase of KS values with average 0.05 was found in the "Natural Land" derived from all the classification results using corrected intensity data. Regarding the "Built-up Land", a maximum 0.04 and 0.14 increases of KS were observed in the intensity data corrected using scan angle and incidence angle, respectively. Table 5.2: Overall accuracy of land cover classification Dataset OI RCI R SA RCI R SA AC RCI R IA RCI R IA AC RCI R SA IA AC 2-classes 72.5% 74.6% 74.9% 78.8% 78.7% 75.0% 3-classes 60.0% 62.3% 62.0% 71.9% 71.7% 62.7% 4-classes 52.0% 57.3% 57.4% 65.7% 65.1% 57.7% 5-classes 30.3% 33.9% 34.2% 45.4% 45.4% 32.9%

Similar accuracy improvement pattern can be observed in the 3-classes scenario where "High Rangeland" ("Tree"), "Low Rangeland" ("Grass" and "Soil") and "Built-up Land" were classified. The overall accuracy of OI classification results was 60%. Approximately 2% to 3% improvements were recorded in the classification results of RCI R SA, RCI R SA AC and RCI R SA IA AC. The KS values between OI and these three dataset were less than 0.1 in all the land cover features. Nevertheless, the overall accuracy spiked to 72% when using incidence 73

CHAPTER 5. LAND COVER CLASSIFICATION
16.0 14.0 Accuracy Improvement (%) 12.0 10.0 8.0 6.0 4.0 2.0 0.0 2classes 3 classes 4classes 5classes RCI_R_SA RCI_R_SA_AC RCI_R_IA RCI_R_IA_AC RCI_R_SA_IA_AC

74

 

Figure 5.4: Accuracy improvement of land cover classification results using radiometrically corrected intensity data
0.9 0.9 0.8 0.9 0.8 0.9 0.7 0.8 0.7 0.8 0.6 0.7 0.6 0.7 0.5 0.6 0.5 0.6 0.4 0.5 0.4 0.5 0.3 0.4 0.3 0.4 0.2 0.3 0.2 0.3 0.1 0.2 0.1 0.2 0 0.1 0 0.1 0 0 0.9 0.9
0.8 0.9 0.8 0.9 0.7 0.8 0.7 0.8 0.6 0.7 0.6 0.7 0.5 0.6 0.5 0.6 0.4 0.5 0.4 0.5 0.3 0.4 0.3 0.4 0.2 0.3 0.2 0.3 0.1 0.2 0.1 0.2 0 0.1 0 0.1 0 0 TreeTree TreeTree Built-up Built-up LandLand Grass Grass Grass Grass Soil Soil Soil Soil 0.2 0.2 0.1 0.1 0.1 0.1 0 0 0 0

0.9 0.9 OI OI RCI_R_SA RCI_R_SA RCI_R_SA_AC RCI_R_SA_AC OI OI RCI_R_IA RCI_R_IA RCI_R_SA RCI_R_SA RCI_R_IA_AC RCI_R_IA_AC RCI_R_SA_AC RCI_R_SA_AC RCI_R_SA_IA_AC RCI_R_SA_IA_AC RCI_R_IA RCI_R_IA RCI_R_IA_AC RCI_R_IA_AC RCI_R_SA_IA_AC RCI_R_SA_IA_AC 0.8 0.9 0.8 0.9 0.7 0.8 0.7 0.8 0.6 0.7 0.6 0.7 0.5 0.6 0.5 0.6 0.4 0.5 0.4 0.5 0.3 0.4 0.3 0.4 0.2 0.3 0.2 0.3 0.1 0.2 0.1 0.2 Natural Natural LandLand Natural Natural LandLand Built-up Built-up LandLand 0 0.1 0 0.1 HighHigh Rangeland Rangeland Built-up Built-up LandLand Low Low Rangeland Rangeland OI OI RCI_R_SA RCI_R_SA RCI_R_SA_AC RCI_R_SA_AC OI OI RCI_R_IA RCI_R_IA RCI_R_SA RCI_R_SA RCI_R_IA_AC RCI_R_IA_AC RCI_R_SA_AC RCI_R_SA_AC RCI_R_SA_IA_AC RCI_R_SA_IA_AC RCI_R_IA RCI_R_IA RCI_R_IA_AC RCI_R_IA_AC RCI_R_SA_IA_AC RCI_R_SA_IA_AC

Built-up Built-up LandLand (a) 2-classes scenario

 

 

0 0 HighHigh Rangeland Rangeland 0.7 0.7
0.7 0.7 0.6 0.6 0.6 0.6 0.5 0.5 0.5 0.4 0.5 0.4 0.4 0.4 0.3 0.3 0.3 0.2 0.3 0.2

Low Low Rangeland Rangeland (b) 3-classes scenario

Built-up  Built-up LandLand  

OI OI RCI_R_SA RCI_R_SA RCI_R_SA_AC RCI_R_SA_AC OI OI RCI_R_IA RCI_R_IA RCI_R_SA RCI_R_SA RCI_R_IA_AC RCI_R_IA_AC RCI_R_SA_AC RCI_R_SA_AC RCI_R_SA_IA_AC RCI_R_SA_IA_AC RCI_R_IA RCI_R_IA RCI_R_IA_AC RCI_R_IA_AC RCI_R_SA_IA_AC RCI_R_SA_IA_AC

OI OI RCI_R_SA RCI_R_SA RCI_R_SA_AC RCI_R_SA_AC OI OI RCI_R_IA RCI_R_IA RCI_R_SA RCI_R_SA RCI_R_IA_AC RCI_R_IA_AC RCI_R_SA_AC RCI_R_SA_AC RCI_R_SA_IA_AC RCI_R_SA_IA_AC RCI_R_IA RCI_R_IA RCI_R_IA_AC RCI_R_IA_AC RCI_R_SA_IA_AC RCI_R_SA_IA_AC

TreeTree Building Building Grass Grass Road Road

Soil Soil Soil Soil

  Built-up Built-up LandLand

 Grass  TreeTree Building Building Grass

Road Road

  scenario (c) 4-classes

  scenario (d) 5-classes

Figure 5.5: Kappa statistics of land cover classes

74

75

CHAPTER 5. LAND COVER CLASSIFICATION

angle in radiometric correction resulting in a 12% accuracy improvement in the classification results of RCI R IA and RCI R IA AC. The significant improvement can be reflected by the sharp increase of KS value in "High Rangeland" from 0.101 (OI) to 0.610 (RCI R IA or RCI R IA AC) and "Built-up Land" from 0.451 (OI) to 0.739 (RCI R IA or RCI R IA AC), as shown in Fig. 5.5(b), even a slight drop of KS was found in "Low Rangeland". In the 4-classes scenario, the OI classification results produced an overall accuracy with 52%. 5.3% and 13.1% of accuracy improvements were observed in the classification results of RCI R SA and RCI R IA, respectively. No significant difference between the classification results occurred when the intensity data was corrected with atmospheric correction. RCI R SA IA AC consistently performed slightly better than RCI R SA with an overall accuracy of 57.7%. In individual land cover feature (see Fig. 5.5(c)), RCI R SA, RCI R SA AC and RCI R SA IA AC produced slightly higher KS values across all land cover features compared to those of OI, except for the "Built-up Land". Nevertheless, RCI R IA and RCI R IA AC outperformed all the other results where all the land cover features demonstrated an increase of KS, in particular "Tree" and "Built-up Land" where the KS values were increased from 0.048 (OI) to 0.614 (RCI R IA or RCI R IA AC) in "Tree" and 0.451 (OI) to 0.795 (RCI R IA or RCI R IA AC) in "Built-up Land". In the 5-classes scenario, the classification problem was the most heterogeneous since the "Built-up Land" had to be sub-divided into "Building" and "Road". Therefore, the overall accuracy of OI dropped to 30.3%. The RCI R SA and RCI R SA AC both reached to approximate 34% overall accuracy. The use of incidence angle in radiometric correction demonstrated a significant accuracy improvement in all trials. Both RCI R IA and RCI R IA AC generated a classified image with 45.4% overall accuracy leading to a 15% accuracy improvement when compared to the result of OI. Similar to the preceding classification scenario, the significant rise of overall accuracy can be ascribed by the improvement of KS in most of the land cover features. The KS of "Tree" was recorded with an increase of 0.567, where "Building", "Road" and "Soil" were found to have an increase of KS close to 0.1 (see Fig. 5.5(d)).

5.4.2

Effect of Radiometric Normalization on Land Cover Classification

Sub-Area 1 Table 5.3 summarizes the overall accuracy of all classification scenarios in sub-area 1 and Fig. 5.6 shows the KS of land cover classes in all the trials. The classified images are shown in Figs. B.5 in Appendix B. In sub-area 1, the area is mainly occupied by a factory building rooftop leaving the main road and vegetation cover at the North. In the 2-classes scenario, the overall accuracy achieved using OI was 88.6% which was identical to the results of RCNI. ONI showed 75

CHAPTER 5. LAND COVER CLASSIFICATION Table 5.3: Overall accuracy of land cover classification in sub-area 1 Dataset OI ONI RCNI
0.8 0.8 0.8 0.7 0.7 0.7 0.6 0.6 Kappa Statistics Kappa Statistics Kappa Statistics 0.6 0.5 0.5 0.5 0.4 0.4 0.4 0.3 0.3 0.3 0.2 0.2 0.2 0.1 0.1 0.1 00 0 OI OI ONI ONI OI RCNI RCNI ONI RCNI

76

2-classes 88.6% 90.0% ( 0.4%) 88.6% ( 0.0%)

3-classes 87.1% 85.3% ( 1.8%) 85.3% ( 1.8%)
0.8 0.8 0.8 0.7 0.7 0.7 0.6 0.6 Kappa Statistics Kappa Statistics Kappa Statistics 0.6 0.5 0.5 0.5 0.4 0.4 0.4 0.3 0.3 0.3 0.2 0.2 0.2 0.1 0.1 0.1 00 0 OI OI ONI ONI OI RCNI RCNI ONI RCNI

4-classes 67.6% 69.6% ( 2.0%) 68.8% ( 1.2%)

Natural Natural Land Land Natural Land (a) 2-classes

Built-up Built-up Land Land Built-up Land   scenario 0.8 0.8  OI OI

High High Rangeland Rangeland High Rangeland (b)

Built-up Built-up Land Land Built-up   Land 3-classes scenario

Low Low Rangeland Rangeland Low Rangeland



0.8 0.7 0.7 0.7 0.6 0.6 Kappa Statistics Kappa Statistics Kappa Statistics 0.6 0.5 0.5 0.5 0.4 0.4 0.4 0.3 0.3 0.3 0.2 0.2 0.2 0.1 0.1 0.1 00 0

ONI ONI OI RCNI RCNI ONI RCNI

Tree Tree Tree

Built-up Built-up Land Land Built-up Land

Grass Grass

Soil Soil Soil

  Grass  (c) 4-classes scenario

Figure 5.6: Kappa statistics of land cover classes in sub-area 1 a slight increase in overall accuracy by 0.4% where such increase was mainly contributed by the "Natural Land". The KS of "Natural Land" increased from 0.405 (OI) to 0.450 (ONI), see Fig. 5.6(a). In the 3-classes scenario, the overall accuracy remained high at 87.1% in OI since the 3-classes scenario sub-divided the "Natural Land" into "High Rangeland" and "Low Rangeland" which only occupied a small portion in the study area. A decrease of accuracy was recorded in ONI and RCNI with 1.8%. As shown in Fig. 5.6(b), both "High Rangeland" 76

77

CHAPTER 5. LAND COVER CLASSIFICATION

and "Built-up Land" were found with a slight reduction in KS by 0.04 (in ONI) and 0.08 (in RCNI), respectively. In the 4-classes scenario, OI produced a 67.6% overall accuracy; the ONI and RCNI were classified with 69.6% and 68.8% overall accuracy resulting in a 2.0% and 1.2% of improvement, respectively. Nevertheless, the KS of all the land cover classes did not show consistent increase (see Fig. 5.6(c)). In ONI, the KS of "Tree" and "Soil" were slightly higher than the KS generated from OI where the KS of "Grass" and "Built-up Land" were recorded with a slight reduction. The difference of KS values between OI and ONI were within 0.04 in all these land cover features. In RCNI, "Grass" and "Soil" produced a slightly higher KS value than that in OI by 0.014 and 0.017, respectively, where the KS of "Built-up Land" and "Tree" were decreased by 0.04 and 0.06, respectively. Based on the experimental testing in sub-area 1, the difference of classification accuracy between OI and the two normalized intensity data was ±2%. The KS of individual land cover classes generated from ONI and RCNI demonstrated a slight difference (±0.08) when compared to the corresponding KS value from OI. In addition, the KS values of "Tree" were very small; most of the cases were less than 0.2. This was mainly due to the high variance of intensity value in treed areas which led to spectral confusion with other land cover classes. Since the experimental results did not demonstrate consistent improvement in terms of overall accuracy and KS when using the normalized intensity data, the efficiency of the proposed correction model and normalization model was not great enough to justify in this study area. Nevertheless, in the coming sub-areas 2 to 4, significant difference can be found in the classification results using corrected and normalized intensity data. Sub-Area 2 In the sub-area 2, the line stripping noise in the intensity data was more obvious when compared to the intensity data in sub-area 1. As shown in Table 5.4, although less than 1% of accuracy reduction was found in ONI and RCNI results in the 2-classes scenario, the overall accuracy remained high (80%). Fig. 5.7(a) shows the KS of "Natural Land" and "Built-up Land" where the differences amongst them were insignificant. This argument can be justified by the classified images as shown in Fig. B.6 in Appendix B. In the 3-classes scenario, OI produced 59.4% of overall accuracy while ONI and RCNI improved the classification results by 3% and 1.8%, respectively. As shown in Fig. 5.7(b), the KS value of "Low Rangeland" generated from RCNI was higher than its corresponding KS value from OI by 0.08. A similar accuracy improvement pattern was achieved in the 4-classes scenario where the overall accuracy of OI, ONI and RCNI were 57.6%, 59.8% and 60.6%, respectively. As the noisy effect was reduced in RCNI, the KS of "Soil" and "Road" were increased from 0.794 (OI) to 0.8463 (RCNI) and from 0.356 (OI) to 0.459 (RCNI), see Fig. 5.7(c). 77

CHAPTER 5. LAND COVER CLASSIFICATION Table 5.4: Overall accuracy of land cover classification in sub-area 2 Dataset OI ONI RCNI 2-classes 80.0% 79.4% ( 0.6%) 79.2% ( 0.8%) 3-classes 59.4% 62.4% ( 3.0%) 61.2% ( 1.8%)
0.9 0.9 OI OI ONI ONI OI RCNI RCNI ONI RCNI 0.9 0.8 0.8 0.8 0.7 0.7 0.7 0.6 0.6 Kappa Statistics Kappa Statistics Kappa Statistics 0.6 0.5 0.5 0.5 0.4 0.4 0.4 0.3 0.3 0.3 0.2 0.2 0.2 0.1 0.1 0.1 00 0 OI OI ONI ONI OI RCNI RCNI ONI RCNI

78

4-classes 57.6% 59.8% ( 2.2%) 60.6% ( 3.0%)

0.7 0.7 0.7 0.6 0.6 0.6 0.5 0.5 Kappa Statistics Kappa Statistics Kappa Statistics 0.5 0.4 0.4

0.4 0.3 0.3

0.3 0.2 0.2

0.2 0.1 0.1 0.1 00 0 Natural Natural Land Land Natural Land Built-up Built-up Land Land

High High Rangeland Rangeland High Rangeland

Built-up Built-up Land Land

Low Low Rangeland Rangeland Low Rangeland

Built-up Land   scenario (a) 2-classes



Built-up Land   scenario (b) 3-classes

0.9 0.9 0.9 0.8 0.8 0.8 0.7 0.7 0.7 0.6 0.6 OI OI ONI ONI OI RCNI RCNI ONI RCNI



Kappa Statistics Kappa Statistics Kappa Statistics

0.6 0.5 0.5 0.5 0.4 0.4 0.4 0.3 0.3 0.3 0.2 0.2 0.2 0.1 0.1 0.1 00 0

Tree Tree Tree

Building Building Building

Road Road

Soil Soil Soil

 scenario (c) 4-classes



Road

Figure 5.7: Kappa statistics of land cover classes in sub-area 2 Since sub-area 2 had more variety of land cover features compared to sub-area 1, the spectral mixture amongst different land cover caused a significant drop of overall accuracy particularly in the 3-classes and 4-classes scenarios. Despite this, improvement in overall accuracy was slightly higher than those achieved in sub-area 1, after applying the proposed normalization model on the intensity data (max 3.0%). The KS values in all the land cover features were similar to those in sub-area 1, except "Tree". The KS of "Tree" was notably small (0.05). This 78

79

CHAPTER 5. LAND COVER CLASSIFICATION

thus influenced the classification results in 3-classes scenario where a significant drop of overall accuracy was found from 80% (in 2-classes) to 60% (in 3-classes). The reason for the small KS value in "Tree" class was mainly due to the three different tree species located in sub-area 2 (see Fig. 5.3(b)) in which the intensity values of these species were completely different in the intensity value (see Fig. 4.13(b)). Although the experiment recorded reduction of KS in "Tree" class, this thus implied that the intensity data would be useful in distinguishing certain tree species. Sub-Area 3 Unlike the previous two sub-areas, the experimental work in sub-area 3 classified all the land cover classification scenarios as listed in Table 5.1. Table 5.5 summarizes the overall accuracy in this case; the classified images are displayed in Fig. B.7 in Appendix B. In the 2-classes scenario, the overall accuracy produced by OI was close to 83% where both ONI and RCNI produced the same overall accuracy at 86.5%. Such increase was mainly due to the improvement of distinguishing "Built-up Land" after radiometric normalization, where both ONI and RCNI recorded a KS value of 0.758 compared to 0.594 recorded in the results of OI (see Fig. 5.8(a)). In the 3-classes scenario, the overall accuracy of OI was 71.8%; 7% and 8% accuracy improvements were achieved in the classification results of ONI and RCNI, respectively. The KS value in both ONI and RCNI was found with an increase by 0.1 in both "High Rangeland" and "Low Rangeland" (see Fig. 5.8(b)). In the 4-classes and 5-classes scenarios, the overall accuracy dropped to 63.5% and 45.1%. Nevertheless, an increase of overall accuracy was found in all the normalized intensity data classification results. Respective increases of 10.6% and 13.4% were observed in ONI and RCNI in the 4-classes scenario. An accuracy improvement of more than 16% was achieved in both normalized data classification results in the 5-classes scenario where the overall accuracy of OI was 61.4%. As shown in Figs. 5.8(c) and 5.8(d), "Tree", "Grass", "Soil" and "Built-up Land" were found with an increase ranging from 0.09 to 0.21 in the ONI and RCNI classification results when compared to the corresponding KS values generated from OI.

Table 5.5: Overall accuracy of land cover classification in sub-area 3 Dataset OI ONI RCNI 2-classes 82.7% 86.5% ( 3.8%) 86.5% ( 3.8%) 3-classes 71.8% 78.8% ( 7.0%) 79.8% ( 8.0%) 4-classes 63.5% 74.1% ( 10.6%) 76.9% ( 13.4%) 5-classes 45.1% 61.4% ( 16.3%) 61.6% ( 16.5%)

79

CHAPTER 5. LAND COVER CLASSIFICATION
11 1 1 0.9 0.9 0.9 0.9 0.8 0.8 0.8 0.8 0.7 0.7 Kappa Statistics Kappa Statistics Kappa Statistics Kappa Statistics 0.7 0.7 0.6 0.6 0.6 0.6 0.5 0.5 0.5 0.5 0.4 0.4 0.4 0.4 0.3 0.3 0.3 0.3 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 00 00 0.8 0.8 0.8 0.8 0.7 0.7 0.7 0.7 0.6 0.6 Kappa Statistics Kappa Statistics Kappa Statistics Kappa Statistics 0.6 0.6 0.5 0.5 0.5 0.5 0.4 0.4 0.4 0.4 0.3 0.3 0.3 0.3 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 00 00 Natural Natural Land Land Natural Natural Land Land OI OI ONI ONI OI OI RCNI RCNI ONI ONI RCNI RCNI Built-up Built-up Land Land OI OI ONI ONI OI OI RCNI RCNI ONI ONI RCNI RCNI 0.9 0.9 0.9 0.9 0.8 0.8 0.8 0.8 0.7 0.7 0.7 0.7 0.6 0.6 Kappa Statistics Kappa Statistics Kappa Statistics Kappa Statistics 0.6 0.6 0.5 0.5 0.5 0.5 0.4 0.4 0.4 0.4 0.3 0.3 0.3 0.3 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 00 00 0.8 0.8 0.8 0.8 0.7 0.7 0.7 0.7 0.6 0.6 Kappa Statistics Kappa Statistics Kappa Statistics Kappa Statistics 0.6 0.6 0.5 0.5 0.5 0.5 0.4 0.4 0.4 0.4 0.3 0.3 0.3 0.3 0.2 0.2 0.2 0.2 0.1 0.1 0.1 0.1 00 00 OI OI ONI ONI OI OI RCNI RCNI ONI ONI RCNI RCNI

80

High High Rangeland Rangeland High High Rangeland Rangeland OI OI ONI ONI OI OI RCNI RCNI ONI ONI RCNI RCNI

Built-up Built-up Land Land Built-up Built-up Land Land

Low Low Rangeland Rangeland

Built-up Built-up Land Land   scenario (a) 2-classes 

Low Rangeland Rangeland   scenario Low (b) 3-classes 

Tree Tree Tree Tree

Built-up Built-up Land Land Built-up Built-up Land Land

Grass Grass

Soil Soil Soil Soil

Tree Tree Tree Tree

Building Building Building Building

Grass Grass Grass Grass

Road Road

Soil Soil Soil Soil

Grass   Grass   (c) 4-classes scenario

Road Road    (d) 5-classes scenario

Figure 5.8: Kappa statistics of land cover classes in sub-area 3

As shown in Fig. 4.15(b), the OI in sub-area 3 had the most serious line stripping noise. Owing to the successful removal of noise in the intensity data, accuracy improvement was found to be significant after radiometric normalization. The results in the first three classification scenarios achieved more than 75% overall accuracy which was higher than most of the preceding experimental trials in sub-area 2 and the 1st case. The over 60% classification accuracy generated from ONI and RCNI in 5-classes scenario was even much higher than all the RCI datasets in the first case (maximum is 45% only). One should note that the more line stripping noise on the land cover features in OI, the more improvement of KS in ONI and RCNI. For instance, the KS of "Tree" in 5-classes scenario was 0.077 in OI and it increased to 0.298 in RCNI; the KS of "Grass" in the same scenario was 0.174 in the OI classification result and 0.384 in the RCNI classification result, respectively. Up to this point, the sub-area 3 successfully proves the effectiveness of the proposed radiometric normalization model on land cover classification. 80

81 Sub-Area 4

CHAPTER 5. LAND COVER CLASSIFICATION

Table 5.6 shows the overall accuracy of land cover classification in sub-area 4 and Fig. B.8 in Appendix B shows the land cover classification results. As shown in Table 5.6, the OI achieved 87.5% classification accuracy in the 2-classes scenario. Both ONI and RCNI did not demonstrate significant impact on the classification results where less than 1% of increase in overall accuracy was found. Table 5.6: Overall accuracy of land cover classification in sub-area 4 Dataset OI ONI RCNI 2-classes 87.5% 87.6% ( 0.1%) 88.4% ( 0.9%) 3-classes 66.3% 72.0% ( 5.7%) 72.7% ( 6.4%) 4-classes 59.0% 68.0% ( 9.0%) 68.2% ( 9.2%)

0.8 0.8 0.8 0.7 0.7 0.7 0.6 0.6 Kappa Statistics Kappa Statistics Kappa Statistics 0.6 0.5 0.5 0.5 0.4 0.4 0.4 0.3 0.3 0.3 0.2 0.2 0.2 0.1 0.1 0.1 00 0 OI OI ONI ONI OI RCNI RCNI ONI RCNI

0.8 0.8 0.8 0.7 0.7 0.7 0.6 0.6 Kappa Statistics Kappa Statistics Kappa Statistics 0.6 0.5 0.5 0.5 0.4 0.4 0.4 0.3 0.3 0.3 0.2 0.2 0.2 0.1 0.1 0.1 00 0 OI OI ONI ONI OI RCNI RCNI ONI RCNI

Natural Natural Land Land Natural Land

Built-up Built-up Land Land

High High Rangeland Rangeland High Rangeland

Built-up Built-up Land Land

Low Low Rangeland Rangeland

Built-up Land (a) (a) (a) 2-classes scenario 0.8 0.8

(a)

(b) (b)scenario Built-up Land Low Rangeland (b) 3-classes (b)

0.8 0.7 0.7 0.7 0.6 0.6 Kappa Statistics Kappa Statistics Kappa Statistics 0.6 0.5 0.5 0.5 0.4 0.4 0.4 0.3 0.3 0.3 0.2 0.2 0.2 0.1 0.1 0.1 00 0

OI OI ONI ONI OI RCNI RCNI ONI RCNI

Tree Tree Tree

Built-up Built-up Land Land Built-up Land

Grass Grass

Soil Soil Soil

(c) (c) Grass (c) (c) 4-classes scenario

Figure 5.9: Kappa statistics of land cover classes in sub-area 4 81

CHAPTER 5. LAND COVER CLASSIFICATION

82

The KS values, as shown in Fig. 5.9(a), showed an opposite trend in the normalized intensity data classification results. The "Natural Land" demonstrated a drop of KS with 0.04 in ONI classification result and 0.01 in RCNI classification result. Contradictorily, the KS value of "Built-up Land" increased from 0.697 (OI) to 0.742 in ONI and 0.760 in RCNI. In the 3-classes scenario, ONI and RCNI produced 5.7% and 6.4% accuracy improvements, respectively, when compared to the classification results of OI which was only 66.3%. "High Rangeland" and "Low Rangeland" were observed with an increase of KS with more than 0.1 in RCNI classification result when compared to that of OI (Fig. 5.9(b)). Following the trend in 3-classes, 9% of overall accuracy improvement was found in the normalized intensity where the accuracy of classification using OI was 59% only. Consistently, an increase of KS values ranging from 0.04 to 0.21 were found in all the land cover features classified using ONI and RCNI (see Fig. 5.9(c)). Since sub-area 4 was located at the same overlapping region of sub-area 3, the line stripping noisy effect was manifest. After radiometric normalization, the discrepancy of intensity within the same land cover feature was significantly reduced resulting in a large accuracy improvement in the 3-classes and 4-classes scenarios.

5.5

Chapter Summary

In this chapter, two case studies were used to investigate the effects of radiometric correction and radiometric normalization of LiDAR intensity data on land cover classification. In the first case, radiometric correction applied to the airborne LiDAR intensity data demonstrated an improvement in land cover classification accuracy from 2% to 15%. Amongst all the trials, the LiDAR intensity data corrected using range and scan angle (RCI R SA and RCI R SA AC) produced a slight increase of overall accuracy from 2% to 6%. The largest increase in overall accuracy (6% to 15%) was achieved by using the intensity dataset corrected with range and incidence angle (RCI R IA and RCI R IA AC). Most of these increases were mainly due to the over-corrections in the vegetation cover which made it easily distinguished from the built-up land. Although all the results demonstrated an accuracy improvement when using radiometrically corrected intensity data, the proposed atmospheric correction and proposed method RCI R SA IA AC did not show their significant performance as revealed when we assessed the land cover homogeneity. Only 2.5% to 5.7% of accuracy improvements were recorded in the RCI R SA IA AC classification results in the four different classification scenarios. Such amount of improvement was similar to what RCI R SA and RCI R SA AC achieved amongst all the trials. It should be noted that though the RCI dataset using incidence angle (RCI R IA or RCI R I A AC) obtained the best classification accuracy amongst others, this does not imply that ra82

83

CHAPTER 5. LAND COVER CLASSIFICATION

diometric correction using incidence angle should always be implemented. The effects of overcorrection did cause the tree canopies in RCI R IA and RCI R IA AC to be easily distinguished from other land cover features. However, it does not mean that all tree canopies possess such a high physical reflectance. If RCI R IA or RCI R IA AC is used to estimate biophysical and land surface parameters, the derived results would be misleading. Therefore, the proposed approach RCI R SA IA AC is corrected in a relative sense where the land cover homogeneity is mostly preserved within the same land cover type. Nevertheless, the data would be of no value for deriving any biophysical information unless absolute ground calibration is performed on the corrected intensity data. In the second case, land cover classification was conducted on OI, ONI and RCNI with different classification scenarios. In the first two sub-areas, the difference of overall accuracy between the OI classification results and the classification results of ONI or RCNI was not likely to exceed 3%. In some classification scenarios, slight reduction of overall accuracy was reported in the ONI or RCNI classification results. Given the stripping noise was not manifest in these two areas, the difference of classification results between OI and ONI or OI and RCNI was not significant. Nevertheless, in case of serious stripping noise in the intensity data, radiometric normalization can significantly contribute to the improvement of land cover classification. In sub-areas 3 and 4, increases of overall accuracy were found with 5.7% to 16.5% (excluding the 2-classes scenario) in the ONI and RCNI classification results. Comparing between the land cover map derived from ONI and RCNI, it was found that the basic pattern of these two results were very similar. In terms of specific land cover classes, "Built-up Land" ("Building" and "Road") always demonstrated a high classification accuracy as reflected from its KS value (most of the time  0.5) regardless of classification scenarios. Nevertheless, "High Rangeland" (or "Tree") showed a relatively low KS value (< 0.2) due to the heterogeneous surface of tree canopies resulting in a high variance of intensity. Previous studies in radiometric correction of remote sensing images usually addressed a single classification scenario (Tokola et al., 2001; Blesius and Weirich, 2005; Zurita-Milla et al., 2007). The claimed accuracy improvements (after radiometric correction) were only tested and concluded for a specific classification scenario. The efficiency of radiometric correction may not be fully investigated which may in turn to be either an over- or underestimate. Based on the results of this chapter, which assessed different classification scenarios, it does not appear necessary to perform radiometric correction and radiometric normalization on the intensity data for a simple classification scenario. The results showed no significant differences in classification accuracy in most of the trials of 2-classes scenario and intensity data with unclear level of stripping noise. Nevertheless, for a more a heterogeneous classification scenario or when using intensity data with serious line stripping problems, the proposed method showed significant 83

CHAPTER 5. LAND COVER CLASSIFICATION improvements on the LiDAR data classification results.

84

84

Chapter 6

Conclusions and Future Work
6.1 Conclusions

As depicted in Chapter 1, the demand of land cover maps at finer scale has been raised with evidence by numerous biophysical and socio-economic studies in urban areas. This thesis aims to explore the use of airborne LiDAR intensity data for land cover mapping, which can overcome the limitations of using high resolution satellite imagery. Nevertheless, the presence of systematic noise and intensity heterogeneity in airborne LiDAR intensity data pose challenges to the qualitative data analysis and applications. Though a few existing research addressed radiometric calibration and correction of LiDAR intensity data based on the radar (range) equation, some of the factors, such as atmospheric attenuation, combining overlapping intensity data, etc., have not been fully investigated. In this regard, this thesis research attempts to fill the current gap by (a) formulating a radiometric correction model, (b) proposing a radiometric normalization model, and (c) studying the effects of these models on different land cover classification scenarios. The contributions of this thesis research include the following: 1. Introduces a set of models for removing the effects of atmospheric attenuation. Since some of the previous studies assumed the atmospheric attenuation as constant for short range laser scanning or clear atmospheric condition, this thesis research attempted to model the atmospheric attenuation factor, which follows the Beer-Lambert Law. The aerosol and molecular scattering coefficients can be derived based on two empirical models proposed by Bucholtz (1995) and Ferdinandov et al. (2009). The extinction coefficients of aerosol absorption and molecular absorption can be retrieved with reference to the HITRAN molecular database. Experimental results demonstrated that the coefficient of variation (cv ) of the intensity data corrected using range and scan angle was reduced by 0.4% to 35.5%. Adding the atmospheric attenuation correction led to a further reduction 85

CHAPTER 6. CONCLUSIONS AND FUTURE WORK of cv by 43.1% to 77.6%.

86

2. Develops a set of mathematical formulas to compute the laser incidence angle. Existing research in radiometric correction did not consider or clearly identify the effects of incidence angle in the laser cross section of the radar (range) equation. Therefore, a set of formulas were developed to compute the incidence angle using the time-tagged LiDAR data and GPS trajectory data file. Based on the derived formulas, the incidence angle can be computed by the scan angle, projected horizontal angle, surface slope and surface aspect. Since effects of over-correction have been reported in the previous literatures while using incidence angle in radiometric correction, this thesis further proposed to incorporate both scan angle and incidence angle for radiometric correction. Experimental results demonstrated that the cv within the same land cover feature was reduced by 70% to 82% in the proposed corrected intensity data. 3. Proposes a radiometric normalization model for airborne LiDAR data strips. Though radiometric correction was applied to the intensity data, combining intensity data from overlapping LiDAR data strips had significant line stripping problem which degraded the land cover homogeneity. Therefore, a radiometric normalization model was proposed to adjust the radiometric misalignment by matching the intensity sub-histogram of a data strip with reference to the intensity sub-histogram generated from a reference data strip. The criterion to split the histogram into sub-histograms was based on fitting the Gaussian mixture components in the multi-modal histogram acquired in the overlapping region of the two LiDAR data strips. The intensity sub-histogram of the target LiDAR data strip was normalized to the corresponding sub-histogram of the reference data strip based on histogram equalization. By visually examining the intensity images, the systematic noises were reduced after radiometric normalization. Experimental results showed that the cv within the same land cover feature was significantly reduced in a range of 33% to 80% with respect to the corrected and normalized intensity data. 4. Assesses the land cover classification accuracy using LiDAR intensity data. Two case studies were performed to investigate the effects of radiometric correction and radiometric normalization of LiDAR intensity data on land cover classification. In the first case, original intensity data and radiometrically corrected intensity data were classified under different scenarios. Radiometric correction applied to the airborne LiDAR intensity data demonstrated an improvement in land cover classification accuracy of 2% to 15%, compared to the classification results using the original intensity data. In the second case, original intensity (OI) data, normalized intensity (ONI) data, and corrected and 86

87

CHAPTER 6. CONCLUSIONS AND FUTURE WORK normalized intensity (RCNI) data were used for land cover classification. Experimental results showed that increases of 5.7% to 16.5% in overall accuracy were recorded in both ONI and RCNI classification results. Despite these improvements, radiometric correction and normalization seemed unnecessary for simple classification scenario (e.g., 2-classes scenario for separating built-up land from natural ground). As aforementioned, a few research groups have already carried out the studies in airborne

LiDAR intensity correction (Coren and Sterzai, 2006; H¨ ofle and Pfeifer, 2007; Kaasalainen et al., 2007). Nevertheless, very little of these other efforts addressed the effects of the proposed techniques on real applications. This thesis sets a good example for proving the effectiveness of radiometric correction and radiometric normalization on airborne LiDAR intensity data and applications. It is apparent from the findings of this thesis that radiometric correction and radiometric normalization have positive impacts on the airborne LiDAR intensity data for land cover classification. Therefore, airborne LiDAR data should be radiometrically corrected and normalized to remove the effects of environmental- and system- induced distortions in the intensity data before performing any thematic applications. This thesis fills the gap in existing airborne LiDAR research and paves the way for the development of future LiDAR data processing system.

6.2

Future Work

The research presented in this thesis provides a foundation for developing a computer-based processing software for LiDAR intensity data correction. Although the thesis focuses on the discrete multiple-return LiDAR data, the proposed method can be applied to full-waveform LiDAR data with slight modification. Despite the improvement in land cover homogeneity, the results are not purported to be the last word in the subject of radiometric correction of LiDAR intensity data. The proposed approach has certain limitations that can be further investigated in future research. Several imperatives for future work are listed as follows: Other LiDAR Sensors: During the Ph.D. study, a number of trials have been carried out to radiometrically correct mobile laser scanning intensity data. Nevertheless, the corrected intensity data (which were not reported in this thesis) did not show any improvement on the intensity homogeneity, which intimated the inappropriate use of radar (range) equation on mobile LiDAR sensor. A number of experimental trials have been reported for radiometric calibration of terrestrial laser scanning intensity data using different external targets (Kaasalainen et al., 2009a). Further research conducted by Kaasalainen et al. (2011) addressed the need for 87

CHAPTER 6. CONCLUSIONS AND FUTURE WORK

88

searching an optimal correction method for mobile laser scanner with respect to the range and incidence angle for practical applications. Apart from civilian applications, a number of space agencies have planned or launched satellite-based laser scanners for planetary exploration, such as the NASA Lunar Orbiter Laser Altimeter, China National Space Administration (CNSA)'s Chang'E-1 Laser Altimeter, NASA's Mars Orbiter Laser Altimeter, NASA's Mercury Laser Altimeter, etc. An accurate radiometric correction method is desired for precise crustal mapping and better understanding of the historical geology through studying the recorded laser intensity data. Multi-wavelength Intensity Data: There are a number of experimental LiDAR sensors operating at different wavelengths currently being developed in laboratory for retrieving the backscattered reflectance of small plant and tree canopy (Morsdorf et al., 2009; Chen et al., 2010; Suomalainen et al., 2011; Zhu et al., 2011). Preliminary findings have already proven the usefulness of multi-wavelength LiDAR data to detect small changes in leaf reflectance due to the biochemical concentration at leaf level (Gong et al. 2012). The backscattered intensity data at different wavelengths were used to develop normalized difference vegetation index (NDVI) and photochemical reflectance index for measuring plant physiology (Woodhouse et al., 2011; Wallace et al., 2012). An improved efficiency in classification and interpretation compared to the traditional monochromatic LiDAR data was demonstrated (Woodhouse et al., 2011; Hakala et al.,2012). Nevertheless, most of these work focused on the short range LiDAR sensor for terrestrial mapping without performing radiometric correction. When technology matures, it is worth investigating radiometric correction of backscattered intensity signals recorded by multiwavelength airborne LiDAR sensor so as to serve a large scale surface mapping and object recognition applications. Other Atmospheric Factors: Though a set of empirical methods were introduced to model the effects of atmospheric absorption and scattering in Chapter 3, additional research should be conducted to test the correction model under different climatic conditions. Furthermore, the influence of atmospheric turbulence has not been considered in an airborne LiDAR sensor. Atmospheric turbulence is mainly caused by the laser beam wandering and scintillation due to the random variations of refractive index caused by temperature, pressure and wind variations along the beam propagation path (Pedireddi and Srinivasan, 2010). This thus leads to fluctuations of laser beam signal resulting in distortion of the recorded laser intensity. Recently, the atmospheric turbulence effect has been studied in free space optical communication (Motlagh et al., 2008), laser ranging system (Cole et al., 2008) and radar system (McMillan, 2010). Cole et al. (2008) added an additional corrective term in the laser range equation considering the tur88

89

CHAPTER 6. CONCLUSIONS AND FUTURE WORK

bulence effect where such factor depends on the radius of the receiving aperture. Kaasalainen and Kaasalainen (2008) demonstrated the impacts of the sensor aperture size on the backscattered laser intensity. Though the aperture size of airborne LiDAR sensor is commonly known as between 8 cm and 15 cm (Wehr and Lohr, 1999a), the specific value was not disclosed by most sensor manufacturers. As a consequence, the atmospheric turbulence factor is not yet considered in modeling the LiDAR backscattered intensity which can be further explored. Laser Reflectance Model: The thesis proposed to incorporate both scan angle () and incidence angle (r ) in the radiometric correction model. To relieve the over-correction effect, a correction mechanism was proposed by using the slope as a threshold to select either using scan angle or incidence angle in the radar (range) equation. Nevertheless, the suggested method may not be universal to all topography and LiDAR dataset. Since cos() and cos(r ) in the radar (range) equation do not stand for all kinds of materials as reported in the laboratory testing by Kukko et al. (2008), future research should investigate and develop a universal laser reflectance model for modeling the peculiar characteristics of laser intensity at different backscattering geometry. Initial study can be carried out by first investigating the cosine correction, Minnaert correction, statistical-empirical correction, C correction, SCS correction, SCS+C correction, which are commonly adopted in optical satellite remote sensing (Soenen et al., 2005). In addition, existing semi-empirical bi-directional reflectance distribution functions (BRDF) in remote sensing and computer graphics (i.e., Torrance-Sparrow, Maxwell-Beard, Standard Robertson, Phong, Blinn-Phong, Cook-Torrance and Oren-Nayar) can also be tested on the airborne LiDAR intensity data. Statistical Analysis: Since this thesis research focuses on radiometric correction and normalization instead of classifier development, in-depth statistical analysis was not conducted in the classification results for assessing the significance. Further effort can be expended in running statistical tests such as Cochran's Q-Test (Patil, 1975), Looney's F-Test (Looney, 1988) or McNemar's Test (Foody, 2004) to investigate if there are any significant differences amongst the classification results before and after radiometric correction and/or radiometric normalization. The test's results could be another qualitative indicator (in addition to the overall accuracy and kappa statistics) to demonstrate the impact of the proposed models on the land cover classification. Different stastical classifiers can also be investigated in order to improve the classification accuracy using the corrected and normalized intensity data. Initial stduy has been conducted to compare the pixel-based and object-based classifers on the LiDAR intensity data (El-Ashmawy et al., 2011). In addition to statistical classification, a study of error propagation (or sensitivity analysis) can be carried out to investigate the variables' uncertainties in 89

CHAPTER 6. CONCLUSIONS AND FUTURE WORK

90

the radar (range) equation. Such study would be important to reveal the influence of different parameters (such as range, scan angle, incidence angle, etc.) in the equation for quantifying the uncertainty in the corrected intensity data.

90

Appendix A

Glossary of Acronyms
AGC ALOS ASTER AVHRR BRDF CNSA cv EEA EM FAO GaAs GIS GLAS GMM GPS IFOV IMU KS LASER LCCS LiDAR Automatic Gain Control Advanced Land Observation Satellite Advanced Spaceborne Thermal Emission and Reflection Radiometer Advanced Very High Resolution Radiometer Bidirectional Reflectance Distribution Function China National Space Administration Coefficient of Variation European Environmental Agency Expectation Maximization Food and Agriculture Organization Gallium Arsenide Geographic Information System Geoscience Laser Altimeter System Gaussian Mixture Model Global Positioning System Instantaneous Field of View Inertial Measurement Unit Kappa Statistics Light Amplification by Stimulated Emission of Radiation Land Cover Classification System Light Detection and Ranging 91

APPENDIX A. GLOSSARY OF ACRONYMS LVIS MLC MODIS NASA Nd:YAG NDVI NOAA NRCan OI PALSAR RCI R IA RCI R IA AC RCI R SA RCI R SA AC RCI R SA IA AC RCI RCNI SLA SLICER SPOT TLS USGS Laser Vegetation Imaging Sensor Maximum Likelihood Classification Moderate Resolution Imaging Spectroradiometer National Aeronautics and Space Administration Neodymium-doped Yttrium Aluminium Garnet Normalized Difference Vegetation Index National Oceanic and Atmospheric Administration Natural Resources Canada Original Intensity Phased Array type L-band Synthetic Aperture Radar

92

Radiometrically Corrected Intensity using Range and Incidence Angle Radiometrically Corrected Intensity using Range, Incidence Angle and Atmospheric Correction Radiometrically Corrected Intensity using Range and Scan Angle Radiometrically Corrected Intensity using Range, Scan Angle and Atmospheric Correction Radiometrically Corrected Intensity using Range, Scan Angle, Incidence Angle and Atmospheric Correction Radiometrically Corrected Intensity Radiometrically Corrected and Normalized Intensity Shuttle Laser Altimeter Scanning Lidar Imager of Canopies by Echo Recovery Syst` eme Pour l'Observation de la Terre Terrestrial Laser Scanning United States Geological Survey

92

Appendix B

Land Cover Classification Results
Appendix B lists all the results of land cover classification as reported in Chapter 5. Figs. B.1 to B.4 show the land cover classification results as reported in Section 5.4.1, where Figs. B.5 to B.8 show the land cover classification results as reported in Section5.4.2.

93

APPENDIX B. LAND COVER CLASSIFICATION RESULTS

94

(a) OI

(b) RCI R SA

(c) RCI R SA AC

(d) RCI R IA

(e) RCI R IA AC

(f) RCI R SA IA AC

Figure B.1: Land cover classification results using OI and five RCI data: 2-classes scenario

94

95

APPENDIX B. LAND COVER CLASSIFICATION RESULTS

(a) OI

(b) RCI R SA

(c) RCI R SA AC

(d) RCI R IA

(e) RCI R IA AC

(f) RCI R SA IA AC

Figure B.2: Land cover classification results using OI and five RCI data: 3-classes scenario

95

APPENDIX B. LAND COVER CLASSIFICATION RESULTS

96

(a) OI

(b) RCI R SA

(c) RCI R SA AC

(d) RCI R IA

(e) RCI R IA AC

(f) RCI R SA IA AC

Figure B.3: Land cover classification results using OI and five RCI data: 4-classes scenario

96

97

APPENDIX B. LAND COVER CLASSIFICATION RESULTS

(a) OI

(b) RCI R SA

(c) RCI R SA AC

(d) RCI R IA

(e) RCI R IA AC

(f) RCI R SA IA AC

Figure B.4: Land cover classification results using OI and five RCI data: 5-classes scenario

97

APPENDIX B. LAND COVER CLASSIFICATION RESULTS

98

 
(a) OI (2-classes) (b) ONI (2-classes)

 
(c) RCNI (2-classes)

 

 
(d) OI (3-classes) (e) ONI (3-classes)

 
(f) RCNI (3-classes)

 

 
(g) OI (4-classes) (h) ONI (4-classes)

 
(i) RCNI (4-classes)

 

Figure B.5: Land cover classification results in sub-area 1

98

99

APPENDIX B. LAND COVER CLASSIFICATION RESULTS

 
(a) OI (2-classes) (b) ONI (2-classes)

 
(c) RCNI (2-classes)

 

 
(d) OI (3-classes) (e) ONI (3-classes)

 
(f) RCNI (3-classes)

 

 
(g) OI (4-classes) (h) ONI (4-classes)

 
(i) RCNI (4-classes)

 

Figure B.6: Land cover classification results in sub-area 2

99

APPENDIX B. LAND COVER CLASSIFICATION RESULTS

100

 
(a) OI (2-classes) (b) ONI (2-classes)

 
(c) RCNI (2-classes)

 

 
(d) OI (3-classes) (e) ONI (3-classes)

 
(f) RCNI (3-classes)

 

 
(g) OI (4-classes) (h) ONI (4-classes)

 
(i) RCNI (4-classes)

 

 
(j) OI (5-classes) (k) ONI (5-classes)

 
(l) RCNI (5-classes)

 

Figure B.7: Land cover classification results in sub-area 3 100

101

APPENDIX B. LAND COVER CLASSIFICATION RESULTS

 
(a) OI (2-classes) (b) ONI (2-classes)

 
(c) RCNI (2-classes)

 

 
(d) OI (3-classes) (e) ONI (3-classes)

 
(f) RCNI (3-classes)

 

 
(g) OI (4-classes) (h) ONI (4-classes)

 
(i) RCNI (4-classes)

 

Figure B.8: Land cover classification results in sub-area 4

101

References
[1] Ackermann F. Airborne laser scanning - present status and future expectations. ISPRS Journal of Photogrammetry and Remote Sensing, 54(2-3):64­67, 1999. [2] Anderson J.R., Hardy E.E., Roach J.T., and Witmer R.E. A land use and land cover classification system for use with remote sensor data. US Geological Survey Professional Paper 964, USGS, Washington, D.C., 1976. [3] Antonarakis A.S., Richards K.S., and Brasington J. Object-based land cover classification using airborne lidar. Remote Sensing of Environment, 112(6):2988­2998, 2008. [4] Baltsavias E.P. Airborne laser scanning: existing systems and firms and other resources. ISPRS Journal of Photogrammetry and Remote Sensing, 54(2-3):164­198, 1999a. [5] Baltsavias E.P. Airborne laser scanning: basic relations and formulas. ISPRS Journal of Photogrammetry and Remote Sensing, 54(2-3):199­214, 1999b. [6] Bartels M. and Wei H. Rule-based improvement of maximum likelihood classified LiDAR data fused with coregistered bands. In Proceedings of Annual Conference of the Remote Sensing and Photogrammetry Society, pages 1­9, Cambridge, UK, September 5-8 2006. [7] Bartholom´ e E. and Belward A.S. GLC2000: a new approach to global land cover mapping from earth observation data. International Journal of Remote Sensing, 26(9):1959­ 1977, 2005. [8] Bates D.R. Rayleigh scattering by air. Planetary and Space Science, 32(6):785­790, 1984. [9] Beasy C., Hopkinson C., and Webster T. Classification of nearshore materials on the Bay of Fundy coast using LiDAR intensity data. In Proceedings of the Canadian Symposium for Remote Sensing, Wolfville, Canada, June 2005. [10] Benz U.C., Hofmann P., Willhauck G., Lingenfelder I., and Heynen M. Multiresolution, object-oriented fuzzy analysis of remote sensing data for GIS-ready information. ISPRS Journal of Photogrammetry and Remote Sensing, 58(3-4):239­258, 2004. 103

REFERENCES

104

[11] Benediktsson J., Chanussot J., and Fauvel M. Multiple classifier systems in remote sensing: From basics to recent developments. In Michal Haindl, Josef Kittler, and Fabio Roli, editors, Multiple Classifier Systems, volume 4472 of Lecture Notes in Computer Science, pages 501­512. Springer Berlin / Heidelberg, 2007. [12] Berdahl P. and Bretz E. Preliminary survey of the solar reflectance of cool roofing materials. Energy and Buildings, 25(2):149­158, 1997. [13] Berezowski T., Chorma´ nski J., Batelaan O., Canters F., and Van de Voorde T. Impact of remotely sensed land-cover proportions on urban runoff prediction. International Journal of Applied Earth Observation and Geoinformation, 16:54­65, 2012. [14] Bhatta B. Analysis of urban growth pattern using remote sensing and GIS: a case study of Kolkata, India. International Journal of Remote Sensing, 30(18):4733­4746, 2009. [15] Bhatta B., Saraswati S., and Bandyopadhyay D. Quantifying the degree-of-freedom, degree-of-sprawl, and degree-of-goodness of urban growth from remote sensing data. Applied Geography, 30(1):96­111, 2010a. [16] Bhatta B., Saraswati S., and Bandyopadhyay D. Urban sprawl measurement from remote sensing data. Applied Geography, 30(4):731­740, 2010b. [17] Blaschke T. Object based image analysis for remote sensing. ISPRS Journal of Photogrammetry and Remote Sensing, 65(1):2­16, 2010. [18] Blesius L. and Weirich F. The use of the minnaert correction for land-cover classification in mountainous terrain. International Journal of Remote Sensing, 26(17):3831­3851, 2005. [19] Bork E.W. and Su J.G. Integrating LiDAR data and multispectral imagery for enhanced classification of rangeland vegetation: a meta analysis. Remote Sensing of Environment, 111(1):11­24, 2007. [20] Boyd D.S. and Hill R.A. Validation of airborne LiDAR intensity values from a forested landscape using Hymap data: preliminary analyses. International Archives of Photogrammetry, Remote Sensing, and Spatial Information Sciences, 36(Part3/W52):71­ 76, 2007. [21] Brenner C. Building reconstruction from images and laser scanning. International Journal of Applied Earth Observation and Geoinformation, 6(3/4):187­198, 2005. [22] Brennan R. and Webster T.L. Object-oriented land cover classification of lidar-derived surfaces. Canadian Journal of Remote Sensing, 32(2):162­172, 2006. 104

105

REFERENCES

[23] Bretar C., Hopkinson C., and Webster T. Managing full waveform LiDAR data: a challenging task for the forthcoming years. International Archives of Photogrammetry, Remote Sensing and Spatial Information Sciences, 37(Part B1):415­420, 2008. [24] Bucholtz A. Rayleigh-scattering calculations for the terrestrial atmosphere. Applied Optics, 34(15):2765­2773, 1995. [25] Buyantuyev A. and Wu J. Urban heat islands and landscape heterogeneity: linking spatiotemporal variations in surface temperatures to land-cover and socioeconomic patterns. Landscape Ecology, 25(1):17­33, 2010. [26] Candocia F.M. Jointly registering images in domain and range by piecewise linear comparametric analysis. IEEE Transactions on Image Processing, 12(4):409­419, 2003. [27] Candocia F.M. Analysis and enhancements to piecewise linear comparametric image registration. IEEE Transactions on Image Processing, 14(2):181­188, 2005. [28] Carleer A.P., Debeir O., and Wolff E. Assessment of very high spatial resolution satellite image segmentations. Photogrammetric Engineering & Remote Sensing, 71(11):1285­ 1294, 2005. [29] Cary and Associates. The global market for airborne LiDAR systems and services. http: //www.caryandassociates.com/marketing_tools/market_reports/rpt4.html, February 2009. [30] Charaniya A.P., Manduchi R., and Lodha S.K. Supervised parametric classification of aerial LiDAR data. In Proceedings of the IEEE 2004 Conference on Computer Vision and Pattern Recognition Workshop, volume 3, pages 1­8, Baltimore, June 27 - July 2 2004. [31] Chasmer L., Hopkinson C., Smith B., and Treitz P. Examining the influence of changing laser pulse repetition frequencies on conifer forest canopy returns. Photogrammetric Engineering & Remote Sensing, 72(12):1359­1367, 2006. [32] Chattopadhyay S., Gupta S., and Saha R.N. Spatial and temporal variation of urban air quality: a GIS approach. Journal of Environmental Protection, 1(1):264­277, 2010. [33] Chen D.M. and Stow D. The effect of training strategies on supervised classification at different spatial resolutions. Photogrammetric Engineering & Remote Sensing, 68(11):1155­1161, 2002. [34] Chen Y., Su W., Li J., and Sun Z. Hierarchical object oriented classification using very high resolution imagery and LiDAR data over urban areas. Advances in Space Research, 43(7):1101­1110, 2009. 105

REFERENCES

106

[35] Chen Y., R¨ aikk¨ onen E., Kaasalainen S., Suomalainen J., Hakala T., Hyypp¨ a J., and Chen R. Two-channel hyperspectral LiDAR with a supercontinuum laser source. Sensors, 10(7):7057­7066, 2010. [36] Chen Z., Gong C., Wu J., and Yu S. The influence of socioeconomic and topographic factors on nocturnal urban heat islands: a case study in Shenzhen, China. International Journal of Remote Sensing, 33(12):3834­3849, 2012. [37] Chormansk J., Van de Voorde T., De Roeck T., Batelaan O., and Canters F. Improving distributed runoff prediction in urbanized catchments with remote ssensing based estimates of impervious surface cover. Sensors, 8(2):910­932, 2008. [38] Cihlar J. Land cover mapping of large areas from satellites: status and research priorities. International Journal of Remote Sensing, 21(6&7):1093­1114, 2000. [39] Cole W.P., Marciniak M.A., and Haeri M.B. Atmospheric-turbulence-effects correction factors for the laser range equation. Optical Engineering, 47(12):126001, 2008. [40] Coren F. and Sterzai P. Radiometric correction in laser scanning. International Journal of Remote Sensing, 27(15):3097­3104, 2006. [41] Dalponte M., Bruzzone L., and Gianelle D. Fusion of hyperspectral and LiDAR remote sensing data for classification of complex forest areas. IEEE Transactions on Geosciences and Remote Sensing, 46(5):1416­1427, 2008. [42] Dare P.M. Shadow analysis in high-resolution satellite imagery of urban areas. Photogrammetric Engineering & Remote Sensing, 71(2):169­177, 2005. [43] Du Y., Teillet P.M., and Cihlar J. Radiometric normalization of multitemporal highresolution satellite images with quality control for land cover change detection. Remote Sensing of Environment, 82(1):123­134, 2002. [44] Durieux L., Lagabrielle E., and Nelson A. A method for monitoring building construction in urban sprawl areas using object-based analysis of SPOT 5 images and existing GIS data. ISPRS Journal of Photogrammetry and Remote Sensing, 63(4):399­408, 2008. [45] El-Ashmawy N., Shaker A., and Yan W.Y. Pixel vs object-based image classification techniques for lidar intensity data. International Archives of Photogrammetry, Remote Sensing, and Spatial Information Sciences, 38(Part 5/W12):1­6, 2011. [46] Elberink S.O. and Vosselman G. Building reconstruction by target based graph matching on incomplete laser data: analysis and limitations. Sensors, 9(8):6101­6118, 2009. [47] Epstein J., Payne K., and Kramer E. Techniques for mapping suburban sprawl. Photogrammetric Engineering & Remote Sensing, 63(9):913­918, 2002. 106

107

REFERENCES

[48] Fang H.T. and Huang D.S. Noise reduction in lidar signal based on discrete wavelet transform. Optics Communication, 233(1-3):67­76, 2004. [49] Ferdinandov E., Dimitrov K., Dandarov A., and Bakalski I. A general model of the atmospheric scattering in the wavelength interval 300-1100nm. Radioengineering, 18(4):517­521, 2009. [50] Filippov V.L., Makarov A.S., and Ivanov V.P. Construction of regional semiempirical models of optical characteristics of the atmosphere. Akademiia Nauk SSSR, Doklady, 265(6):1353­1356, 1982. [51] Foody G.M. Thematic map comparison: evaluating the statistical significance of differences in classification accuracy. Photogrammetric Engineering & Remote Sensing, 70(5):627­633, 2004. [52] Friedl M.A., McIver D.K., Hodges J.C., Zhang X.Y., Muchoney D., Strahler A.H., Woodcock C.E., Gopal S., Schneider A., Cooper A., Bacinni A., Gao F., and Schaaf C. Global land cover mapping from modis: algorithms and early results. Remote Sensing of Environment, 83(1-2):287­302, 2002. [53] Geerling G.W., Labrador-Garcia M., Clevers J.G.P.W., Ragas A.M.J., and Smits A.J.M. Classification of floodplain vegetation by data fusion of spectral (CASI) and LiDAR data. International Journal of Remote Sensing, 28(19):4263­4282, 2007. [54] Goodale R., Hopkinson C., Colville D., and Amirault-Langlais D. Mapping piping plover (Charadrius melodus melodus) habitat in coastal areas using airborne LiDAR data. Canadian Journal of Remote Sensing, 33(6):519­533, 2007. [55] Gong W., Song S., Zhu B., Shi S., Li F., and Cheng X. Multi-wavelength canopy LiDAR for remote sensing of vegetation: design and system performance. ISPRS Journal of Photogrammetry and Remote Sensing, 69:1­9, 2012. [56] Gregorio A.D. and Jansen L.J.M. Land Cover Classification System, Classification Concepts and User Manual. 2000. [57] Habib A.F., Kim E.M., and Kim C.J. New methodologies for true orthophoto generation. Photogrammetric Engineering & Remote Sensing, 3(1):25­36, 2007. [58] Habib A., Bang K.I., Kersting A.P., and Chow J. Alternative methodologies for LiDAR system calibration. Remote Sensing, 2:874­907, 2010. [59] Habib A., Kersting A.P., Shaker A., and Yan W.Y. Geometric calibration and radiometric correction of LiDAR data and their impact on the quality of derived products. Sensors, 11(9):9069­9097, 2011. 107

REFERENCES

108

[60] Hakala T., Suomalainen J., Kaasalainen S., and Chen Y. Full waveform hyperspectral LiDAR for terrestrial laser scanning. Optical Express, 20(7):7119­7127, 2012. [61] Han W.S. and Burian S.J. Determining effective impervious area for urban hydrologic modeling. Journal of Hydrologic Engineering, 14(2):111­120, 2009. [62] Hayes D.S. and Latham D.W. A rediscussion of the atmospheric extinction and the absolute spectral-energy distribution of Vega. The Astrophysical Journal, 197:593­601, 1975. [63] Helmer E.H. and Ruefenacht B. A comparison of radiometric normalization methods when filling cloud gaps in Landsat imagery. Canadian Journal of Remote Sensing, 33(4):325­340, 2007. [64] Heo J. and FitzHugh T.W. A standardized radiometric normalization method for change detection using remotely sensed imagery. Photogrammetric Engineering & Remote Sensing, 66(2):173­181, 2000. [65] Herold M., Goldstein N.C., and Clarke K.C. The spatiotemporal form of urban growth: measurement, analysis and modeling. Remote Sensing of Environment, 86(3):286­302, 2003. [66] Hou Z. A review on MR image intensity inhomogeneity correction. International Journal of Biomedical Imaging, 2006:1­11, 2006. [67] H¨ ofle B. and Pfeifer N. Correction of laser scanning intensity data: data and model-driven approaches. ISPRS Journal of Photogrammetry and Remote Sensing, 62(6):415­433, 2003. [68] Jat M.K., Garg P.K., and Khare D. Monitoring and modelling of urban sprawl using remote sensing and GIS techniques. International Journal of Applied Earth Observation and Geoinformation, 10(1):26­43, 2008. [69] Jenn D. Radar and Laser Cross Section Engineering. American Institute of Aeronautics and Astronautics (AIAA) Education Series, 2nd edition, 2005. [70] Jelalian A.V. Laser Radar Systems. Artech House, Boston, London, 1992. [71] Jensen J.R. Introductory Digital Image Processing: A Remote Sensing Perspective. Upper Saddle River: Prentice-Hall, 3rd edition edition, 2005. [72] Ji W., Ma J., Twibell R.W., and Underhill K. Characterizing urban sprawl using multistage remote sensing images and landscape metrics. Computers, Environment and Urban Systems, 30(6):861­879, 2006. 108

109

REFERENCES

[73] Jiang X., Wiedinmyer C., Chen F., Yang Z.-L., and Lo J. C.-F. Predicted impacts of climate and land use change on surface ozone in the Houston, Texas, area. Journal of Geophysical Research, 113(D20312):doi:10.1029/2008JD009820, 2008. [74] Jutzi B. and Gross H. Investigations on surface reflection models for intensity normalization in airborne laser scanning (ALS) data. Photogrammetric Engineering & Remote Sensing, 76(9):1051­1060, 2010. [75] Kaasalainen S., Hyypp¨ a J., Litkey P., Hyypp¨ a H., Ahokas E., Kukko A., and Kaartinen H. Radiometric calibration of ALS intensity. International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, 36(Part3/W52):201­205, 2007. [76] Kaasalainen M. and Kaasalainen S. Aperture size effects on backscatter intensity measurements in earth and space remote sensing. Journal of Optical Science of America A, 25(2):1142­1146, 2008. [77] Kaasalainen S., Hyypp¨ a H., Kukko A., Litkey P., Ahokas E., Hyypp¨ a J., Lehner H., Jaakkola A., Suomalainen J., Akuj¨ arvi A., Kaasalainen M., and Pyysalo U. Radiometric calibration of lidar intensity with commercially available reference targets. IEEE Transactions on Geoscience and Remote Sensing, 47(2):588­598, 2009. [78] Kaasalainen S., Krooks A., Kukko A., and Kaartinen H. Radiometric calibration of terrestrial laser scanners with external reference targets. Remote Sensing, 1(3):144­158, 2009b. [79] Kaasalainen S., Niittym¨ aki H., Krooks A., Koch K., Kaartinen H., Vain A., and Hyypp¨ a H. Effect of target moisture on laser scanner intensity. IEEE Transactions on Geoscience and Remote Sensing, 48(4):2128­2136, 2010. [80] Kaasalainen S., Jaakkola A., Kaasalaninen M., Krooks A., and Kukko A. Analysis of incidence angle and distance effects on terrestrial laser scanner intensity: search for correction methods. Remote Sensing, 3(10):2207­2221, 2011. [81] Kato S. and Yamaguchi Y. Analysis of urban heat-island effect using ASTER and ETM+ data: Separation of anthropogenic heat discharge and natural heat radiation from sensible heat flux. Remote Sensing of Environment, 99(1-2):44­54, 2005. [82] Kato S. and Yamaguchi Y. Estimation of storage heat flux in an urban area using ASTER data. Remote Sensing of Environment, 110(1):1­17, 2007. [83] Kim K. and Shan J. Building roof modeling from airborne laser scanning data based on level set approach. ISPRS Journal of Photogrammetry and Remote Sensing, 66(4):484­ 497, 2011. 109

REFERENCES

110

[84] Korpela I., Ørka H.O., Hyypp¨ a J., Heikkinen V., and Tokola T. Range and AGC normalization in airborne discrete-return LiDAR intensity data for forest canopies. ISPRS Journal of Photogrammetry and Remote Sensing, 65(4):369­379, 2010. [85] Kukko A., Kaasalainen S., and Litkey P. Effect of incidence angle on laser scanner intensity and surface data. Applied Optics, 47(7):986­992, 2008. [86] Kumar A., Pandey A.C., Hoda N., and Jeyaseelan A.T. Evaluation of urban sprawl pattern in the tribal-dominated cities of Jharkhand state, India. International Journal of Remote Sensing, 32(22):7651­7675, 2011. [87] Lafarge F. and Mallet C. Creating large-scale city models from 3D-point clouds: a robust approach with hybrid representation. International Journal of Computer Vision, 99(1):69­85, 2012. [88] Lewis J.E., Leppar¨ anta M., and Granberg H.B. Statistical properties of sea ice surface topography in the Baltic sea. Tellus A, 45(2):127­142, 1993. [89] Lai X. Zheng X. and Wan Y. A kind of filtering algorithms for LiDAR intensity image based on flatness terrain. In Proceedings of International Symposium on Spatiotemporal Modelling, Spatial Reasoning, Analysis, Data Mining and Data Fusion, Beijing, China, August 27-29 2005. [90] Lai Y.R., Chung K.L., Lin G.Y., and Chen C.H. Gaussian mixture modeling of histograms for contrast enhancement. Expert Systems with Applications, 39(8):6720­6728, 2012. [91] Li J., Song C., Cao L., Zhu F., Meng X., and Wu J. Impacts of landscape structure on surface urban heat islands: a case study of Shanghai, China. Remote Sensing of Environment, 115(12):3249­3263, 2011. [92] Li G. and Weng Q. Measuring the quality of life in city of Indianapolis by integration of remote sensing and census data. International Journal of Remote Sensing, 28(2):249­ 267, 2007. [93] Li Z., Bruggemann T.S., Ford J.J., Mejias L., and Liu Y. Toward automated power line corridor monitoring using advanced aircraft control and multisource feature fusion. Journal of Field Robotics, 29(1):4­24, 2012. [94] Liang B. and Weng Q. Assessing urban environmental quality change of Indianapolis, United States, by the remote sensing and GIS integration. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 4(1):43­55, 2011. [95] Liu H. and Weng Q. Seasonal variations in the relationship between landscape pattern and land surface temperature in Indianapolis, U.S.A. Environmental Monitoring and 110

111 Assessment, 144(1-3):199­219, 2008.

REFERENCES

[96] Liu H. and Weng Q. Scaling-up effect on the relationship between landscape pattern and land surface temperature. Photogrammetric Engineering & Remote Sensing, 75(3):291­304, 2009. [97] Liu H. and Zhou Q. Developing urban growth predictions from spatial indicators based on multi-temporal images. Computers, Environment and Urban Systems, 29(5):580­594, 2005. [98] Lloyd C.D. and Atkinson P.M. Deriving DSMs from LiDAR data with kriging. International Journal of Remote Sensing, 23(12):2519­2524, 2002. [99] Lloyd C.D. and Atkinson P.M. Deriving ground surface digital elevation models from LiDAR data with geostatistics. International Journal of Geographical Information Science, 20(5):535­563, 2006. [100] Loew A. and Mauser W. Generation of geometrically and radiometrically terrain corrected SAR image products. Remote Sensing of Environment, 106(3):337­349, 2007. [101] Lohr U. Digital elevation models by laser scanning. Photogrammetric Record, 16(91):105­ 109, 1998. [102] Looney S.W. A statistical technique for comparing the accuracies of several classifiers. Pattern Recognition Letters, 8(1):5­9, 1988. [103] Loveland T.R., Reed B.C., Brown J.F., Ohlen D.O., Zhu Z., Yang L., and Merchant J.W. Development of a global land cover characteristics database and IGBP DISCover from 1 km AVHRR data. International Journal of Remote Sensing, 21(6&7):1303­1330, 2000. [104] Mallet C. and Bretar F. Full-waveform topographic LiDAR: state-of-the-art. ISPRS Journal of Photogrammetry and Remote Sensing, 64(1):1­16, 2009. [105] Mann S. Comparametric equations with practical applications in quantigraphic image processing. IEEE Transactions on Image Processing, 9(8):1389­1406, 2000. [106] Matikainen L., Hyypp¨ a J., Ahokas E., Markelin L., and Kaartinen H. Automatic detection of buildings and changes in buildings for updating of maps. Remote Sensing, 2(5):1217­ 1248, 2010. [107] McGovern E.A., Holden N.M., Ward S.M., and Collins J.F. The radiometric normalization of multitemporal Thematic Mapper imagery of the midlands of Ireland - a case study. International Journal of Remote Sensing, 23(4):751­766, 2002. 111

REFERENCES

112

[108] McMillan R.W. Atmospheric turbulence effects on radar systems. In Proceedings of the IEEE 2010 National Aerospace and Electronics Conference, pages 181­196, Dayton, Ohio, USA, July 14-16 2010. [109] Mitraka Z., Chrysoulakis N., Kamarianakis Y., Partsinevelos P., and Tsouchlaraki A. Improving the estimation of urban surface emissivity based on sub-pixel classification of high resolution satellite imagery. Remote Sensing of Environment, 117(1):125­134, 2012. [110] Morsdorf F., Nichol C., Malthus T., and Woodhouse I.H. Assessing forest structural and physiological information content of multi-spectral LiDAR waveforms by radiative transfer modeling. Remote Sensing of Environment, 113(10):2152­2163, 2009. [111] Motlagh A.C., Ahmadi V., Ghassemlooy Z., and Abedi K. The effect of atmospheric turbulence on the performance of the free space optical communication. In Proceedings of the 6th International Symposium on Communication Systems, Networks and Digital Signal Processing, pages 540­543, Graz, Austria, July 23-25 2008. [112] Mutlua M., Popescua S.C., Striplingb C., and Spencer T. Mapping surface fuel models using LiDAR and multispectral data fusion for fire behavior. Remote Sensing of Environment, 112(1):274­285, 2008. [113] Myeong S., Nowak D.J., Hopkins P.F., and Brock R.H. Urban cover mapping using digital, high-spatial resolution aerial imagery. Urban Ecosystems, 5(4):243­256, 2001. [114] National Research Council. Radiative forcing of climate change: expanding the concept and addressing uncertainties. The National Academies Press, Washington, DC, USA, 205. [115] Nichol J. and Wong M.S. Modeling urban environmental quality in a tropical city. Landscape and Urban Planning, 73(1):49­58, 2005. [116] Nichol J., Wong M.S., Fung C., and Leung K.K.M. Assessment of urban environmental quality in a subtropical city using multispectral satellite images. Environment and Planning B: Planning and Design, 33(1):39­58, 2006. [117] Nichol J. An emissivity modulation method for spatial enhancement of thermal satellite images in urban heat island analysis. Photogrammetric Engineering & Remote Sensing, 75(5):547­556, 2009. [118] Nichol J. and Wong M.S. Mapping urban environmental quality using satellite data and multiple parameters. Environment and Planning B: Planning and Design, 36(1):170­ 185, 2009. 112

113

REFERENCES

[119] Onishi A., Cao X., Ito T., Shi F., and Imura H. Evaluating the potential for urban heat-island mitigation by greening parking lots. Urban Forestry & Urban Greening, 9(4):323­332, 2010. [120] Patil K.D. Cochran's Q test: exact distribution. Journal of the American Statistical Association, 70(349):186­189, 1975. [121] Pauleit S., Ennos R., and Golding Y. Modeling the environmental impacts of urban land use and land cover change - a study in Merseyside, UK. Landscape and Urban Planning, 71(2-4):295­310, 2005. [122] Pedireddi L.B. and Srinivasan B. Characterization of atmospheric turbulence effects and their mitigation using wavelet-based signal processing. IEEE Transactions on Communications, 58(6):1795­1802, 2010. [123] Petrie G. and Toth C.K. Introduction to laser ranging, profiling, and scanning. In J. Shan and C.K. Toth, editors, Topographic Laser Ranging and Scanning: Principles and Processing. CRC Press, 2009a. [124] Petrie G. and Toth C.K. Airborne and spaceborne laser profiles and scanners. In J. Shan and C.K. Toth, editors, Topographic Laser Ranging and Scanning: Principles and Processing. CRC Press, 2009b. [125] Pu R., Landry S., and Yu Q. Object-based urban detailed land cover classification with high spatial resolution IKONOS imagery. International Journal of Remote Sensing, 32(12):3285­3308, 2011. [126] Rahman A., Aggarwal S.P., Netzband M., and Fazal S. Monitoring urban sprawl using remote sensing and GIS techniques of a fast growing urban centre, India. IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing, 4(1):55­64, 2011a. [127] Rahman A., Kumar Y., Fazal S., and Bhaskaran S. Urbanization and quality of urban environment using remote sensing and GIS techniques in East Delhi-India. Journal of Geographic Information System, 3(1):62­84, 2011b. [128] Rajasekar U. and Weng Q. Urban heat island monitoring and analysis using a nonparametric model: a case study of Indianapolis. ISPRS Journal of Photogrammetry and Remote Sensing, 64(1):86­96, 2009. [129] Ravagnani F., Pellegrinelli A., and Franchini M. Estimation of urban impervious fraction from satellite images and its impact on peak discharge entering a storm sewer system. Water Resources Management, 23(10):1893­1915, 2009. 113

REFERENCES

114

[130] Ria~ no D., Chuvieco E., Salas J., and Aguado I. Assessment of different topographic corrections in Landsat-TM data for mapping vegetation types. IEEE Transactions on Geoscience and Remote Sensing, 41(5):1056­1061, 203. [131] Richter R., Kellenberger T., and Kaufmann H. Comparison of topographic correction methods. Remote Sensing, 1:184­196, 2009. [132] Riegler G., Stolz R., and Mauser W. Geometric and radiometric corrections of ERS SAR data for biomass estimation of meadows in rugged terrain. In Proceedings of SPIE, EUROPTO Series, pages 224­236, Barcelona, Spain, September 1998. [133] Roncat A., Bergauer G., and Pfeifer N. B-spline deconvolution for differential target cross-section determination in full-waveform laser scanning data. ISPRS Journal of Photogrammetry and Remote Sensing, 66(4):418­428, 2011. [134] Rothman L.S., Gordon I.E., Barbe A., Benner D.C., Bernath P.F., Birk M., Boudon V., Brown L.R., Campargue A., Champion J.-P., Chance K., Coudert L.H., Dana V., Devi V.M., Fally S., Flaud J.-M., Gamache R.R., Goldman A., Jacquemart D., Kleiner I., Lacome N., Lafferty W.J., Mandin J.-Y., Massie S.T., Mikhailenko S.N., Miller C.E., Moazzen-Ahmadi N., Naumenko O.V., Nikitin A.V., Orphal J., Perevalov V.I., Perrin  A., Predoi-Cross A., Rinsland C.P., Rotger M., Sime ckov´ a M., Smith M.A.H., Sung K., Tashkun S.A., Tennyson J., Toth R.A., Vandaele A.C., and Vander Auwera J. The HITRAN 2008 molecular spectroscopic database. Journal of Quantitative Spectroscopy & Radiative Transfer, 110(9/10):533­572, 2008. [135] Roy D.P., Ju J., Lewis P., Schaaf C., Gao F., Hansen M., and Lindquist E. Multi-temporal MODIS-Landsat data fusion for relative radiometric normalization, gap filling, and prediction of Landsat data. Remote Sensing of Environment, 112(6):3112­3130, 2008. [136] Schawlow A.L. and Townes C.H. Infrared and optical masers. Physical Review, 112(6):1940­1949, 1958. [137] Shaker A., Yan W.Y., and El-Ashmawy N. The effects of laser reflection angle on radiometric correction of the airborne LiDAR intensity data. In ISPRS Workshop Laser Scanning 2011, Calgary, Canada, August 29-31 2011. [138] Shan J. and Sampath A. Urban DEM generation from raw LiDAR data: a labeling algorithm and its performance. Photogrammetric Engineering & Remote Sensing, 71(2):217­226, 2005. [139] Shimada M. Radiometric and geometric calibration of JERS-1 SAR. Advanced Space Research, 17(1):79­88, 1996. 114

115

REFERENCES

[140] Shimada M., Isoguchi O., Tadono T., and Isono K. PALSAR radiometric and geometric calibration. IEEE Transactions on Geoscience Remote Sensing, 47(12):3915­3931, 2009. [141] Silfvast W.T. Laser Fundamentals. Cambridge University Press, New York, 1996. [142] Small D., Holecz F., Meier E., Nesch D., and Barmettler A. Geometric and radiometric calibration of RADARSAT images. In Proceedings of Geomatics in the Era of RADARSAT, Ottawa, Canada, May 24-30 1997. [143] Soenen S.A., Peddle D.R., and Coburn C.A. SCS+C: A modified sun-canopy-sensor topographic correction in forested terrain. IEEE Transactions on Geoscience and Remote Sensing, 43(9):2148­2159, 2005. [144] Song J.H., Han S.H., Yu K., and Kim Y.I. Assessing the possibility of land cover classification using LiDAR intensity data. In Proceedings of the ISPRS Technical Commission III Symposium 2002, Graz, Austria, September 9-13 2002. [145] Soudarissanane S., J. Van Ree, Bucksch A., and Lindenbergh R. Error budget of terrestrial laser scanning: influence of the incidence angle on the scan quality. In Proceedings 3DNordOst, Berlin, Germany, 2007. [146] Steinvall O. Effects of target shape and reflection on laser radar cross sections. Applied Optics, 39(24):4381­4391, 2000. [147] Streutker D.R. A remote sensing study of urban heat island of Houston, Texas. International Journal of Remote Sensing, 23(13):2595­2608, 2002. [148] Streutker D.R. Satellite-measured growth of the urban heat island of Houston, Texas. Remote Sensing of Environment, 85(3):282­289, 2003. [149] Sudhira H.S., Ramachandra T.V., and Jagadish K.S. Urban sprawl: metrics, dynamics and modeling using GIS. International Journal Applied Earth Observation and Geoinfomation, 5(1):29­39, 2004. [150] Sun H., Forsythe W., and Waters N. Modeling urban land use change and urban sprawl: Calgary, Alberta, Canada. Networks and Spatial Economics, 7(4):353­376, 2007. [151] Suomalainen J., Hakala T., Kaartinen H., R¨ aikk¨ onen E., and Kaasalainen S. Demonstration of a virtual active hyperspectral LiDAR in automated point cloud classification. ISPRS Journal of Photogrammetry and Remote Sensing, 66(5):637­641, 2011. [152] Superczynsk S.D. and Christopher S.A. Exploring land use and land cover effects on air quality in Central Alabama using GIS and remote sensing. Remote Sensing, 3(12):2552­2567, 2011. 115

REFERENCES

116

[153] Tewolde M.G. and Cabral P. Urban sprawl analysis and modeling in Asmara, Eritrea. Remote Sensing, 3(10):2148­2165, 2011. [154] Thanapura P., Helder D.L., Burckhard S., Warmath E., O'Neill M., and Galster D. Mapping urban land cover using Quickbird NDVI and GIS spatial modeling for runoff coefficient determination. Photogrammetric Engineering & Remote Sensing, 73(1):57­ 65, 2007. [155] Tian G., Yang Z., and Xie Y. Detecting spatiotemporal dynamic landscape patterns using remote sensing and the lacunarity index: a case study of Haikou City, China. Environment and Planning B: Planning and Design, 34(3):556­569, 2007. [156] Tokola T., Sarkeala J., and van der Linden M. Use of topographic correction in Landsat TM-based forest interpretation in Nepal. International Journal of Remote Sensing, 22(4):551­563, 2001. [157] Tomasi C., Vitale V., Petkov B., Lupi A., and Cacciari A. Improved algorithm for calculations of Rayleigh-scattering optical depth in standard atmospheres. Applied Optics, 44(16):3320­3341, 2005. [158] Tran H., Uchihama D., Ochi S., and Yasuoka Y. Assessment with satellite data of the urban heat island effects in Asian mega cities. International Journal of Applied Earth Observation and Geoinformation, 8(1):34­48, 2006. [159] Tucker C.J., Grant D.M., and Dykstra J.D. NASA's global orthorectified landsat data set. Photogrammetric Engineering & Remote Sensing, 70(3):313­322, 2004. [160] Vain A., Yu X., Kaasalainen S., and Hyypp¨ a J. Correcting airborne laser scanning intensity data for automatic gain control effect. IEEE Geoscience and Remote Sensing Letters, 7(3):511­514, 2010. [161] Van Der Sande C.J., de Jong S.M., and de Roo A.P.J. A segmentation and classification approach of IKONOS-2 imagery for land cover mapping to assist flood risk and flood damage assessment. International Journal of Applied Earth Observation and Geoinformation, 4(3):217­229, 2003. [162] Vosselman G., Kessels P., and Gorte B. The utilization of airborne laser scanning for mapping. International Journal of Applied Earth Observation and Geoinformation, 6(3-4):177­186, 2005. [163] Vovk U., Pernu s F., and Likar B. A review of methods for correction of intensity inhomogeneity in MRI. IEEE Transactions on Medical Imaging, 26(3):405­421, 2007. 116

117

REFERENCES

[164] Vu T.T., Yamazaki F., and Matsuoka M. Multi-scale solution for building extraction from LiDAR and image data. International Journal of Applied Earth Observation and Geoinformation, 11(4):281­289, 2009. [165] Wagner W. Radiometric calibration of small-footprint full-waveform airborne laser scanner measurements: basic physical concepts. ISPRS Journal of Photogrammetry and Remote Sensing, 65(10):505­513, 2010. [166] Wallace A. Nichol C. and Woodhouse I. Recovery of forest canopy parameters by inversion of multispectral LiDAR data. Remote Sensing, 4(2):509­531, 2012. [167] Walter V. Object-based classification of remote sensing data for change detection. ISPRS Journal of Photogrammetry and Remote Sensing, 58(3-4):225­238, 2004. [168] Wehr A. and Lohr U. Airborne laser scanning - an introduction and overview. ISPRS Journal of Photogrammetry and Remote Sensing, 54(2):68­82, 1999a. [169] Wehr A. and Lohr U. Theme issue on airborne laser scanning. ISPRS Journal of Photogrammetry and Remote Sensing, 54(2):61­83, 1999b. [170] Weng Q. and Yang S. Urban air pollution patterns, land use, and thermal landscape: an examination of the linkage using GIS. Environmental Monitoring and Assessment, 117(1-3):463­489, 2006. [171] Weng Q. Thermal infrared remote sensing for urban climate and environmental studies: methods, applications, and trends. ISPRS Journal of Photogrammetry and Remote Sensing, 64(4):335­344, 2009. [172] Weng Q., Rajasekar U., and Hu X. Modeling urban heat islands and their relationship with impervious surface and vegetation abundance by using ASTER images. IEEE Transactions on Geoscience and Remote Sensing, 49(10):4080­4089, 2011. [173] Weng Q. Remote sensing of impervious surfaces in the urban areas: requirements, methods, and trends. Remote Sensing of Environment, 117:34­49, 2011. [174] Wilkinson G.G. Results and implications of a study of fifteen years of satellite image classification experiments. IEEE Transactions on Geoscience and Remote Sensing, 43(3):433­440, 2005. [175] Woodhouse I. H., Nichol C., Sinclair P., Jack J., Morsdorf F., Malthus T. J., and Patenaude G. A multispectral canopy LiDAR demonstrator project. IEEE Geoscience and Remote Sensing Letters, 8(5):839­843, 2011. [176] Wu S.Q., Li Z.G., Xie S.L., and Rahardja S. Change detection using comparagram of images under varying illumination. Electronics Letters, 46(12):832­834, 2010. 117

REFERENCES

118

[177] Xian G. Analysis of impacts of urban land use and land cover on air quality in the Las Vegas region using remote sensing information and ground observations. International Journal of Remote Sensing, 28(24):5427­5445, 2007. [178] Xu C., Liu M., Zhang C., An S., Yu W., and Chen J.M. The spatiotemporal dynamics of rapid urban growth in the Nanjing metropolitan region of China. Landscape Ecology, 22(6):925­937, 2007. [179] Xu W., Wooster M.J., and Grimmond C.S.B. Modelling of urban sensible heat flux at multiple spatial scales: a demonstration using airborne hyperspectral imagery of Shanghai and a temperature-emissivity separation approach. Remote Sensing of Environment, 112(9):3493­3510, 2008. [180] Yan W.Y. and Shaker A. The effects of combining classifiers with the same training statistics using Bayesian decision rules. International Journal of Remote Sensing, 32(13):3729­3745, 2011. [181] Yang B., Fang L., Li Q., and Li J. Automated extraction of road markings from mobile lidar point clouds. Photogrammetric Engineering & Remote Sensing, 78(4):331­338, 2012. [182] Yang X. and Lo C.P. Relative radiometric normalization performance for change detection from multi-date satellite images. Photogrammetric Engineering & Remote Sensing, 66(8):967­980, 2000. [183] Yeh A.G.O. and Li X. Measurement and monitoring of urban sprawl in a rapidly growing region using entropy. Photogrammetric Engineering & Remote Sensing, 67(1):83­90, 2001. [184] Yoon J.S., Shin J.I., and Lee K.S. Land cover characteristics of airborne LiDAR intensity data: a case study. IEEE Geoscience and Remote Sensing Letters, 5(4):801­805, 2008. [185] Yu Q., Gong P., Chinton N., Biging G., Kelly M., and Schirokauer D. Object-based detailed vegetation classification with airborne high spatial resolution remote sensing imagery. Photogrammetric Engineering & Remote Sensing, 72(7):799­811, 2006. [186] Yu X.J. and Ng C.N. Spatial and temporal dynamics of urban sprawl along two urbanrural transects: A case study of Guangzhou, China. Landscape and Urban Planning, 79(1):96­109, 2007. [187] Yuan F., Sawaya K.E., Loeffelholz B.C., and Bauer M.E. Land cover classification and change analysis of the twin cities (Minnesota) Metropolitan Area by multitemporal Landsat remote sensing. Remote Sensing of Environment, 98(2-3):317­328, 2005. 118

119

REFERENCES

[188] Zeng X., Sui D.Z., and Li S. Linking urban field theory with GIS and remote sensing to detect signatures of rapid urbanization on the landscape: toward a new approach for characterizing urban sprawl. Urban Geography, 26(5):410­434, 2005. [189] Zhang J. and Wang Y. Study of the relationships between the spatial extent of surface urban heat islands and urban characteristic factors based on Landsat ETM+ data. Sensors, 8(11):7453­7468, 2008. [190] Zhang J. Multi-source remote sensing data fusion: status and trends. International Journal of Image and Data Fusion, 1(1):5­24, 2010. [191] Zhang K., Yan J., and Chen S.C. Automatic construction of building footprints from airborne LiDAR data. IEEE Transactions on Geoscience and Remote Sensing, 44(9):2523­2533, 2006. [192] Zhou W. and Troy A. An object-oriented approach for analysing and characterizing urban landscape at the parcel level. International Journal of Remote Sensing, 29(11):3119­ 3135, 2008. [193] Zhou W., Huang G., Troy A., and Cadenasso M.L. Object-based land cover classification of shaded areas in high spatial resolution imagery of urban areas: a comparison study. Remote Sensing of Environment, 113(8):1769­1777, 2009. [194] Zhou X. and Wang Y.C. Dynamics of land surface temperature in response to landuse/cover change. Geographical Research, 49(1):23­36, 2011. [195] Zhou Y.Y., Weng Q., Gurney K.R., Shuai Y., and Hu X. Estimation of the relationship between remotely sensed anthropogenic heat discharge and building energy use. ISPRS Journal of Photogrammetry and Remote Sensing, 67(1):65­72, 2012. [196] Zhu B., Gong W., Shi S., and Song S. A multi-wavelength canopy LiDAR for vegetation monitoring: system implementation and laboratory-based tests. Procedia Environmental Sciences, 10(Part C):2775­2782, 2011. [197] Zuev V.E. Laser-light transmission through the atmosphere. Topics in Applied Physics, 14:29­69, 1976. [198] Zurita-Milla R., Clevers J. G. P. W., Schaepman M. E., and Kneubuehler M. Effects of MERIS L1b radiometric calibration on regional land cover mapping and land products. International Journal of Remote Sensing, 28(3-4):653­673, 2007.

119


