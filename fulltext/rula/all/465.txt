THE FEAR FACTOR: EFFECTS OF IMPLICIT AND EXPLICIT PROCESSING ON THE
EMOTIONAL ENHANCEMENT OF MEMORY

Ronak Patel

B.Ed., Queen's University, 2006

B.Sc. (Honours), Queen's University, 2005

A thesis presented to Ryerson University

in partial fulfillment of the

requirements for the degree of

Master of Arts

in the Program of

Psychology

Toronto, Ontario, Canada, 2009

©Ronak Patel 2009

RYERSGN LMiVBRHTY L*MW

PR0PBWY0F

I hereby declare that I am the sole author of this thesis. I authorize Ryerson University to lend this thesis to other institutions or individuals for the purpose of scholarly research.

I furth~r authorize Ryerson University to reproduce this thesis by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of

(ii)

The Fear Factor: Effects of Implicit and Explicit Processing on the Emotional Enhancement of
Memory. Ronak Patel, M.A. in Psychology, 2009, Ryerson University.

This thesis examines whether implicit and explicit processing of emotional facial expressions

affects the emotional enhancement of memory (EEM). On the basis that explicit processing is

associated with relative reductions in amygdala activation and arousal, I predicted that fearful
faces, in particular, would lead to a robust EEM effect following encoding with implicit, but not

explicit processing. Participants were shown a series of facial expressions (happy, fearful, angry,

and neutral) in an "indirect" and a "direct" task designed to elicit implicit and explicit
processing, respectively. Later they underwent a recognition memory test using the RememberKnow paradigm. Fearful faces exhibited a unique pattern whereby indirect encoding led to an

enhanced subjective sense of recollection, whereas direct encoding prevented an increase in
recollection that was observed for all other emotions. These findings may reflect interactions among amygdalar/arousal thresholds and levels of processing (LOP) effects on recognition
memory.

Acknowledgements

I would like to thank my supervisor, Dr. Todd Girard, for his endless dedication, support, and

enthusiasm towards this project. I am grateful for the incredible mentorship and guidance he has given me over the past two years. Next, I would like to thank my co-supervisor, Dr. Robin
Green, for her constant support, mentorship, and for encouraging me to explore my interests in

emotional memory. I am also grateful to Dr. Julia Spaniol for her insightful feedback throughout
the development of this project.

I would like to thank the first cohort of Psychology graduate students at Ryerson University for
their friendship, support, and for making the past two years a truly enjoyable experience.

Finally, I would like to express my gratitude to my family as well as to my closest friends (you
know who you are), you all have been with me through the good times and bad and have

supported me unconditionally throughout. If I could express my gratitude to you in a few short

words, I would. But since I can't, I will simply say that I hope you all know that you are a loved
and valued part of my life.

List of Figures

Figure 1. Exemplar facial emotion photos from the Toronto Rehab Facial Emotion
Battery

Figure 2. Visual representation of "indirect" and "direct" encoding tasks
Figure 3. Mean arousal ratings for all levels of Emotion

Figure 4. Mean difference score for old stimuli receiving a Remember response
at each level of Encoding task and Emotion

Figure 5. Mean difference score for old stimuli receiving a Know response
at each level of Encoding task and Emotion

Figure 6. Mean Remember hit rates at each level of Encoding Task and Emotion...
Figure 7. Mean Know hit rates at each level of Encoding Task and Emotion
Figure 8a. Mean proportion ot laces encoaea in me inuireci ia&K at catu i^v^i ^

Confidence

Figure 8b. Mean
Confidence
Figure 9. Mean proportion of new taces at eacn level oi L.on

Figure 10. Depiction of levels of processing (LOP) effects masking emotional

enhancement of memory (EEM)-related decreases in Remember responses for fearful

List of Abbreviations

ANOVA: Analysis of variance

BOLD: Blood-oxygen level dependent
rCBF: Cerebral blood flow

Pr: Discrimination index

EEM: Emotional enhancement of memory
FA: False alarm

fMRI: Functional magnetic resonance imaging
K: Know response

LOP: Levels of processing
M: Mean

PET: Positron emission tomography
SAM: Self-assessment manikin
RT: Reaction time
R: Remember response

SCR: Skin conductance response

SD: Standard deviation
SEM: Standard error of the mean

SART: Sustained attention to response test

TR-FEB: Toronto Rehab facial emotion battery

The Fear Factor: Effects of Implicit and Explicit Processing on the
Emotional Enhancement of Memory

The emotional enhancement of memory (EEM) has been shown to be critically dependent

on two components: amygdala involvement and arousal. Studies have demonstrated that implicit and explicit emotional processing can alter these two components in distinct ways. This thesis
investigates the effects of implicit and explicit processing on the EEM. Before describing the
methods and objectives more specifically, several relevant literatures are reviewed below to

provide a background for the rationale. First, I review the concept of the EEM effect, and early
experiments in the field. Following this review, I will provide an overview of the relations

between the amygdala and sympathetic arousal to the EEM. I then detail the literature that

and subsequently, how this may affect the EEM effect. To this end, I propose the use of facial
emotion expressions in conjunction with behavioural tasks to elicit different processing demands.

I further specify why fearful facial expressions, may be particularly effective in examining the
specificity of amygdala-arousal contributions to the EEM. Finally, I put forward the RememberKnow paradigm as a means of measuring the EEM.
Introduction

Emotion has profound effects on how we remember events from our past. The presence

of affectively charged content can selectively enhance our ability to recall events, a phenomenon

known as the EEM. Our ability to experience emotion depends on the interaction of two key dimensional processes: valence and arousal (Russell, 1980). While valence refers to how
pleasant (positive

arousal refers to the intensity of

an event (i.e. how exciting or calming an event is perceived). Valence and arousal reflect multi-

component processes that comprise both autonomic responses (e.g., changes in peripheral

sympathetic activity) and subjective evaluations (e.g., cognitive responses based on individual
experience) (Cacioppo et al, 1992; Lang et al, 1993; Soussignan, 2005). The arousal dimension

and, more specifically, the physiological aspects of arousal, was the initial focus of early EEM
studies.

The Early Studies: A Focus on Arousal

Early studies investigating the EEM effect focused on autonomic indices of arousal, in

particular, and used the galvanic skin conductance response (SCR) as a probe into this
dimension. SCR is a measure of somatic and neurophysiological activity, presumed to reflect emotional states (Soussignan, 2005). In a seminal study by Kleinsmith and Kaplan (1963), participants were shown a series of words (e.g., kiss, rape, vomit, etc.) paired with numbers,

while their SCR was recorded. They were later tested for recall of the numbers at various time

intervals, ranging from 2 min to 1 week after encoding. Words associated with high a level of
SCR facilitated long-term retention as compared to words associated with lower levels of SCR.

Interestingly, participants demonstrated an inability to retrieve numbers associated with high

arousing words after a short period of time (e.g., 2 min). These findings were consistent with the
perseverative-consolidation theory proposed by Walker (1958), which stated that for all effortful learning, a consolidation phase or "active trace process" gradually forms over time. The theory

further stipulated a degree of "temporary inhibition of recall" occurs to protect the consolidating
trace against disruption (Walker & Tarte, 1963). According to the theory, high arousal during
the encoding phase should result in a more intense active trace process, thereby enhancing long-

term memory. However, high arousal should also cause a greater temporary inhibition of recall. Additional support for the theory came from others such as Levonian (1967), who presented 83

sensors. Similar to Kleinsmith and Kaplan, Levonian found that items associated with high levels
of arousal facilitated both long-term remembering and short-term forgetting. While researchers

have been able to replicate these findings (e.g., Walker & Tarte, 1963) other studies have demonstrated that high arousal can lead to benefits in both long and short-term retention (e.g.,
Corteen, 1969). Although the findings regarding the effects of arousal on short-term memory

have been mixed, these early studies firmly established the robust enhancing effect of high arousal on long-term, episodic memory (memory for specific life events of an individual's past).
Over the past few decades, there has been considerable interest in elucidating the neural
underpinnings mediating this effect.

Neurobiology ofthe EEM: Two Critical Components

Animal lesion studies have implicated the amygdala, a structure within the medial-

temporal lobe of the brain, as a critical neural substrate in facilitating long-term memory for
emotionally arousing events (Cahill, 2000).These findings have extended to humans. For

example, a number of studies have shown that patients with lesions to the amygdala show a

decrease, and in some cases, complete elimination of the EEM (e.g., Adolphs et ah, 1997; Phelps et ai, 1998). Findings from functional neuroimaging studies have provided yet another level of
support as amygdala activity at encoding predicts whether arousing items will later be
remembered or forgotten, an effect that is specific to arousing versus non-arousing items

(Kensinger & Corkin, 2004). While these findings confirm the role of the amygdala in the

consolidation of emotional arousing events for episodic memory, they do not address the
amygdala's relationship to autonomic arousal, a main focus of the early studies.

Autonomic arousal or more specifically, sympathetic arousal, reflects activity driven by

the sympathetic nervous system in response to emotional situations. The early EEM studies

employed SCR as an indirect measure of this sympathetic activity. Activation of the sympathetic
nervous system leads to the release of epinephrine and norepinephrine that bind to adrenergic

receptors on peripheral tissues. Animal studies have shown that the administration of epinephrine

enhances memory for emotionally arousing events (see McGaugh, Cahill, & Roozendal, 1996 for
a review). As epinephrine and norepinephrine released in the periphery do not easily cross the
blood brain barrier, they are thought to influence memory via stimulation of the vagus nerve

(Cahill, 2000). This nerve projects to areas in the brainstem that ultimately connect with the
locus coeruleus, which then releases norepinephrine in the amygdala and other brain structures

(e.g., hippocampus; LaBar & Cabeza, 2006). The amygdala has been identified as a key neural
structure in mediating the enhancing effects of epinephrine on memory. Post-training infusions
of P-adrene

block memory enhancing effects of peripheral epinephrine injections (Liang, Juler, & McGaugh,
1986). The finding that memory enhancing ettects ot epinepnrme are aiso oiouteu vy <x p-

adrenergic antagonists that do not readily enter the brain (e.g., sotalol), confirms that epinephrine

effects are initiated by activation of peripheral p-adrenergic receptors (Introini-Collison et ah,
1992). These findings support McGaugh's memory modulation hypothesis, which posits that
arousal induced by emotional events activates the amygdala, which in turn engages stress-

hormone systems (e.g., noradrenaline and cortisol) to promote memory consolidation (McGaugh,
2004). Enhanced consolidation is further facilitated by the interaction with other brain regions
such as the hippocampus. Indeed, lesions to the basolateral amygdala block the memory

modulatory effects of glucocorticoid injections in the hippocampus (Roozendal & McGaugh,

1997). The extensive findings from animal experiments have unveiled both the amygdala and
rine) as two

itical components mediating EEM. Findings from human studies have also shed light on the
crucial nature of these components.

LaBar and Phelps (1998) conducted a study with patients who had undergone either left

or right temporal lobectomy (en bloc resection of the anteromedial temporal lobe, including the
amygdala, hippocampus, and adjacent cortex). Arousal levels, as indexed by SCR, were

recorded while patients were viewing arousing and neutral words. Patients were asked to recall
the words immediately after encoding and after a 1-hour delay. While both patients and healthy
participa

arousin

g words relative to neutral words in all groups), the EEM was only observed among

healthy controls. The authors demonstrated that arousal, in the absence of amygdala

involvement, did not yield the EEM. Their findings were also consistent with the hypothesis that
the amygdala plays a critical role in the consolidation of emotionally arousing events. In 2006,
Anderson, Yamaguchi, Grabski, and Lacka compared memory for emotional scenes versus

emotional faces, both known to evoke significant amygdala activation. The EEM effect was

observed only when emotional stimuli were accompanied by increases in sympathetic arousal.

The authors concluded that amygdala activation and arousal represent dissociable processes that

interact to influence the EEM (also see Patel & Green, 2007). They further proposed the notion
of a threshold process, such that a sufficient level of sympathetic arousal is required to enhance

memory consolidation for emotionally arousing events. In summary, both animal and human

studies have demonstrated a dynamic interplay between arousal and the amygdala in producing the EEM, such that the absence of either component fails to yield the robust memory enhancing

effect. The study of factors that may modulate these components seems particularly important in

light of potential consequences on memory; however, few human studies have investigated such
factors.

Implicit/Explicit Processing ofEmotional Information

The way in which humans process emotional information modulates amygdala activation

as well as arousal. Critchley et al. (2000) showed that differential processing of facial emotions

resulted in distinct neural activation patterns. The authors were interested in whether effortful or
i-:+ :,,* ^+^+;^^ ^omA*;r«i wrmiri result in a different nattern of activation than implicit

interpretation of emotion (i.e. processing emotion without full cognitive awareness). In order to

elicit these two types of processing, "implicit" and "explicit" tasks were used. In the implicit
task, participa
require

Thus, the emotional

content was directly processed during the explicit task, but was more indirectly processed in the
implicit task. When each task was analyzed separately, the authors found support for the existence of two distinct neural pathways or networks underlying implicit and explicit

processing. Moreover, the authors found that when directly comparing the two tasks, the
amygdala region was significantly more active during the implicit task in comparison to the

explicit task. Another study by Hariri, Bookheimer, & Mazziotta (2000) found similar results
when examining cerebral blood flow (rCBF) changes during a matching and labeling task. Matching facial emotion expressions was associated with a bilateral increase of the rCBF

«k»TM,«p in thft amvedaia while labeling the same facial expressions, requiring a deeper level of explicit processing, was associated with a diminished rCBF response in the amygdalae. Other studies have also reported the same pattern of amygdala activation in response to implicit and

explicit emotional processing (e.g., Keightley at al., 2003; Lange et ah, 2003). Kapler et al.
(2001) extended these findings by demonstrating that explicit emotion processing not only attenuates amygdala activity but that the reduction in amygdala activation is accompanied by a concomitant suppression of sympathetic arousal. These results are consistent with other studies
demonstrating amygdala activity in response to emotionally salient stimuli is positively

correlated with increases in SCR (Critchley, Mathias, & Dolan, 2002; Furmark et al, 1997).
Taken together, these studies provide reliable evidence that implicit processing of facial

response and concomitantly suppresses sympathetic arousal. The current study aims to

investigate the effects of differential emotional processing on the EEM. Based on the above neurobiological evidence, I hypothesize that implicit processing will result in the EEM effect
whereas explicit processing will result in a relative suppression oi imt, cuc^i.

Probing EEM Specificity using Facial Emotion Expressions

In addition to task-related processing demands, the type of stimulus may affect the
strength of the EEM. A recent meta-analysis revealed that amygdala activation peaks across a

number of functional magnetic resonance imaging (fMRI) and positron emission tomography

(PET) studies yielded a stronger effect size for facial expressions in comparison to other stimuli
such as scenes (Sergerie, Chochol, & Armony, 2008). These meta-analytic findings point to the

addition, the use of different facial emotions affords the opportunity to examine the specificity of
amygdala-arousal contributions to the EEM. That is, the degree of amygdala activation in

response to facial expressions can depend on the particular type of emotion. Indeed, a growing

number of studies suggest that there are distinct neural pathways underlying the expression and

recognition of fear and other emotions such as anger. Whalen, Shin, Mclnerney, and Fisher

(2001) found that the blood-oxygen level dependent (BOLD) signal intensity in the amygdala

was greater to facial expressions of fear than of anger. In addition, PET findings from Blair et al.
(1999) found no evidence of activity in the amygdala for increasing intensities of angry facial

expressions. Rather, the same study found that facial expressions of anger were associated with activity in the orbitofrontal cortex and anterior cingulate cortex. A meta-analysis examining the
neuroanatomy of emotion recognition supported the view that anger was most significantly

associated with activity in the orbitofrontal cortex, while fear was most associated with activity
in the amygdala (Murphy, Nimmo-Smith, & Lawrence, 2003). These studies demonstrate that

the amygdala is preferentially activated by facial expressions of fear (also see meta-analysis by
Phan, Wager, Taylor, & Liberzon, 2002). The robustness of amygdala activation in response to

fearful stimuli is further supported by studies that report significant amygdala activation to

perceived conditions (Morris, Ohman, & Dolan, 1998; Whalen et al., 1998) and low attentional
load conditions (Hsu & Pessoa, 2007).

The contrast between fear and anger further extends to emotions that differ in valence,
such as facial expressions of happiness. While amygdala activation has been found in response to

the processing of happy faces, the magnitude of activation is often less than that observed in
response to fearful faces (Glascher, Tuscher, Weiller, & Biichel, 2004). These findings are

consistent with imaging findings that show bilateral amygdala activation is more associated with negative than positive emotions (Hamann, Ely, Hoffman, & Kilts, 2002). As the EEM critically
depends on significant amygdala activation and sympathetic arousal, I predict that implicit

of angry and happy faces. I further expect that such an effect will not be observed, that is, it will
be effectively "suppressed", for fearful faces that are processed under explicit conditions.

Importantly, these predictions extend Anderson et a/.'s (2006) arousal-threshold proposal to
but the effect is

dependent on exceeding a threshold of amygdala activation as well.
EEMandthe Remember-Know Paradigm

To test our specific EEM predictions, the current study used the Remember-Know

recognition paradigm originally developed by Tulving (1985). In this paradigm, participants are

asked to give a "Remember" response for items for which they become consciously aware of
nic details that were experienced at the time the item was presented (Wheeler & Stuss,

2003). The critical element of the Remember response is the participants' sense of re-living or "recollecting" an earlier event. In contrast, "Know" responses are associated with items that are

recognized, but for which the participant is not able to retrieve any supporting contextual
information. Thus, items with a Know response are thought to feel "familiar" to the participant.
The dual process theory of recognition proposes that Remember and Know responses reflect distinct underlying memory processes of "recollection" and "familiarity", respectively
(Yonelinas, 2002). Whereas recollection represents the retrieval of specific information,

familiarity represents retrieval in the absence of any detailed information. Recent EEM studies
using the Remember-Know paradigm have demonstrated that emotion selectively enhances the
subjective experience of recollection as indexed by an increased proportion of Remember

responses to emotionally arousing stimuli (Anderson et ah, 2006; Sharot, Delgado, & Phelps,

2004; Sharot, Verfaellie, & Yonelinas, 2007). These same studies have also shown that emotion
has no effects on the subjective experience of familiarity during recognition, as revealed by

similar levels of Know responding across emotional and neutral stimuli. Interestingly, the
enhanced feeling of recollection occurs even though overall recognition accuracy is not

necessarily enhanced (Sharot et ah, 2004,2007). That is, the EEM may be more related to the
level of conscious recollection than to retrieval accuracy per se.
Main Objective & Hypotheses

The main objective of this thesis is to examine the behavioural expression of the EEM for
different facial emotions using the Remember-Know paradigm under conditions of implicit and
explicit processing. The hypotheses of the current study are:

1)

Implicit processing of fearful faces will be associated with a heightened recollective
experience (as indexed by increased Remember responses) relative to neutral faces.

2) The EEM effect for fearful faces will be reduced or 'suppressed' under conditions of
explicit, as compared to implicit processing.

3) In contrast to fear, angry and happy faces will be associated with a lesser or no increase in recollection relative to neutral faces under conditions of either implicit or explicit
processing.

4) Facial emotions will have no effect on familiarity-based responses relative to neutral
expressions, under conditions of either implicit or explicit processing.
Methods

Participants and Design

Forty students (32 females, 8 males; mean age = 23.3 years, SD = 6.32 years) participated
in the current experiment. An additional 19 students were recruited to provide subjective ratings
of arousal (15 females, 4 males; mean age = 23.84 years, SD = 8.68 years). All participants were

enrolled at Ryerson University and either given course credit for their participation or

volunteered. Only participants between the ages of 18 to 65, with intact vision and hearing were

included in the study. We further screened all participants for any history of neurological or

psychiatric disorders, brain injury, substance abuse, or psychotropic medications. All screening
interviews were subjected to a blind review following data collection. Four participants were

excluded from analysis on the basis of their responses to the screening. Participants provided
informed consent after the nature of the experimental procedures had been explained. The
experiment consisted of a 2 (Encoding task: indirect, direct) X 4 (Emotion: happy, fearful, angry,

neutral) within-subjects design. The study was approved by the Research Ethics Boards of
Ryerson University and Toronto Rehabilitation Institute.
Stimuli

Stimuli were selected from the Toronto Rehab Facial Emotion Battery (TR-FEB), a

battery currently under development to address the limitations associated with sets of facial affect stimuli that are publicly available. The battery contains a greater number of unique faces, a
wider range of emotional expressions, greater ecological validity through semi-controlled

environments, and greater ethnic diversity as compared to existing collections (e.g., Pictures of
Facial Affect, Ekman & Friesen, 1976; International Affective Picture System , Lang, Bradley,
& Cuthbert, 2008; Florida Affect Battery , Bowers, Blonder, & Heilman, 1989; The AR Face

Database, Martinez & Benavente, 1998; The Psychological Image Collection at Stirling, <http://pics.psych.stir.ac.uk>; Pose, Illumination, and Expression Database, Sim, Baker, & Bsat
2003; The Karolinska Directed Emotional Faces, Lundqvist, Flykt, & Ohman, 1998). A total of

72 faces with normative data were selected from the TR-FEB (see Figure 1 for examples), and
the remaining 40 came from a similar set (NimStim Face Stimulus Set, Tottenham et aL, in

press). Only those photos achieving over 80% agreement on the communicative intent of the

photo were considered in the current study (see Patel, Green, & Girard, 2007 for normative study
on TR-FEB photos). In all photos, face orientation was forwards, standardized to black and

white, and scaled to the same size using Adobe Photoshop 7.0. Photos of 112 unique individuals

portraying one of four emotional expressions (happy, fearful, angry, and neutral) were selected
for the experiment. Fourteen photos (7 men and 7 women) representing each emotion were

presented at study (56 in total), and an additional 56 photos were used as recognition foils. An

additional 2 "buffer" photos were presented at the beginning of the indirect task and end of the direct encoding task (4 buffer photos in total). These 4 buffer items and 4 foils served as practice

items during the memory test. All recognition foils were matched to target items in terms of
gender, age, race/ethnicity, hair length, and stimulus set. Study items were presented to
participants in one of two fixed orders, such that two negative emotions did not occur in

immediate succession to one another, in order to prevent participants' SCRs1 from habituating to
negative emotions. Two separate orders were created to reduce the possibility of results being
due to specific ordering of emotions. Due to the careful ordering required and in order to meet

the demands for proper SCR synchronization, studied and unstudied sets of faces were the same

across participants. More specifically, items at encoding required specialized programming in

order to time lock studied items during each task to participants' SCR recordings through a series
of digital pulses that were transmitted between the stimulus presentation and physiological
recording equipment. At recognition, the order of presentation of studied and unstudied photos
was random for each participant.

To characterize the emotional value of the faces, an independent group of 19 participants

rated all photos used in the current study on arousal. Using the Self-Assessment Manikin
procedure (SAM; Lang, Bradley, Greenwald, & Hamm, 1993) participants rated each photo
1 SCR data not presented in this thesis.

along a 5-point, visually based scale. The SAM depicts a graphic character that ranges from

sleepy with closed eyes (' 1' - not arousing at all) to excited with open eyes ('5' - very arousing).

Happy

Fearful

Angry

Neutral

Figure 1. Exemplar facial emotion photos from the Toronto Rehab Facial Emotion Battery (TRFEB).

Encoding Task

Participants sat a computer where they were presented with two tasks: an "indirect" task and a "direct" task. These tasks were designed to target conditions of implicit and explicit
processing respectively. In the indirect task, pa..

gender of the face, e.g., "Are the following faces female?" In the direct task, participants were

asked a yes/no question about the emotional expression of the face, e.g., "Are the following faces happy?" (see Figure 2). In each task, participants were presented with four yes/no questions,
each of which was followed by a study set of seven faces. For the indirect task, two questions

(male vs. female) were repeated for a total of four trial sets. For the direct task, questions

pertaining to each of the four facial emotions were presented for the four trial sets. The ordering
of questions within each task (male versus female for indirect and type of emotion for direct) was

random. The indirect task always preceded the direct task to avoid the possibility of explicit
emotional processing carrying over from the direct to the indirect task.

©Hawing
faces

Direct Task

Are th&
following faces female?

indirect Task

Figure 2. Visual representation of "indirect" and "direct" encoding tasks. Participants were

presented with an "indirect" task and "direct" task to elicit implicit and explicit emotional

processing respectively. The indirect task preceded the direct task, and each task involved yes/no
questions in order to control for verbal demands.

Each face was

view each stimulus for its entire duration. An examiner seated behind the participant read each
question out loud as it appeared on the screen, and participants responded verbally ("yes" or

"no") upon presentation of each face (automated responding using a microphone was not

undertaken due to problems identified with time locking the microphone's recording to the SCR

signal in addition to time-locking stimulus presentation). All responses were recorded by the
examiner. In between the stimulus, a blank screen containing a fixation point was presented. The
fixation point varied between 16-24 s to allow the physiological SCR signal the opportunity to
return to baseline levels (Dawson, Schell, & Filion, 2000). The stimuli were presented on a

computer screen about 60 cm from the participant using E-Prime version 1.2. (Psychology

Software Tools, Inc., 2002). The text was printed in size 18 Courier New font and was presented
in black against a white background.
Delay Period

Following the end of the direct task, participants underwent a 15-min distraction period.
Participants completed 2 "filler" tasks: the Sustained Attention to Response Test (SART;

Roberston et ai, 1997) and the Simple and Choice Reaction Time (RT) Tests (Green & Melo,
unpublished instrument). Both filler tasks required sustained attention and vigilance to non-face
stimuli, and served to minimize the possibility that participants were rehearsing or maintaining
online representations of studied faces during the delay period. In the SART, participants were
presented with a series of numbers on a computer screen and asked to press a red button every

time they saw a number except for when they saw the number '3'. Each number was preceded by a fixation point (circle with an 'x' through it) in the center of the screen. Participants were asked
to focus their attention on the fixation point until the next number appeared on the screen. In the

simple RT test, participants were asked to press the ' 1' key every time they saw an arrow. In the

choice RT test, participants pressed the ' 1' key if the arrow pointed upwards and the '2' key if
the arrow pointed downwards. Participants were instructed to respond as quickly and as

accurately as possible. In both the simple and choice RT tests, a practice phase preceded the test
phase.

Recognition task

Participants received a surprise recognition memory test following the distraction period.
Recognition was measured using Remember-Know judgments (Tulving, 1985) and with
recognition confidence ratings (Yonelinas & Parks, 2007). This procedure was used to target

recollection and familiarity based processes in an explicit recognition task. Participants read
detailed instructions on how to make Remember-Know judgments (see Appendix A) and were

difference between a "Remember" and "Know" judgment. Participants completed a series of
practice trials and were asked to verbally justify their response choice. Once the experimenter
was assured that the participant had a good understanding of the instructions (i.e.,

"Remembering" a face reflected a specific conscious recollection of having seen the face during study including associated experimental details, thoughts, and/or feelings; whereas "Knowing"

reflected similar confidence of having seen a face, but without any accompanying specific
recollective details) they proceeded to the recognition test.

In the recognition task, foils consisted of unstudied individuals expressing the same four

emotions presented in the encoding task: fearful, angry, happy, and neutral. For example, if individual A's face was presented during study with afearful expression, then during recognition
testing, individual A served as an "old" studied item with the same fearful expression, whereas

"new" foils comprised of faces of unstudied individuals. Participants were explicitly told that
new faces would not contain photos of old faces with a different emotional expression, thus an

old face would appear as it did in the encoding phase or not at all. The stimuli were presented in

a random order on a computer screen using E-prime. Each trial consisted of two, self-paced slides showing the same photo: On the first slide, participants were asked whether the photo was
'new', 'remembered' or 'known' by pressing the appropriate key. On the second slide, the same
photo was shown and participants were asked to rate the confidence of their recognition response

on a scale of 1 (sure new) to 6 (sure old) as outlined by Yonelinas and Parks (2007). Participants selected a '6' to indicate that they were sure the item was previously studied, a '5' to indicate
that they were unsure if it was studied, and a '4' to indicate if they were guessing that it was studied. Participants responded with a' 1' if they were sure it was not previously studied, a '2' to
indicate that they were unsure it was not previously studied, and a '3' to indicate that they were
guessing it was not studied.
Data Analysis

Indices of recognition memory performance in the current study are based on hit rates

and false alarm rates. Hit rates are defined as the proportion of Remember (R) or Know (K)
responses given to an "old" face (RHitand KHit, respectively), whereas false alarms rates are

defined as the proportion of Remember or Know responses given to a "new" face (RFa and KFa,
respectively). Overall recognition accuracy was measured using the discrimination index (Pr)

derived from the two-high threshold model (Snodgrass & Corwin, 1988), and calculated as the

hit rate minus the false alarm rate2.
To examine the effects of emotion on different types of recognition, "emotional
difference scores" were calculated as outlined by Sharot et al. (2007). These difference scores

represent the proportion of emotional faces given a particular recognition response minus the

2 False alarms (FA) were not distinguishable by encoding task. New faces were matched to old faces by emotional
expression onij

required an FA correction and where 'Encoding Task' was a factor in the analysis, we equally applied the false
alarm rate to both the direct and indirect conditions.

proportion of neutral faces eliciting that response (e.g., RHit for fearful - RHit for neutral). Larger

positive values indicate that the emotion increased the likelihood of an enhancing effect on the
relevant response (R, K, or new). These difference scores were used to examine whether emotion enhanced the subjective experience of remembering (R) or whether it influenced

recognition in the absence of a feeling of recollection (K). To further quantify the effect of
emotional faces on recognition performance, the processes underlying remember and know
judgments were also assessed using model-based estimates of recollection and familiarity

(Yonelinas et ah, 1998). The dual process model assumes that recollection and familiarity reflect
distinct memory processes: Recollection represents a threshold process by which participants are

able to recall contextual details related to some aspect of the study event. Under this model,

recollection is estimated by the proportion of old faces receiving an R response (RHit) minus the
proportion of new faces receiving this response (RFa), then dividing by the proportion of times a

participant could have responded correctly with an R response (l-RFa): RHit - RFa/(l-RFa)
(recollection formula A). Alternatively, recollection is often estimated by simply subtracting RFa

from RHit (recollection formula B). Since RFais usually very close to zero, the two formulae generally provide similar results; however, formula A is thought to reflect true recollection based
on a high-threshold model, which assumes that, although new items may seem familiar, they
cannot truly be recollected (personal communication with Yonelinas via e-mail, May, 2009;

Yonelinas et al., 1998). When recollection fails, recognition is thought to be based on a
familiarity assessment process, assumed to be well-described by a signal-detection process.

Participants are instructed to respond with "Know" if an item cannot be recollected, and thus, familiarity is calculated by computing the probability of receiving a K response given the item

did not receive an R response, corrected for false alarms: Familiarity - (KWl-RHit)- (KFa)/(lRFa) (Yonelinas et ah, 1998).

The effects of emotion on and high and low confidence recognition responses were also

examined to determine if the effects of emotion were observed for the most confidently

recognized items. High confidence items were those that received a rating of '6' (sure old) whereas low confidence items were those items that received a rating of '5' (unsure old).
For all analyses, EEM effects were interpreted with neutral faces as the baseline, any task effects were interpreted in terms of the effects of direct encoding relative to indirect encoding.
Results

Subjective Ratings ofArousal

Subjective ratings were submitted to a 1-way (Emotion: happy, fearful, angry, neutral)

within-subjects ANOVA. The main effect of emotion, F(3, 54) = 46.33,/? <.001, partial r\2 = .72,
revealed that fearful faces were rated as more arousing than angry faces: repeated contrasts, F(l, 18) = 21.74, ,p < .001, partial n2 = 0.55, angry faces were more arousing than happy faces, F(l,
18) = 6.96, p = ,008,1, partial n2 = 0.34, and happy faces were more arousing than neutral faces,

F(l,18) = 13.54, p = .002, partial r\2 = 0.43 (see Figure 3).

fearful

angry

happy

neutral

Figure 3. Mean subjective arousal ratings for each class of facial emotion expressions. Each emotional expression is significantly different from the next at p < .05 (error bars = standard
error of the mean, SEM).

Recognition Accuracy (Pr)

The effects of emotion on recognition accuracy were examined using a 2 (Encoding task:

indirect, direct) X 2 (Response: remember, know) X 4 (Emotion: happy, fearful, angry, and
neutral) within-subjects ANOVA. There was a main effect of Task, F(l, 35) - 9.85, p = .003,

partial r\2 = .22, revealing participants were more accurate at recognizing faces encoded in the
direct task (M= .24, SD = .06) as compared to the indirect task (M= .19, SD = .07). R responses

(M= .30, SD = .12) were also accompanied by higher accuracy relative to K responses (M- .12,

SD = .11) as indicated by a main effect of Response, F(l, 35) = 24.86,/? < .001, partial rj2= .42.
There was no main effect of Emotion, F(3, 105) = 0.92, p= .432, partial r?= .03, which is
consistent with several

memory accuracy (Dougal & Rotello, 2007; Ochsner, 2000; Sharot et al, 2007; Talarico &

Rubin, 2003). No significant interactions were observed: Task by Response, F(l, 35) - .61,p -

.439, partial n2 = .02; Task by Emotion, F(3,105) = 1.58,/? = .199, partial n2 = .04; and Response
by Emotion, F(3, 105) = 2.15,p = .098, partial rj2 = .06. Likewise, there was no three-way
interaction between Task, Response and Emotion, F(3,105) = .67, p =.572, partial n = .02.
Remember and Know Responses

The effects of emotion on R and K response rates were assessed using a 2 (Encoding

task: direct, indirect) x 2 (Response: remember, know) x 3 (Emotion: happy, fearful, angry) ANOVA on the difference scores for old faces (e.g., RHit for fear minus RHit for neutral). A

main effect of Response, F(l, 35) = 7.80, p = .008, partial rj2 = .18, revealed that emotional faces
selectively increased R responses (M= .08, SD = .13) as compared to K responses (M= -.03, SD

= .15 ). There was no main effect of Task, F (1, 35) = 2.48,/? = .124, partial n2 = .07, and no
main effect of Emotion, F(2, 70) = 0.98,/? = .382, partial n2 = .03. No significant interactions

were observed: Task by Response, F(l, 35) = 0.02,p = .897, partial n2 .01; Task by Emotion,
F(2, 70) = 0.86,/? = .426, partial n2 = 0.02; Emotion by Response, F(2, 70) = 0.61,/? = .548,

partial rf = .02; Task by Response by Emotion, F(2, 70) = 1.26,/? = .289, partial n2 = .04. This
omnibus ANOVA may have been too insensitive to evaluate the specificity of EEM on
remembering across the three emotion types (Rosnow & Rosenthal, 1989). Thus, to assess our a

priori hypothesis that the EEM would be specific to R responses and most pronounced for
fearful faces encoded in the indirect task, focused contrast analyses were carried out using onesample t tests on difference scores. These focused contrasts assessed whether difference scores

were significantly different from zero. Values greater than zero (i.e. positive values) indicated
the emotion was having an enhancing effect on responding.

First, one-sample t tests were calculated on emotional difference scores for R responses.

Fearful faces encoded in the indirect task elicited a greater proportion of R responses relative to

neutral faces encoded in indirect task (Mm = .13, SD = .28), t(35) = 2.75, p = .009, d= 0.46.

This effect was absent for fearful faces encoded in the direct task (Mdiff = .02, SD = .22), t(35) =

0.59, p = .561, d= 0.10. Happy faces encoded in the indirect task also elicited a greater number
of R responses as compared to neutral responses (Mdiff = .07, SD = .22), although this effect was

marginal, t(35) = 1.95, p = .059, d = 0.32. R responses were not significantly increased for happy faces encoded in the direct task (Mdiff = .05, SD =.23), t{35) = 1.37, p = . 179, d = 0.22.
Angry faces encoded in the indirect task also elicited a greater number of R responses as

compared to neutral faces (Mdiff = .10, SD = .25), f(35) = 2.30,^ = .028, d = 0.38, an effect that
was also observed for angry faces encoded in the direct task {Mdiff = .09, SD = .23), ^(35) = 2.40,
p = .022, d= 0.40 (see Figure 4 for a summary of these findings).
One-sample t te

As expected, no effects of emotion were observed on K responding for faces encoded in the

indirect task: happy, f(35) = -0.46,;? = .648, d= -0.10; fearful, f(35) < .0\,p = \.000,d< 0.01; and angry, t(35) = -0.44, p = 0.666, d= -0.07. Similarly, no effects of emotion were observed on
K responding for faces encoded in the direct task: happy, /(35) = -1.60,/? = 0.119, d= -0.27;

fearful, t(35) = -0.25,p =.806, d= -0.04; and angry, t(35) = -1.81,/? = 0.079, d= -0.30 (see
Figure 5 for a summary of these findings).

Although the reporting of difference scores is consistent with previous studies and a
convenient method to display the results (e.g., Sharot et al, 2007), further analyses were

conducted in order to confirm whether the results obtained with difference scores were due to

changes in recognition for emotional faces versus neutral faces. Table 1 reveals that RHits for

neutral faces were higher after encoding in the direct task than after encoding in the indirect task.
Furthermore, the means for the happy and angry faces encoded in the direct task were also higher

compared to indirect encoding; but no such increases were observed for fearful faces encoded in
the direct task. Thus, R responses increased for all faces encoded in the direct task except for

fearful faces, (see Figure 6). In other words, direct encoding of fearful faces seemed to block the
increase in remembering of those faces that was seen for other stimuli under direct conditions.

Given that this crucial information was not captured by the difference scores, the rest of the
analyses were conducted on rates.

Given the problems identified with difference scores, I reanalyzed the data using rates

and assessed a priori hypotheses by submitting hit rates (RHits and KHits) to a series of 2

(Encoding task: indirect, direct) X 2 (Emotion 'emotion', neutral) ANOVAs. To examine the effect of fear on remembering, RHitsfor fearful faces were submitted to a 2 (Encoding task:
indirect, direct) X 2 (Emotion: fearful, neutral) ANOVA. A main effect of Emotion, F(l,35) -

5.86, p = .021, partial r\2 =.14, revealed that RHits were significantly "higher for fearful faces (M=
.35, SD = .15) as compared to neutral faces (M= .27, SD = .16). There was also a marginal Task

by Emotion interaction, F(l, 35) = 3.40,p = .07, partial n2 = .09. Paired-samples t tests revealed
that RHitsWere significantly greater for fearful faces encoded in the indirect task relative to neutral

faces, but that this effect was not present for fearful faces encoded in the direct task (see Table

1). This interaction was further supported by lack of a main effect of Task, F(1, 35) = 1.05,p = .313, partial '7 2
=

.03 In contrast, for happy faces, a main effect Task, F(1, 35) = 5.00, p

=

.033,

Table 1. Comparison of Dependent measures for Reme,mber Responses for Old Stimuli:

Difference Scores and Hit Rates

Mean Hit Rates
Indirect Happy Neutral Fearful Neutral Angry Neutral Direct Happy Neutral Fearful Neutral .37 .31 .34 .31 .31 .23 .36 .23 .33 .23

SD

Mean Difference

SD diff

P

D

.19 .20 .21 .20 .18 .20

.07

.22

.059

.33

.13

.28

.009*

.46

.10

.25

.028*

.38

.25 .19 .22 .19

.05

.23

.179

.22

.02

.22

.561

.10

.022* Angry .40 .40 .23 .09 .23 Neutral .19 .31 * p < .05. Bolded values highlight the change in neutral hit rates at recognition following direct (.31) vs. indirect (.23) encoding that must be taken into account when interpreting the effect of emotion.

25

happy

----neutral

indirect

direct

Figure 6. The mean proportion of Remember hit rates (Rmts) for faces encoded in the indirect
and direct tasks (error bars = SEM).

partial rf = .12, revealed that RHits were higher for faces encoded in the direct task (M= .34, SD
= .19) relative to the indirect task (M= .27, SD = .16). A main effect of Emotion, F(l, 35) =

5.00, p = .033, partial r\2 = .12, revealed that RHits were significantly higher for happy faces (M=

.34, SD = .18) relative to neutral faces (M= .27, SD = .16). However there was no Task by

Emotion interaction, F(l, 35) = .13,p = .722, partial rj2 < .01. Angry faces also showed a main
effect of Task, F(l, 35) = 7.32, p = .010, partial r\2 =.17, where RHite were significantly greater

for faces encoded in the direct task (M= .36, SD = .18) in comparison to the indirect task (M-

.28, SD = .18). A main effect of Emotion, F(l, 35) = 13.66, p = .001, partial rj2 = .28, revealed
R^ were significantly greater for angry faces (M= .37, SD = .16) as compared to neutral faces

(M= .27, SD = .16). However there was no significant Task by Emotion interaction, F(l, 35):

.01,/? = .942,partial?/2 <.01.
Parallel analyses were also conducted on K responses to old stimuli (see Figure 7). KHits
for happy faces were submitted to a 2 (Encoding task: indirect, direct) X Emotion: happy,

neutral) ANOVA and revealed no main effect of Task, F(l, 35) = .56, p = .461, partial r\2 = .02,
no main effect of Emotion, F{\, 35) = 1.84, p = .184, partial r\2 = .05, and no Task by Emotion
interaction, F(l, 35) = .46,p = .501, partial rf = 01. Fearful faces had no effect on Know

responding as revealed by a non-significant main effect of Task, F{\, 35)= 1.48, p = .231, partial

rj2 = .04, no main effect Emotion, F(l, 35) = .02, p = .888, partial t]2 < .01, and no Task by
Emotion interaction, F(l, 35) = .30,p = .864, partial rj2 < .01. Finally, angry faces did not show
any effect on know responding as revealed by a non-significant main effect of Task, F(l, 35) =

.81,/? = .375, partial rj2 = .02, no main effect of Emotion, F{ 1, 35) = 2.36, p = .134, partial tf
= .06, and no Task by Emotion interaction, F(l, 35) = .24, p = .631, partial rf < -01.
A 2 (Response: Remember, Know) X 4 (Emotion: happy, fearful, angry, neutral) within-

subjects ANOVA was conducted to examine false alarms. The ANOVA revealed a highly

reliable main effect of Response, F{\, 35) = 84.39,/? <001, partial rj2 = .71, indicating that
participants made a fewer proportion of RFa (M= .04, SD = .04) than KFa (M= .18, SD = .10).
This finding suggests that participants were in fact using the Remember-Know paradigm

correctly, reserving their remember responses for only highly specific details they could recall. A

main effect of Emotion, F(3, 105) = 4.70,/? = .004, partial n2 = .12, revealed that only fearful
faces (M=.13, SD =.08) were particularly susceptible to false alarms as compared to neutral

faces (M=.\0,SD = .07), F(l, 35) = 6.66,/? = 0.014, partial rj2 = 0.160 (happy: F(l,35) = 0.97,

p = 0.332, partial t]2 = .03; angry: F(l,35) = 0.01,p = .928 , partial rj2 < -01). There was no

significant Response by Emotion interaction, F(3,105) = 0.23, p = .879, partial rf < .01

happy

angry

·neutral

0.2 +indirect direct

Figure 7. The mean proportion of Know hit rates (KHits) for faces encoded in the indirect and
direct tasks (error bars = SEM).

Recollection and Familiarity Estimates

Recollection estimates (derived from formula A) and familiarity estimates were

submitted to a 2 (Encoding task: indirect, direct) x 2 (Response: recollection, familiarity) x 4

(Emotion: happy, fearful, angry, neutral) within-subjects ANOVA. A main effect of Task,

F(l,35) = 11.27,p = .002, partial tf = -24, revealed increased recognition for faces encoded in
direct task (M= .33, SD = .03) as compared to the indirect task (M= .27, SD = .03). There was

no main effect of Response, F(l, 35) = 0.20, p = .654, partial r? = .01, and no main effect of
Emotion, F(3, 105) = 1.56, p = .203 , tf = .04. No significant interactions were observed: Task

by Response, F(l, 35) = 0.42,/? =.520, partial >/2 = .01; Task by Emotion F(3,105)=1.76,p-

.159, partial rj2 =.05; and Response by Emotion, F(l, 35) = 0.65,/? = .587, rj2 = .02. Likewise,
there was no three-way interaction between Encoding task, Response, and Emotion, F(3,105) =-

0.21, p =.888, partial rj2 =.01.
Planned contrasts to address our a priori hypotheses were conducted using 2 (Encoding task: indirect, direct) X 2 (Emotion: 'emotion', neutral) ANOVAs on estimates of recollection
and familiarity. The ANOVA on recollection for fearful faces revealed a marginally significant

interaction, F(l, 35) = 3.59,/? = .067, partial r\2 =.09. Paired t tests revealed that recollection was

significantly enhanced for fearful faces encoded in the indirect task (M= .32, SD =.21) relative
to neutral faces (M = .22, SD = .18), t(35) = 2.U,p = .042, d = 0.35, whereas this effect was

absent in the direct task condition (fearful: M=.29, SD = .23; neutral: M= .29, SD = .18), t(35) =

-0.12, p = .906, d = -0.02. There was no main effect of Task, F(l, 35) = .98,/? = .330, partial r\2
=.03 and no main effect of Emotion F(l, 35) = 1.94,/? = .173, partial r\2 =.05. For happy faces, a
main effect of Task, F(l, 35) = 5.10, p = .030, partial tj2 =.13, revealed greater recollection for
faces encoded in the direct task (M=.32, SD = .17) relative to the indirect task (M= .25, SD -

.14). A main effect of Emotion, F(l, 35) = 6.27,/? = .017, partial rj2 =.15, revealed recollection
was significantly enhanced for happy faces (M= .32, SD = .16) relative to neutral faces (M= .26,

SD =.14). There was no Task by Emotion interaction, F(l, 35) = .12,/? = .695, partial rj2 < .01.
Angry faces also showed a main effect of Task, F(l, 35) = 7.81,/? = .008, partial r\2 =.18,
revealing recollection was greater for faces encoded in the direct task (M= .34, SD = .16) relative to the indirect task (M= .26, SD = .14). A main effect of Emotion, F(l, 35) = 11.23,/?

.002, partial r\2 =.24, revealed recollection was significantly enhanced for angry faces (M= .34, SD = .16) relative to neutral faces (M=.26, SD = .13). There was no Task by Emotion

interaction, F(\, 35) = .01,p = .940, partial r\2 < .01. Overall these results are consistent with the
focused contrast analyses conducted on R responses. As expected, both recollection formulae A
and B yielded almost identical results (data not shown).

Parallel analyses were also conducted on estimates of familiarity. Familiarity estimates

for fearful faces showed a marginal main effect of Task, F(l, 35) = 2.89, p = .098, partial rj2 =
.08 (indirect: M= .25, SD =.16; direct: M= .31, SD - .14), no main effect of Emotion F{\, 35) = .03,/? = .874, partial t]2 < .01, and no Task by Emotion interaction, F(l,35) = .88,p -

.355, partial rj2 = .02.For the happy 2X2 ANOVA, a main effect of Task, F(\, 35) = 4A5,p -

.049, partial rj2 = .11, revealed greater familiarity for faces encoded in the direct task (M= .32,

SD = .17) relative to the indirect task (M= .26, SD = .20). There was no main effect of Emotion,
F(l, 35) = .12,/? = .735, partial tf < .01 and no Task by Emotion interaction, F(\, 35) = .52,/? =

.477, partial r;2 = .02. For the angry ANOVA, a main effect of Task, F(l, 35) = 8.12,/? = .007,

partial rf = .198, revealed greater familiarity for faces encoded in the direct task (M= .34, SD =

.13) relative to the indirect task (M= .25, SD = .20). There was no main effect of Emotion, F(l, 35) = .40,/? = .531, partial r\2 = .01, and no Task by Emotion interaction, F(l, 35) = .01,/? = .92,

partial rj2 < .01. In contrast to the pattern for KHits, familiarity estimates generally yielded a Task
effect that revealed a greater sense of familiarity for all faces encoded in the direct task relative
to the indirect task. Interestingly, this effect was observed for all faces except for fearful faces.

Similar to the pattern of K responses, emotional faces showed no effect on familiarity relative to
neutral faces, demonstrating the enhancing effects of emotion on memory are specific to
recollection.

Confidence Ratings

An examination of whether EEM effects were restricted to faces recognized with high
confidence was undertaken using a 2 Encoding task (indirect and direct) X 2 Confidence

response ('6' sure old, '5' unsure old) X 4 Emotion (happy, fearful, angry, neutral) within-

subjects ANOVA for old faces. A main effect of Task, F(l, 35) = 8.49, p =.006, partial n2 = .20,
revealed a greater proportion of faces encoded in the direct task (M= .32, SD = .06) correctly

received an 'old' rating relative to the indirect task (M= .28, SD = .07). A main effect of
Confidence, F(l, 35) = 66.34, p <.001, partial n2 = .66, revealed a greater proportion of old faces received a high confidence 'old' rating (M= .44, SD =.13) relative to the proportion receiving a
low confidence rating (M= .17, SD = .09). That is, the majority of recognition hits were

accompanied by a high level of confidence. There was a significant Task by Emotion interaction,

F(3, 105) = 5.97,p = .001, partial n2 =.15, and a marginal three-way interaction between Task,

Response, and Emotion, F(3,105) = 2.23, p = .085, partial n2 = .06. Follow-up paired t tests
revealed no EEM effect within high and low confidence responses for faces encoded in the

indirect task (see Figure 8a). For faces encoded in the direct task, the proportion of angry faces
associated with a high confidence recognition response was greater relative to neutral faces,

whereas this effect was not observed for low confidence items (see Figure 8b). Visual comparison of Figures 8a and b reveals an interesting pattern of results that may also be driving
the three-way interaction. Negative emotions encoded in the indirect task received a lower

proportion of correct old confidence ratings, whereas both fearful and angry faces received a higher proportion of correct old confidence ratings in the direct task. This pattern was especially
pronounced for faces rated as highly confident.. There was no main effect of Emotion, F(3,105) = 1.42, p = .248, partial n2 = .04, no Task by Confidence response interaction, F(l, 35) = 1.42,

A 2 (Confidence: '6' sure old, '5' unsure old) X 4 Emotion (happy, fearful, angry,

neutral) within-subjects ANOVA was conducted for new faces (i.e., false alarms). A main effect

of Emotion, F(l, 35) = 2.80,/? = .044, partial rf =.07, revealed that fearful faces (M= .22, SD .15) elicited a greater proportion of 'old' confidence responses overall as compared to happy

faces (M= .16, SD = .15), t(35) = -2.81,p = .008, </= 0.47, and angry faces (M= .17, SD =15), f(35) = 2.02, p = .052 (marginal), J = 0.34. A priori testing revealed that the proportion of fearful
faces receiving a high confidence response was significantly greater than that of neutral faces
whereas this effect was not observed for low confidence items (see Figure 9).

9

0.14

< 0.12
 happy

 angry

^ neutral

High'Old'

Low'Old'

Confidence Rating

Figure 9. The proportion of new stimuli receiving either a high or low 'old' confidence rating
(*p < .05., error bars = SEM).

Discussion

This thesis showed that explicit processing of happy, angry, and neutral, but not fearful
facial expressions at encoding, unexpectedly increased recollection relative to implicit

processing. In addition, implicit processing of fearful faces enhanced participants' subjective

sense of recollection relative to neutral faces, whereas explicit processing did not. These findings
suggest that implicit and explicit processing of emotional information have different effects on

memory and that fearful stimuli, in particular, play a unique role in shaping these effects.
Increases in Recollection for Faces Encoded in the Direct Task

One of the most striking patterns in our data was the increase in recollection for faces

encoded in the direct task. Higher levels of familiarity, accuracy, and confidence were also

associated with these faces. Critically, this effect extended to neutral faces, which suggests that a non-emotion specific mechanism likely accounts for this unexpected finding. One such mechanism may relate to the levels of processing (LOP) theory proposed by Craik & Lockhart
(1972). The LOP theory contends that various levels of semantic processing at encoding can

have profound effects on memory retention. Studies revealed that deep encoding of words (e.g.,

asking whether a word fits in a particular category, e.g, "Is the word the name of an animal?") in
contrast to shallow encoding (e.g., examining the perceptual characteristic of the word, e.g., "Is the word in capital letters?") resulted in higher levels of memory performance (see Craik &

Tulving, 1975). The LOP effect has been consistently replicated and has also extended to various
memory paradigms assessing recollection and familiarity (e.g., remember/know, process-

dissociation, and receiver operating characteristic curve, ROC, procedures). These studies have
shown that deep encoding leads to a large increase in recollection and a smaller but very

consistent increase in familiarity (see Yonelinas 2002 for a review). LOP may account for the increases in performance associated with the direct encoding condition. That is, the emotional

discrimination task may have facilitated a deeper form of processing than the gender
discrimination task. Explicit focus on emotional expressions is likely to have led participants to

extract information about the portrayed individual's internal emotional state, their intentions, or

reactions to events in the immediate environment (Whalen et ai, 2009). It seems plausible that processing such aspects may reflect a deeper level of processing than the judgments made in the
gender discrimination task. While this assertion remains to be empirically tested, it is offered as
an interesting and plausible explanation for the observed increases in recognition performance
associated with the direct task.

Another possibility underlying the increases in recollection for directly encoded happy, angry, and neutral faces relates to transfer appropriate processing (TAP; Roediger & Blaxton,

1987). The TAP model proposes that memory performance benefits from the extent to which
processes at test overlap with those engendered by the encoding condition. The explicit processes

underlying R responses reflect that participants were experiencing conscious recollection of
details associated with the events of studying specific faces at encoding. To the extent that these
details involved processing of the emotional content of the faces, corresponding R responses may

more closely resemble the explicit emotional nature of the direct encoding task (i.e. participants

were required to make judgments about emotion type). Future exploration of a TAP hypothesis would be aided by an implicit test of recognition that similarly maps on to the implicit processing
of emotion tapped by the indirect task.
EEM Effects

In addition to the increase in recollection associated with direct encoding, angry and

relative to neutral faces. These findings are supported by studies demonstrating that the

amygdala is responsive to most facial emotions (Fitzgerald et al, 2006; Somerville et a/., 2004;

Yang, 2002). Notable, however, is the specific pattern of EEM findings for faces encoded in the

indirect task, where fearful faces exhibited the strongest EEM effect, followed by angry and
happy faces. This same pattern of results was also observed with the subjective ratings, where

participants rated fearful faces as the most arousing, followed by angry and happy expressions.
These parallel sets of findings are consistent with studies assessing human amygdala responses

to all expressions, which provide evidence that the amygdala is most sensitive to fearful faces.

For example, Fitzgerald et al. (2006) observed that the degree and spatial extent of amygdala
activation tended to be greater for fearful faces than angry, happy, neutral, and other

expressions. In addition, studies directly contrasting fearful faces against the other expressions have shown significantly greater amygdala activity to fearful faces than to angry faces (Whalen
et al., 2001) and happy faces (Morris et al., 1996).

Interestingly, fearful faces exhibited a unique profile reflecting differential effects of task on expression of the EEM. Further exploration revealed that implicit processing of fearful faces

enhanced recollection, whereas this effect was not observed for fearful faces processed under explicit conditions. More specifically, the analysis demonstrated that, unlike the other emotions,
explicit processing of fearful faces was not accompanied by an increase in recollection of those
faces. Several possibilities that may account for these findings are discussed.
The Fear Factor: What's Happening?

An examination of Figure 6a revealed there was a slight decreasing trend in RHits for

fearful faces encoded under direct vs. indirect conditions. As hypothesized, this trend may be
associated with reduced amygdala-arousal activity known to occur during explicit processing.

amygdala activation at encoding is related to subsequent memory for emotional items
(Kensinger & Schacter, 2006) and "remember" judgments for those items (Dolcos, LaBar,

Cabeza, 2004). This interpretation, however, begs the question as to why angry and happy faces
were not susceptible to our task manipulation in the same manner as fearful faces. Consistent

with the pattern of EEM results during implicit processing, the subjective ratings, and with

evidence from the imaging literature, fear may have exceeded a threshold of amygdala-arousal
activity that was differentially sensitive to the effects of our tasks (a "threshold model").

However without the presence of direct fMRI observation, it is not possible to confirm this hypothesis. Furthermore, while the vast majority of brain imaging studies report attenuated
amygdala activity during explicit processing, there are exceptions (e.g., Habel et al, 2007).

Nonetheless, on the basis of the literature, I propose that the lack of an increase in recollection

associated with fearful faces encoded under explicit conditions is associated with attenuated
amygdala-arousal activity.

I further consider an intriguing possibility whereby EEM-related decreases in recollection

for fearful faces encoded in direct task are being masked by LOP effects. In other words, not

taking the LOP effect into account, I predicted a significant decrease in recollection for fearful
faces encoded during the direct task. However in the presence of the LOP effect, and its
associated increases in recollection, any decreases in recollection due to explicit processing may

have been disguised. The unique profile associated with fearful faces may therefore reflect the
presence of two factors: An intact LOP effect, where direct encoding yielded increases in
recollection, and an LOP-independent effect, characterized by the EEM effect for fearful faces
encoded in the indirect task and a diminished EEM effect under direct encoding conditions (see
Figure 10).

-Fear EEM effect

-Neutral: EEM effect

-Fear: EEM + LOP effects

-Neutral: EEM + LOP
effects

indirect

direct

Figure 10. Depiction of possible decreases in R responses for fearful faces being masked by
LOP-related increases in R responses for both fearful and neutral faces encoded in the direct
condition.

One final possibility I consider is that some qualitative difference unique to fearful versus

other emotional expresssions may account for the observed pattern of results. In other words,
processi

effect (i.e., LOP-related processes). More specifically, there is reason to believe that indirect

encoding of fearful faces was not susceptible to the effects of shallow processing of emotional
information. Instead, a deeper form of processing may have taken place because in contrast to

other emotions, the detection of fear-related information is highly automatic. The processing of

threat-related information, such as facial expressions of fear, is thought to be mediated by preattentive mechanisms that do not involve consciously controlled processes (Christianson, 1992).

This notion is supported by studies that have manipulated subjective awareness. Using various
techniques such as backward masking and binocular suppression, these studies have

demonstrated the amygdala reliably responds to the presentation of fearful facial expressions that

are outside conscious awareness (Morris et al, 1998,1999; Whalen et al., 1998; Williams et al,
2004). These findings have even extended to specific facial features such as fearful eye whites.
Whalen and colleagues (2004) showed that backward masking of fearful eye whites, in contrast

to other eye conditions (e.g., happy eye whites) produced circumscribed activation in the ventral

regions of the amygdala. Taken together, these results suggest that the processing of fear-related information relies upon a high degree of "automaticity". That is, I hypothesize that this type of
specialized processing facilitated a deeper form of processing under indirect encoding conditions
as compared to the other emotions. Moreover, the absence or inhibition of such automated processing under more explicit conditions may underlie the lack of increase in recollection observed in the direct encoding task. In evolutionary terms, further increases in recollection may
not be necessary when conscious evaluation of threatening information is undertaken (e.g.,

assessing source of threat, degree of potential harm). Whereas under conditions of reduced
stimulus analysis, recollection is high, ensuring that potentially significant events are not
forgotten.

Enhanced Recollection versus Accuracy and Response Bias

Our analyses also revealed that emotional faces selectively enhanced the subjective sense

of recollection relative to neutral faces; however this "boost" was not associated with enhanced
overall memory accuracy. The recollective boost that accompanies highly vivid, emotional

memories has generally been assumed to be associated with greater accuracy. However this

assumption has been challenged. A study by Talarico and Rubin (2003), for example, examined
accuracy of flashbulb memories, extremely vivid, emotional-laden, unexpected events such as

the terrorist attacks of September 11,2001. Overall accuracy for the flashbulb memory did not differ from the accuracy for everyday events, in both cases declining with the passage of time. However, ratings of recollection and belief in accuracy remained heightened for the flashbulb
memory, while those for everyday memories decreased over time. This dissociation between

objective accuracy and the subjective recollective boost and for emotional information is further
supported by studies examining memory for stimuli learned in the laboratory. Sharot and
Yonelinas (2008) manipulated the encoding contexts in which emotional and neutral photos were

presented to participants, and later asked them to provide remember/know judgments after a

delay. While they found emotion enhanced an individual's recollective experience as revealed by
a boost in "remember" judgments for emotional photos, participants were no better at recalling
the type of task that was performed during the encoding of the emotional photos relative to

neutral photos. Additional studies have also documented the dissociation between the enhanced
subjective sense of recollection and accuracy using emotional words (e.g., Dougal & Rotello,

2007; Kapucu, Rotello, Ready, & Seidl, 2008). Our findings extend this growing body of
evidence to the recognition of emotional faces.

Studies have begun to unravel the factors contributing to the enhanced subjective sense of recollection. Recent ROC modeling studies (e.g., Dougal & Rotello, 2007; Kapucu et al., 2008)
have demonstrated that recognition of emotional information is associated with a more liberal

response bias, revealing participants are more willing to accept having previously experienced an

emotional event even if it did not occur. Indeed our findings revealed that participants showed

greater false alarm rates to fearful faces as compared to neutral faces, which is consistent with other studies that reported increased false alarm rates for emotional events (e.g., Sharot et ah,
2004). While examining response bias was considered in the current study, the differential EEM
effects observed for fearful faces that had been encoded in the indirect vs. direct conditions in

our study cannot solely be explained by changes in bias. New items in our study represented
photos of unstudied individuals expressing the same four emotions at study. Thus, because new

items at recognition were not distinguishable by task conditions, there was no way for

participants to employ differential task-related response criteria at test (personal communication
with Benjamin, A., June, 2009). One possible future direction may be to directly test the influence of response bias when presented with differential encoding conditions. Transforming

our design to a between-subjects design or using emotional stimuli that allow us to create false
alarms that are identifiable by task would allow us more readily to assess response bias effects.
Confidence Ratings

Noteworthy is the pattern of confidence ratings that appeared to contradict the main

finding of EEM for fearful faces in the indirect, but not direct, task. Although a non-significant

trend, a greater proportion of negative faces encoded in the direct task was associated with highe:

confidence relative to neutral faces, and the opposite pattern was found for negative faces in the
indirect task. This pattern of confidence ratings appear discrepant with the finding that R
;sponses

are not always accompanied by the highest levels of confidence. Indeed modeling studies have

shown that participants use a range of confidence levels to report "remembering" (Dougal &

Rotello, 2007). Participants were also explicitly told that R and K responses can be accompanied
by equal levels of recognition confidence (Appendix A), allowing participants to use the entire

confidence range when providing an R response.
Limitations and Future Directions

There are several limitations in the current study. The encoding tasks were designed to

reflect differential engagement of the amygdala and physiological arousal. As mentioned earlier, brain imaging will be needed to confirm that our indirect task, designed to elicit implicit
emotional processing, is associated with significantly greater amygdala activity relative to

explicit processing. In order to confirm the pattern of arousal activity across both encoding tasks, measurements of SCR can also be recorded simultaneously during brain imaging. Similar

to the results of the subjective ratings, it is predicted that fearful faces under indirect encoding

conditions, in particular, will elicit the greatest change in SCR and amygdala activation relative
to the other emotions. Such within-subject measurements of arousal will also afford the
opportunity to assess correlations between arousal and the EEM.

Also noteworthy is that whereas the vast majority of studies have reported relative
decreases in amygdala activation during explicit processing, there is at least one known

exception. Habel et al. (2007) found significantly greater bilateral amygdala activation during an

explicit task (emotion discrimination) as compared to an implicit task (age discrimination). Thus,

the possibility that the observed increases in recollection for directly encoded faces may be due
to greater amygdala-arousal activity during explicit processing cannot be ruled out. However, our

findings would not support this hypothesis, as one would have predicted the largest increase in
recollection to occur for fearful faces encoded in the direct task. Moreover, Habel et a/.'s (2007)

findings are difficult to interpret in light of unequal task demands. Participants' accuracy for the
implicit age-discrimination task was significantly lower than the explicit emotion-discrimination
task. The authors suggest that the increased difficulty of their implicit task may have

inadvertently elicited greater cortical prefrontal areas leading to less amygdala activation due to

inhibitory effects. Previous studies comparing performance accuracy between gender and
emotion discrimination tasks such as the ones used in the current study have found no

differences in accuracy between tasks (e.g., Critchley et al, 2000). Participants in our study also
reported no difficulties in performing either of the tasks A future route of investigation includes

assessing differences in task performance using measures of accuracy and reaction time. While
no difference in accuracy between tasks is expected, it is predicted that direct encoding will be
associated with longer reaction times, reflecting a deeper form of processing relative to indirect
encoding.

Another limitation includes the possibility of task carry-over effects on our EEM

findings. The indirect task was placed before the direct task to avoid the possibility of explicit emotional processing carrying over from the direct to indirect task. However it is possible that
carry-over effects from the gender discrimination task influenced the emotion-discrimination

task in ways that may have affected our findings. In addition to such carry-over effects, the
temporal ordering of the tasks may have also resulted in different consolidation periods (longer

consolidation time for faces encoded in the indirect task) and susceptibility to proactive and retroactive interference. Counterbalancing the task order across participants or employing a
between-subject design are
ssibilityofany

task-ordering effects on our results.

The majority of our participants were female, which reflected the disproportionate

amount of females enrolled in 1st year Psychology courses at Ryerson University. There is
evidence to suggest that females are superior to males in facial emotion processing (e.g., faster

reaction times for accurately identified facial emotions, Rahman, Wilsons, & Abrahams, 2004);

however, it is unknown how such differences may affect the EEM. Future studies may be aimed
at investigating the role of possible sex differences in our findings.

Lastly, while recollection and familiarity estimates were used to assess the memory

processes underlying Remember and Know judgments, ROC curves are also commonly used for

assessing recollection and familiarity. These curves are generated by plotting hit rates against
false alarm rates, and are useful for delineating the effects on accuracy and response bias

(Dougal & Rotello, 2007). However one critical limitation of the ROC method is that in order to derive stable ROCs it is necessary to collect a large number of responses from each subject.

ROCs based on less than 60 items per subject/condition (i.e. 60 new items plus 60 old items from

each study condition) have been found to yield poorly behaved ROCs that are noisy and
irregularly shaped (Yonelinas & Parks, 2007). In order to generate stable ROCs in the current

study, a total of 240 unique faces would be needed. As mentioned earlier, the facial emotion databases currently available present a significant challenge to obtaining such a high stimulus
number. Clinical Implications

While future studies are needed to elucidate the mechanisms underlying the effects

implicit and explicit processing on the EEM, implications for cognitive rehabilitation arising

from this work are particularly important. A crucial aspect of Robertson and Mure's (1999)

model of rehabilitation specifies that the target process of rehabilitation, in this case memory, be
precisely and repeatedly activated by either bottom-up (stimulus oriented) or top-down

(attention-related) techniques. If the target process, subserved by a damaged neural network, is
repeatedly activated by means of these techniques, then the model proposes reinstatement of

connectivity can occur (Bornhofen & McDonald, 2008). Neuroimaging evidence supports the

notion that implicit and explicit processing of emotional information map on to bottom-up and
top-down processes respectively, as the former elicits greater subcortical involvement while the
latter is associated with greater frontal involvement. In certain cases, one type of processing may

be preferable over another. For example, based on the findings from the current study, I would
predict that implicit-based techniques (practice orientation to cues such as eyes and mouth in the

facial expression) applied to fearful faces would lead to greater memory relative to explicit-based
technique (i.e. enhanced attention towards making emotional judgements) If such enhancement

is found to be associated with greater amygdala-arousal activity relative to explicit processing,

this would suggest cognitive recovery may be better stimulated under indirect emotional
processing conditions that allow for maximal activation of networks.
Conclusion

This thesis demonstrates that implicit processing of emotional facial expressions via
gender judgments enhanced participants' subjective sense of recollection for fearful faces,

whereas explicit processing via emotion discrimination judgments blocked increases in

recollection. In contrast to facial expressions of fear, happy, angry, and neutral facial emotion
expressions were associated with increases in recollection following explicit processing. These

findings lend themselves to the possibility of several interpretations, all of which await future

testing. In addition to specifying the effects of implicit and explicit processing on memory for
emotional information, a better understanding of their underlying mechanisms will have
important rehabilitative implications for clinical populations that suffer from memory
impairment.

Appendix A

Remember-Know Computerized Instructions:

Slide 1: In the first part of this experiment, you saw a series of faces. This was called the "study phase". You will now be shown all the faces you saw in the study phase along with new faces. You will be asked which faces are new and which ones you recognize from the study phaseSlide 2: There are different kinds of recognition. For instance, recognition can bring back to mind something you recollect about what it is that you recognize. For example, you might
recognize someone's face and REMEMBER thinking that person had similar eyes to yours.

At other times, recognition brings nothing back to mind about what it is you recognize. As when, for example, you are confident that you recognize someone, and you KNOW you recognize them, because of strong feelings of familiarity - but you have no recollection of seeing this
person before. You do not recall anything specific about them.

these now and then we will practice a few examples together to confirm that the instructions are
clear.

Slide 3: The purpose of this part of the experiment is to look at how these different types of recognition apply to the faces that you saw earlier today in the study phase. I will briefly describe

Sometimes when you recognize a face as one you saw in the study phase, recognition will bring back to mind something you REMEMBER thinking about when the face appeared then. You
recollect something you consciously experienced at that time.

Other times recognizing a face as one you saw in the study phase will not bring back to mind anything specific you remember about seeing it then. Instead, the face will seem familiar, so that you feel confident and KNOW that it was one you saw in the study phase, even though you do
not recollect anything you experienced when you saw it then

Slide 4: You will be asked to indicate whether the face being shown to you is:
"NEW" (you did not see it in the study phase)

"REMEMBER"(you saw it in the study phase and remember something specific about it from
when you saw it)

"KNOW"(you saw it in the study phase but you cannot remember any specific details)

Slide 5: So just to recap, you will answer "NEW" if you did not see the face in the study phase.
You will answer "REMEMBER" if recognition is accompanied by some specific or vivid
recollective experience.

OR you will answer "KNOW" if you recognize a face with strong feelings of familiarity, but
without any specific recollective experience.

Slide 6: After you make your selection of either "NEW", "REMEMBER" or "KNOW", you will be asked to rate how confident you are in your response. Let's practice... [proceed to verbal
instructions]

Supplementary Oral Instructions to Computerized Instructions:

This can be a tricky task to keep straight because of all the types of responses. So although you've just read the instructions, I'm going to now go over them with you again and show how
things will look on the computer.

You will see the faces one at a time. If you do not recognize the face as previously being in the "study phase" then you press N for "New". If you recognize a face, we would like to know how well you remember it. If it triggers something that you experienced when you saw it previously, like, for example, something about its appearance on the screen or the order in which the face came in, then I would like you to indicate this kind of recognition by pressing R for Remember.

In other'instances the face may remind you of something you thought about when you saw it

previously, like it reminded you of a friend or family member, or an image that you formed when
you saw the face, or something of personal significance that you associated with the face. Again, if you can recollect any of these aspects of when the face was presented, then I would like you to
press R for Remember.

Do you have any questions about Remember responses? Can you give me an example of
something that you remember? (confirm or clarify understanding as necessary)

At other times you will see a face and you will recognize it as one that you saw in the study phase, but the face will not bring back to mind anything you remember about seeing it then, the face will just seem extremely familiar. When you feel confident that you saw the face, even
though you do not recollect anything you experienced when you saw it, I would like you to
indicate this kind of recognition, by pressing K for Know. With know responses you are sure

about seeing the face in the study phase but cannot remember the circumstances in which the face was presented, or the thoughts elicited when the word was presented. Do you have any
questions about Know responses?

Following your selection of either "New", "Remember", or "Know" you will be asked how confident you were in your response. If you are confident that have seen the face, then we would like to know how sure you are by pressing 1 for "Sure", 2 for "Unsure" and 3 for "Guessing".
you are by pressing "S" for Sure, U for "Unsure" and G for "Guessing". Do you have any
Q's? Let's practice...

It might be helpful to know that all of the faces that you saw in the study phase will be presented to you at some point. I'll stay here for the first while and you can ask me if you have any Qs as you go along, but then I might slip out for a bit. This last part will take about 15-20 minutes and
is at your own pace. Whenever you're ready, press the spacebar to begin...

References

Adolphs, R., Cahill, L., Schul, R., & Babinsky, R. (1997). Impaired declarative memory
for emotional material following bilateral amygdala damage in humans. Learning
andMemory, 4, 291-300.

Aggleton J. P., ed. 2000. The Amygdala. London: Oxford Univ. Press, pp. 690.

Anderson, A. K., Yamaguchi, Y., Grabski, W., & Lacka, D. (2006). Emotional memories
are not all created equal: Evidence for selective memory enhancement. Learning
andMemory, 73,711-718.

Blair, R. J. S., Morris, J. S., Frith, C. D., Perrett, D. L., & Dolan, R. J. (1999). Dissociable neural
responses to facial expressions of sadness and anger. Brain, 122, 883-893.

Bowers, D., Blonder, L., X., & Heilman, K., M., (1989). The Flordia Affect battery, Revised.
Gainsville, FL: The Center for Neuropsychological Studies, University of Florida.

Cacioppo, J. T., Bush, L. K., & Tassinary, L. G. (1992). Microexpressive facial actions
as a function of affective stimuli: Replication and extension. Perspectives

from Psychology and Sociology Bulletin, 18, 515-526.

Cahill L. (2000). Modulation of long-term memory in humans by emotional arousal:
adrenergic activation and the amygdala. See Aggleton, 2000, pp. 425-46.

Christianson, S. (Ed). (1992). The handbook ofemotion and memory: Research and theory.
Hillsdale, New Jersey: Lawrence Erlbaum Associates.

Corteen, R. S. (1969). Skin conductance changes and word recall. British Journal of
Psychology, 60, 81-84.

Craik, F. I. M. & Lockhart, R. (1972). Levels of processing: A framework for memory research.
Journal of Verbal Learning & Verbal Behavior, 77,671-684.

Craik, F. I. M. & Tulving, E. (1975). Depth of processing and the retention of words in episodic
memory. Journal ofExperimental Psychology: General, 104(3), 268-294.

Critchley, H., Daly, E., Phillips, M., Brammer, M., Bullmore, E., Williams, S.,

Van Amelsvoort, T., Robertson, D., David, A., & Murphy, D. (2000). Explicit and

implicit neural mechanisms for processing of social information from facial
expressions: A functional magnetic resonance imaging study. Human Brain
Mapping, 9, 93-105.

Critchley, H., Mathias, C. J., & Dolan, R. J. (2002). Fear conditioning in humans: The influence
of awareness and autonomic arousal on functional neuroanatomy. Neuron, 33, 653-663.
Dawson, M. E., Schell, A. M., & Filion, D. L. (2000). The electrodermal system. In J. T.
Cacioppo, L. G. Tassinary, & G. G. Berntson (Eds.), Handbook ofpsychophysiology
(2nd ed, pp. 200-223). New York: Cambridge University Press.

Dolcos, F., LaBar, K. S., & Cabeza, R. (2004). Interaction between the amygdala and the medial
temporal lobe memory system predicts better memory for emotional events. Neuron, 42,
855-863.

Dougal, S., & Rotello, C. M. (2007). "Remembering" emotional words is based on response bias, not recollection. Psychonomic Bulletin & Review, 14(3), 423-429.

Ekman, P., & Friesen, W. (1976). Pictures offacial affect. Palo Alto, CA: Consulting
Psychologists Press.

Fitzgerald, D. A., Angstadt, M., Jelsone, L. M, Nathan, P. J., & Phan, K. L. (2006). Beyond
threat: Amygdala reactivity across multiple expressions of facial affect. Neuroimage,
30(4), 1441-1448.

Furmack, T., Fischer, H., Wik, G., Larsson, M., & Fredrikson, M. (1997). The amygdala and
individual differences in human fear conditioning. Neuroreport, 8, 3957-3960.
Glascher, J., Tiischer, O., Weiller, C, & Btichel, C. (2004). Elevated responses to

constant facial emotions in different faces in the human amygdala: an fMRI study
of facial identity and expression. BMC Neuroscience, 5(45).

Habel, U., Windischberger C, Derntl, B., Robinson, S., Kryspin-Exner, I., Gur. R. C, & Moser,

E. (2007). Amygdala activation and facial expressions: Explicit emotion discrimination

versus implicit emotion processing. Neuropsychologia, 45, 2369-2377.

Hamann, S. B., Ely T. D., Hoffman J. M., & Kilts, C. D. (2002). Ecstasy and agony:
Activation of the human amygdala in positive and negative emotion.
Psychological Science, 13(2), 135-141.

Hariri, A. R., Bookheimer, S. Y., & Mazziotta, J. C. (2000). Modulation emotional
responses: Effects of a neocortical network on the limbic system. Neuroreport,
77(17), 43-48.

Hsu, S. M., & Pessoa, L. (2007). Dissociable effects of bottom-up and top-down factors
in the processing of unattended fearful faces. Neuropsychologia, ¥5(13), 3075

Introini-Collison, I, Saghafi, D, Novack, G. & McGaugh, J.L. (1992). Memory-enhancing

effects of posttraining dipivefrin and epinephrine: Involvement of peripheral and central
adrenergic receptors. Brain Research, 572, 81-86.

Kapler, E. S., Hariri, A. R., Mattay, V. S., McClure, R. K., & Weinberger, D. R. (2001).
Correlated attenuation of amygdala and autonomic responses: A simultaneous fMRI and SCR study. Society for Neuroscience Abstracts, 645. 3.

Kapucu, A., Rotello, C. M., Ready, R. E., & Seidl, K. N. (2008). Response bias in
'remembering' emotional stimuli: A new perspective on age differences. Journal of
Experimental Psychology: Learning, Memory, & Cognition, 34, 703-711.

Keightley, M. L., Winocur, G., Graham, S. J., Mayberg, H. S., Hevenor, S., & Grady, C. L.

(2003). An fMRI study investigating cognitive modulation of brain regions associated
with emotional processing of visual stimuli. Neuropsychologia, 41, 585-596.

Kensinger, E. A., & Corkin, S. (2004). Two routes to emotional memory: Distinct

neural processes for valence and arousal. Proceedings ofthe National Academy of
Sciences, 707,3310-3315.

Kensinger E. A. & Schacter, D. L. (2006). Amygdala activity is associated with the successful

encoding of item, but not source, information for positive and negative stimuli. Journal of
Neuroscience, 26, 2564-2570.

Kleinsmith, L. J., & Kaplan, S. (1963). Paired-associate learning as a function of arousal
and interpolated interval. Journal ofExperimental Psychology, 65, 190-193. LaBar, C, & Cabeza, R. (2006) Cognitive neuroscience of emotional memory. Nature
Reviews Neuroscience 7, 54-64.

LaBar, K. S., & Phelps, E. A. (1998). Arousal-mediated memory consolidation:
Role of the medial temporal lobe in humans. Psychological Science, 9,
490-493

Lange, K., Williams, L. M., Young, A. W., Bullmore, E. T., Brammer, M. J., Williams, S. C. et
al. (2003). Task instructions modulate neural responses to fearful facial expressions.
Biological Psychiatry, 53,226-232.

Lang, P.J., Bradley, M.M., & Cuthbert, B.N. (2008). International affective picture system

(IAPS): Affective ratings of pictures and instruction manual. Technical Report A-8.
University of Florida, Gainesville, FL.

Lang, P. J., Greenwald, M. K., Bradley, M. M. & Hamm, A. O. (1993). Looking at
pictures: Affective, facial, visceral, and behavioural reactions. Psychophysiology,
30, 261-273.

Lang, P. J., Greenwald, M., Bradley, M. M., & Hamm, A. O. (1993). Looking at pictures: Evaluative, facial, visceral, and behavioral responses. Psychophysiology, 30, 261-273.

Liang, K. C, Juler, R. G., & McGaugh, J. L. (1986). Modulating effects of posttraining
epinephrine on memory: Involvement of the amygdala noradrenergic system. Brain
Research, 368(1), 125-133.

Levonian, E. (1967). Retention of information in relation to arousal during continuouslypresented material. American Educational Research Journal, 4, 103-116.

Lundqvist, D., Flykt, A., & Ohman, A. (1998). The Karolinska Directed Emotional Faces--

KDEF [CD-ROM]. Department of Clinical Neuroscience, Psychology section,
Karolinska Instituted Stockholm, Sweden.

Martinez, A. M, & Benavente, R. (1998). The AR Face Database. CVC Technical Report #24.
McGaugh, J. L., Cahill, L., & Roozendal, B. (1996). Involvement of the amygdala in
memory storage: Interaction with other brain systems. Proceedings ofthe
National Academy ofSciences ofthe United States ofAmerica, 93,13508-13514.

McGaugh, J.L. (2004). The amygdala modulates the consolidation of memories of
emotionally arousing experiences. Annual Review ofNeuroscience, 27, 1-28.

Morris, J. S., Ohman, A., & Dolan, R. J. (1998). Concious and unconscious emotional learning in
the human amygdala. Nature, 383, 812-814.

Morris, J. S., Ohman, A., & Dolan, R. J. (1999). A subcortical pathway to the right
amygdala mediating "unseen" fear. Proceedings ofthe National Academy of
Sciences ofthe United States ofAmerica, 96(4), 1680-1685.

Morris, J. S., Frith, C. D., Perrett, D. I., Rowland, D., Young, A. W., Calder, A.J., et al. (1996).
A differential neutral response in the human amygdala to fearful and happy facial
expressions. Nature, 393, 812-814.

Murphy, F. C, Nimmo-Smith, I, & Lawrence A. D. (2003). Functional neuroanatomy

of emotions: A meta-analysis. Cognitive, Affective, and Behavioral
Neuroscience, 3(3), 207-233.

Ochsner, K. N. (2000). Are affective events richly recollected or simply familiar? The
experience and process of recognizing feelings past. Journal ofExperimental
Psychology: General, 129, 242-261.

Patel, R., and Green, R.E.A. (2007). Mechanisms of the Emotional Enhancement of Memory. Peer-reviewed brief report published in conference proceedings of Festival of international conferences on caregiving, disability, aging and technology (FICCDAT),
Toronto, June 2007.

Patel, R., Green, R. E. A., & Girard, T. A. (2007). The impact of arousal deficits on facial
emotion perception and memory following traumatic brain injury. Toronto rehabilitation
institute research day; Toronto, Canada, November 2007.

Phan, K. L., Wager, T., Taylor, S. F., & Liberzon, I. (2002). Functional neuroanatomy of
emotion: A meta-analysis of emotion activation studies in PET and fMRI. Neuroimase,
16(2), 331-348.

Phelps E. A., LaBar, K. S., Anderson, A. K., O'Connor K. J., Fulbright, R. J., & Spencer,

D. D. (1998). Specifying the contributions of the human amygdala to emotional memory:
A case study. Neurocase, 4, 527-540.

Rahman, Q., Wilson, G. D., & Abrahams, S. (2004). Sex, sexual orientation, and identification
of positive and negative facial affect. Brain and Cognition, 54, 179-185.

Robertson, I. H., Manly, T., Andrade, J., Baddeley, B. T., & Yiend, J. (1997). 'Oops!':

Performance correlates of everyday attentional failures in traumatic brain injured and
normal subjects. Neuropsychologia, 35(6), 747-758.

Robertson, I. H, & Murre, J. M. (1999). Rehabilitation of brain damage: Brain plasticity and
principles of guided recovery. Psychological Bulletin, 125, 544-575.

Rosnow, R. L. & Rosenthal, R. (1989). Statistical procedures and the justification of knowledge
in psychological science. American Psychologist, 44(\Q), 1276-1284.

Roozendaal, B. & McGaugh, J.L. (1997). Basolateral amygdala lesions block the memory-

enhancing effect of glucocorticoid administration in the dorsal hippocampus of rats.
European Journal ofNeuroscience, 9, 76-83.

Russell, J. (1980). A circumplex model of affect. Journal ofPersonality & Social
Psychology, 39,1161-1178.

Sergerie, K., Chochol, C, & Armony, J. L. (2008). The role of the amygdala in emotional
processing: A quantitative meta-analysis of functional neuroimaging studies.
Biobehavioral Reviews, 32, 811-830.

Sharot, T., Delgado, M. R., & Phelps, E. A. (2004). How emotion enhances the feeling of
remembering. Nature Neuroscience, 7(12), 1376-1380.

Sharot, T., Verfaellie, M., & Yonelinas, A. (2007). How emotion strengthens the
recollection experience: A time-dependent hippocampal process. PLoS ONE, 2
(10),el068.

Sharot, T., & Yonelinas, A. P. (2008). Differential time dependent effects of emotion on
recollective experience and memory for contextual information. Cognition, 106, 538-547. Sim, T., Baker, S., & Bsat, M. (2003). The CMU pose, illumination, and expression database.
IEEE Transactions on Pattern Analysis and Machine Intelligence, 25(12), 1615-1618.

Somerville, L. H., Kim, H., Johnstone, T., Alexander, A. L., & Whalen, P. J. (2004). Human
amygdala responses during presentation of happy and neutral faces: correlates with state
anxiety. Biological Psychiatry, 55(9), 897-903.

Soussignan, R., Erie, N., Henry, A., Benoist, S., & Backshine, S. (2005). Dissociation of
emotional processes in response to visual and olfactory stimuli following
frontotemporal damage. Neuroscase, 11,114-128.

Snoddgrass, J. G. & Corwin, J. (1988). Pragmatics of measuring recognition memory:

Application to Dementia and Amnesia. Journal ofExperimental Psychology, 117(1), 3450.

Talarico, J. M., & Rubin, D. C. (2003). Confidence, not consistency, characterizes flashbulb
memories. Psychological Science, 14(5), 455-461.

Tottenham, N., Tanaka, J., Leon, A.C., McCarry, T., Nurse, M, Hare, T.A., Marcus, D.J.,

Westerlund, A., Casey, B.J., & Nelson, C.A. (in press). The NimStim set of facial
expressions: judgments from untrained research participants. Psychiatry Research, June,

Tulving, E. (1985). Memory and consciousness. Canadian Psychology, 26, 1-12.

Walker, E. L. (1958). Action decrement and its relation to learning. Psychological Review, 65,
129-142.

Walker, E. L. & Tarte, R. D. (1963). Memory storage as a function of arousal and time
with homogeneous and heterogeneous lists. Journal of Verbal Learning and
Verbal Behavior, 2, 113-119.

Whalen, P. J., Shin, L. M., Mclnerney, S. C, & Fisher, H. (2001). A functional MRI study of
human amygdala responses to facial expressions of fear versus anger. Emotion, 1(1), 7083.

Whalen, P. J., Rauch, S. I., Etcoff, N. L., Mclnerney, S. C, Lee, M. B., & Jenike, M. A.
(1998). Masked presentations of emotional facial expressions modulate amygdala
activity without explicit knowledge. Journal ofNeuroscience, 18, 411-418.

Whalen, P. J., Davis, C, Oler, J. A., Kim, H., Kim, J., & Neta, M. (2009). Human amygdala
responses to facial expressions of emotion. In P. J. Whalen & E. A. Phelps (Eds.), The
human amygdala (1st ed, pp. 265-288. New York: The Guilford Press.

Whalen, P. J., Johnstone, T., Somerville, L. H., Nitschke, J. B., Polis, S., Alexander, A. L., et al.
(2004). Human amygdala responsivity to masked fearful eye whites. Science, 306, 2061.

Wheeler, M. A., & Stuss, D. (2003). Remembering and knowing in patients with frontal
lobe injuries. Cortex, 39, 827-846.

Williams, M. A., Morris, A. P., McGlone, F., Abbott, D. F., & Mattingly, J. B. (2004).
Amygdala

suppression. Journal ofNeuroscience, 24, 2898-2904.

Yang, T. T., Menon, V., Eliez, S., Blasey, C, White, C. D., Reid, A. J., et al. (2002). Amygdalar
activation associated with positive and negative facial expressions. Neuroreport, 75(14),
1737-1741.

Yonelinas A P. (2002). The nature of recollection and familiarity: A review of 30 Years

of Research. Journal ofMemory and Language, 46, 441-517.

Yonelinas, A. P. & Parks, C. M. (2007). Receiver operating characteristics (ROCs) in
recognition memory: A review. Psychological Bulletin, 133(5), 800-832.

Yonelinas, A. P., Kroll, N. E., Dobbins, I., Lazzara, M, & Knight, R. (1998). Recollection and
familiarity deficits in Amnesia: Convergence of remember-know, process dissociation,
and receiver operating characteristic data. Neuropsychology, 12(3), 323-339.


