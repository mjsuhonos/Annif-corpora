Ryerson University

Digital Commons @ Ryerson
Theses and dissertations

1-1-2011

Dance to the Music: The Effects of Moving on Emotional Responsiveness
Lucy McGarry
Ryerson University

Follow this and additional works at: http://digitalcommons.ryerson.ca/dissertations Part of the Psychology Commons Recommended Citation
McGarry, Lucy, "Dance to the Music: The Effects of Moving on Emotional Responsiveness" (2011). Theses and dissertations. Paper 1343.

This Thesis is brought to you for free and open access by Digital Commons @ Ryerson. It has been accepted for inclusion in Theses and dissertations by an authorized administrator of Digital Commons @ Ryerson. For more information, please contact bcameron@ryerson.ca.

DANCE TO THE MUSIC: THE EFFECTS OF MOVING ON EMOTIONAL RESPONSIVENESS By Lucy McGarry Hon B.Sc., University of Toronto, 2008

A thesis presented to Ryerson University in partial fulfillment of the requirements for the degree of Master of Arts in the Program of Psychology

Toronto, Ontario, Canada, 2011 © Lucy McGarry 2011

  

Author's Declaration

I hereby declare that I am the sole author of this thesis or dissertation. I authorize Ryerson University to lend this thesis or dissertation to other institutions or individuals for the purpose of scholarly research.

Signature I further authorize Ryerson University to reproduce this thesis or dissertation by photocopying or by other means, in total or in part, at the request of other institutions or individuals for the purpose of scholarly research.

Signature

  

ii  

  

DANCE TO THE MUSIC: THE EFFECTS OF MOVING ON EMOTIONAL RESPONSIVENESS By Lucy McGarry Ryerson University, Master of Arts, Psychology, 2011

Abstract

In the current study I examined whether interpretive movement to music enhances emotional experience of the music, in dancers and non-dancers. Participants interacted with a series of musical excerpts, varying in valence and arousal, by either sitting still (still condition), moving arms up and down to the beat of the music (constrained condition), or gesturing their arms freely to the music (free condition), allowing for creative interpretation. Physiological and self-reported emotional responses to these songs were compared post-interaction. I found that after free gesturing, experienced dancers had polarized valence and arousal ratings towards happy vs. sad excerpts as opposed to after still and constrained conditions. Similar results were obtained for skin conductance (sweat) and zygomaticus major (smiling) responses. Non-dancers showed no difference in ratings or physiological responses between interaction conditions. This suggests that the effects of movement on emotional responsiveness to music are mediated by dance training.

  

iii  

  

Acknowledgements

I would like to sincerely thank Frank Russo for his tireless support and expertise as my advisor throughout every stage of this process. I would also like to thank Chris Lachine and Amy Kleynhans for their assistance with recruiting and running subjects, and Gabe Nespoli and Alex Andrews with their help with programming for analysis of physiological data. I am grateful to my family and friends for all of their support, and to Rajwant Sandhu for her editing assistance. Finally, I would like to thank my thesis supervisory committee, consisting of Ben Dyson and Jean-Paul Boudreau, as well as my external examiner, Todd Girard, for their helpful insights and suggestions.

  

iv  

  

Table of Contents Author's Declaration .................................................................................................................... ii Abstract......................................................................................................................................... iii Acknowledgements ...................................................................................................................... iv List of Tables ............................................................................................................................... vii List of Figures............................................................................................................................. viii List of Appendices........................................................................................................................ ix Introduction................................................................................................................................... 1 Mimicry in emotional understanding...................................................................................... 2 The mirror neuron system........................................................................................................ 3 Emotional music understanding involves movement interpretation.................................... 5 Musical movement simulation and its impact on musical understanding ........................... 6 Dance as exaggerated musical movement simulation ............................................................ 7 Movement expertise and MNS activity ................................................................................... 9 Operational Definition of Dance Movement......................................................................... 10 Free versus Constrained movement ...................................................................................... 11 Imagined movement................................................................................................................ 12 Measurement of musical emotion perception....................................................................... 12 The current study .................................................................................................................... 13 Methods........................................................................................................................................ 14 Participants .............................................................................................................................. 14 Apparatus and materials ........................................................................................................ 15 Design ....................................................................................................................................... 17 Procedure ................................................................................................................................. 17 Data Analysis ........................................................................................................................... 19 Pre-Interaction and post-interaction mimicry........................................................................ 19 EMG Data Analysis............................................................................................................... 19 Skin Conductance Data Analysis .......................................................................................... 20 Heart Rate Data Analysis ...................................................................................................... 20 Respiration Data Analysis ..................................................................................................... 20 Post-Interaction Polarization scores ...................................................................................... 20 Data Exclusions ..................................................................................................................... 21 Statistics................................................................................................................................. 22 Results .......................................................................................................................................... 22 Pre-Interaction Results ........................................................................................................... 22 Post-Interaction Results.......................................................................................................... 23

  

v  

  

Valence Ratings..................................................................................................................... 23 Arousal Ratings ..................................................................................................................... 24 Liking..................................................................................................................................... 26 Zygomatic Activity................................................................................................................ 28 Corrugator Activity................................................................................................................ 29 Skin conductance response.................................................................................................... 31 Heart Rate Activity................................................................................................................ 32 Breathing Activity ................................................................................................................. 33 Individual Differences in Physiology of Liking .................................................................... 35 Discussion .................................................................................................................................... 35 Future Directions..................................................................................................................... 42 Conclusions .............................................................................................................................. 44 References.................................................................................................................................... 45 Appendix A .................................................................................................................................. 50 Analyses of pre-interaction data: Individual differences .................................................... 50 Pre-interaction zygomatic responses ..................................................................................... 50 Pre-interaction corrugator responses.................................................................................... 51 Pre-interaction skin conductance, heart rate, and respiration ........................................... 52 Individual differences ............................................................................................................. 52 Discussion .................................................................................................................................... 56 Appendix B .................................................................................................................................. 57 Methods........................................................................................................................................ 57 Participants .............................................................................................................................. 57 Procedure ................................................................................................................................. 57 Data Analysis ........................................................................................................................... 57 Appendix C .................................................................................................................................. 64 Appendix D .................................................................................................................................. 66 Methods........................................................................................................................................ 66 Results .......................................................................................................................................... 66 Discussion .................................................................................................................................... 67

  

vi  

  

List of Tables Table 1. Participant demographic information ............................................................................. 15 Table 2. Valence Polarization ANOVA Table ............................................................................. 24 Table 3. Arousal Polarization ANOVA Table.............................................................................. 26 Table 4. Liking ANOVA Table .................................................................................................... 28 Table 5. Zygomatic Polarization ANOVA Table ......................................................................... 29 Table 6. Corrugator Polarization ANOVA Table ......................................................................... 30 Table 7. Skin Conductance Polarization ANOVA Table ............................................................. 32 Table 8. Heart Rate Polarization ANOVA Table ......................................................................... 33 Table 9. Respiration Polarization ANOVA Table ........................................................................ 35 Table B1. One week follow-up: Physiological and self-report data............................................. 58 Table B2. Valence Polarization ANOVA Table........................................................................... 58 Table B3. Arousal Polarization ANOVA Table ........................................................................... 59 Table B4. Zygomatic Polarization ANOVA Table....................................................................... 59 Table B5. Corrugator Polarization ANOVA Table ...................................................................... 60 Table B6. Skin Conductance Polarization ANOVA Table........................................................... 60

  

vii  

  

List of Figures

Figure 1. Valence Polarization Scores. ......................................................................................... 24 Figure 2. Arousal Polarization Scores. ......................................................................................... 25 Figure 3. Liking Scores................................................................................................................. 27 Figure 4. Zygomatic Polarization Scores...................................................................................... 29 Figure 5. Corrugator Polarization Scores...................................................................................... 30 Figure 6. SCR Polarization Scores................................................................................................ 32 Figure 7. Heart Rate Polarization Scores...................................................................................... 33 Figure 8. RSP Polarization Scores. ............................................................................................... 34 Figure A1. Zygomatic activity across songs, pre-interaction. ...................................................... 51 Figure A2. Corrugator activity, pre-interaction. ........................................................................... 52 Figure A3. Correlations between zygomatic polarizations and happy and sad song valence ratings for dancers. ................................................................................................................ 54 Figure A4. Correlations between zygomatic polarizations and happy and sad song arousal ratings for dancers. ............................................................................................................................ 55 Figure B1. Follow-up Valence Polarization. ................................................................................ 61 Figure B2. Follow-up Arousal Polarization.................................................................................. 61 Figure B3. Follow-up Zygomatic Polarization. ............................................................................ 62 Figure B4. Follow-up Corrugator Polarization............................................................................. 62 Figure B5. Follow-up SCR Polarization....................................................................................... 63

  

viii  

  

List of Appendices Appendix A .................................................................................................................................. 50 Appendix B .................................................................................................................................. 57 Appendix C .................................................................................................................................. 64 Appendix D .................................................................................................................................. 66

  

ix  

  

Introduction It has been speculated that we understand others' emotions through neural and peripheral simulations of their emotional movements (Carr, Iacoboni, Dubeau, Mazziotta, & Lenzi, 2003; Dimberg & Petterson, 2000). Neurally, interpretation of other people's actions has been linked to performance of those actions oneself, as overlapping brain circuitry is involved in the production and perception of movement (Rizzolatti & Craighero, 2004). Behaviorally, mimicry of others' movements is thought to lead to enhanced emotion recognition (Barsalou, Niedenthal, Barbey, & Ruppert, 2003). Similarly to socio-emotional communication, it has been postulated that music is understood through the audience's interpretations of the artist's movement intentions (Molnar-Szakacs & Overy, 2006). Furthermore, it is hypothesized that audiences understand musical performance through direct simulation of the performer's expressions (Livingstone, Thompson, & Russo, 2009). Communication of emotion is an essential skill for daily living. Music and dance are known to be specialized and well-established artistic modes used to convey and induce emotion (Juslin & Sloboda, 2001; Krumhansl &Schenk, 1997). Music and dance are thus important to explore in terms of their potential to provide information about the mechanisms involved in regular emotional communication, and in their applicability to clinical domains. In the current study, I wished to examine whether free movement to music would enhance emotional engagement during subsequent listening to that music, due to exaggerated simulation of interpreted emotional intentions from the music. I expected emotional engagement to be evident through self-reported and physiological measures, especially in individuals who have experience interpreting music through movement such as trained dancers.

  

1  

  

Mimicry in emotional understanding The effects of moving to music on musical emotion understanding have not been directly investigated. However, there is evidence in the social psychology, neuroscience, music psychology, and dance psychology literature that simulation of motor acts, either peripherally (on the body) or neurally (in the brain), is related to empathy or emotion understanding in the observer (Carr et al., 2003; Dimberg & Petterson, 2000; Riskind & Gotay, 1982; Molnar-Szakacs & Overy, 2006; Chartrand & Bargh, 1999; Cross et al., 2006). Social psychologists have found that during regular social interaction, mimicry of emotional movement is linked to emotional understanding and liking (Riskind & Gotay, 1982; Riskind, 1984; Chartrand & Bargh, 1999; Barselou et al., 1993). Watching another individual engaging in different physical postures, or engaging in these postures oneself, affects one's self- and other-perception of either melancholy (slumped posture) or pride (uplifted posture; Riskind & Gotay, 1982; Riskind, 1984). These findings support the idea that engaging in emotional body movements influences emotion. Individuals even have a tendency to nonconsciously mimic the movements of others and it has been found that this tendency is correlated with scores on an empathy questionnaire (Chartrand & Bargh, 1999). In Chartrand and Bargh's (1999) study, participants were videotaped while interacting with a confederate, and were found to imitate facial expressions and behaviours of the other person. In a follow-up study they found that high-mimickers scored higher on a perspective-taking empathy scale (Chartrand & Bargh, 1999). Embodied cognition theories of emotion also posit that our postures and movements are closely tied to our emotional experiences (Barselou et al., 2003). When participants are instructed to mimic another person's movements in a social setting, mimicry has been found to mediate empathy, in addition to liking and prosocial behaviours toward the mimicked individual

  

2  

  

(Stel, van Baaren, & Vonk, 2008), and conversely, being mimicked enhances liking of the mimicker (van Baaren, Holland, Kawakami, & Knippenberg, 2004). These examples illustrate the mediating effect that movement may have on emotional understanding as well as social connectedness during regular social interaction. The mirror neuron system Neuroscience literature makes a strong case for the existence of an action-perception network in the brain that guides simulation and empathic responses during regular social interaction as well as during the execution and perception of music and dance (Rizzolatti & Craighero, 2004; Carr et al., 2003). This network contains overlapping brain circuitry involved in the execution and perception of movement (Rizzolatti & Craighero, 2004), which is thought to play a critical role in the action-simulation process observed in emotional communication (Carr et al., 2003; Molnar-Szakacs & Overy, 2006; Iacoboni & Dapretto, 2006). First discovered through single-cell recordings in monkeys, neurons belonging to this system have been demonstrated to fire during the execution and perception of identical actions, and even during perception of different actions leading to a corresponding end goal (Rizzolatti & Craighero, 2004). The existence of the mirror neuron system (MNS) has also been documented in humans through fMRI, EEG, and TMS studies (Iacoboni & Dapretto, 2006; Pineda, 2008). While unable to isolate activity in single cells, these studies suggest that areas of the posterior inferior frontal gyrus, adjacent ventral premotor cortex, and inferior parietal lobule respond similarly towards execution and perception of action and intention-oriented movements in humans (Buccino et al., 2001; Rizzolatti & Craighero, 2004). In humans, mirror neuron circuitry has also been linked to the ability to perceive and produce emotional signals, and to underlie the understanding of another person's emotional
   3  

  

intentions (Carr et al., 2003). Carr et al. (2003) found that viewing or imitating an emotional facial expression lead to activation in the MNS as well as in the insula and amygdala. Wicker et al. (2003) found that smelling or watching someone else smell a positive or negative scent activated the MNS, insula and amygdala as well. Carr et al. (2003) propose that in order to understand another's emotional intentions, we need to simulate their emotional actions in our own brain. This simulation occurs through generation of imitative motor action patterns in the MNS, followed by a relay of emotional action through the insula to the limbic system, which in turn generates an empathic response (Carr et al., 2003). Support for the theory that the MNS plays a role in the understanding of emotional intention also comes from studies of individual differences. Individuals scoring higher than average on empathy scales have higher than average activation in mirror neuron areas during visual and auditory motion perception (Gazzola, Aziz-Zedeh, & Keysers, 2006), and are more likely to mimic others (Chartrand & Bargh, 1999). Individuals with problems identifying the emotions of others, such as individuals with autism (Williams, Whiten, Suddendorf, & Perrett, 2001) and those with psychopathic tendencies (Fecteau, Pascua-Leone, & Theoret, 2008), have decreased activation in the MNS during perception of emotions in others as compared to healthy individuals, and are also less likely to mimic others (Williams et al., 2001; Fecteau et al., 2008). Thus, it appears that mimicry can be understood in terms of neural simulation taking place in the MNS, in conjunction with corresponding peripheral activity, as an automatic reaction to help discern the intentions behind others' movements, and in the case of emotional movements, evoke an empathic response.

  

4  

  

Emotional music understanding involves movement interpretation Researchers of the psychology of music have recently begun to draw connections between the MNS, movement simulation, and the perception of music. In a persuasive paper on the role of simulation and the MNS in music perception, Monar-Szakacs & Overy (2006) suggest that music is understood through the listener's interpretations of a musician's manipulations of sound, indicating movement intention. The authors point out that all auditory events, including music, are caused by movement. When an individual plays an instrument or sings, he or she has the chance to manipulate movement in very subtle ways, creating purposeful combinations of emotional sound. The musician can thus convey intricate emotional movements beyond that which might be employed in regular social communication. The listener automatically simulates the musician's emotional movements (Livingstone, et al., 2009; Chan & Russo, in prep), and this process leads to resonance with the musician's emotions. Ramachandran and Hirstein (1999) suggest that one method artists use to evoke emotion in their audiences involves a peak shift effect ­ they take an attribute of an enjoyable stimulus in nature and exaggerate it, creating a "super stimulus" which operates to attract the viewer more than the original. The musician can take the emotionality of everyday movement and manipulate it in the realm of sound, to highlight and accentuate emotion. Gazzola (2006) found that the perception of auditory events generates MNS activity and that individual differences in MNS activity toward auditory events are correlated with scores on an empathy scale. Furthermore, Lahav et al. (2006) found that music elicits activation in the MNS. Due to the manipulation and accentuation of communication of emotional sound in music, it is likely that neural simulation of music is at least equivalent to if not greater than neural simulation of other human-movement-oriented sounds. It is also likely

  

5  

  

that neural and peripheral music simulation lead to a high degree of emotional resonance with the musician compared to other sources of human-oriented sound. Musical movement simulation and its impact on musical understanding Just as mimicry has been found to mediate emotional understanding in the social psychology literature, it has been hypothesized that mimicry mediates emotional understanding of song (Livingstone et al., 2009). Research suggests that audiences simulate the emotional expressions of a musician (Livingstone et al., 2009; Chan & Russo, in prep). Music researchers have found that interpretation of emotion communicated in music can be understood through the visual modality (Thompson & Russo, 2007). In addition, music listeners tend to naturally imitate the facial expressions of performers, which may mediate the level of understanding of the musical piece (Livingstone et al., 2009). In a study by Livingstone and colleagues (2009), when singers were asked to imitate a song passage, they demonstrated voluntary mimicry of the emotional facial expressions of the performer they were trying to imitate, before engaging in their own musical imitation, as measured by physiological indexes of the zygomaticus major (smiling) and corrugator supercilli (frowning) muscles. Phillips-Silver and Trainor (2005) found that when babies were bounced in either duple form or triple form to ambiguous music, they were more likely to interpret the music later as corresponding to the metre of their earlier vestibular input, supporting the idea that movement can influence music perception. While imitation of the exact movements depicted by a musician is impossible, mimicry of muscles that reflect similar emotional themes has been hypothesized to mediate understanding of a musical piece (Overy & Molnar-Szakacs, 2009; Livingstone et al., 2009).

  

6  

  

Dance as exaggerated musical movement simulation Dance can be viewed as an exaggerated simulation of the emotional movements in music (Krumhansl & Schenk, 1997; Boone & Cunningham, 1998), and can thus be expected to have an enhanced impact on emotional understanding of the music. Research suggests that watching a dance to music increases the observer's understanding of the emotion conveyed in the music (Krumhansl & Schenk, 1997). In Krumhansl and Schenk's (1997) study, participants watched a dance, or listened to the music to which the dance was choreographed, or watched and listened simultaneously. Participants rated the emotionality of the piece similarly whether they were in the dance-watching or music-listening condition. When dance and music were experienced together, participants' ratings of emotionality were polarized. This polarization suggests that watching a dance to music enhances one's emotional experience of the overall piece as compared to simply hearing the music or simply seeing the dance, and that there are corresponding emotional properties that can be communicated through music and dance movement. While music extracts the uniquely emotional elements of sound and exploits them to create a musical piece (Molnar-Szakacs et al., 2006), dance is considered an exaggerated form of emotional movement (Boone & Cunningham, 1998; Dittrich, Troscianko, Lea, & Morgan, 1996). Exaggeration of bodily emotion expression leads to enhanced recognition by observers of the emotions depicted by performers (Atkinson, Dittrich, Gemmell, & Young, 2004). Presumably, the high recognition rate of emotional body movements in dance (Krumhansl & Schenk, 1997; Camurri et al., 2003) occurs because of emotion exaggeration (Atkinson et al., 2004). Since dance movements have been shown to communicate the same emotions as the music they correspond to (Krumhansl & Schenk, 1997), dances composed to music are likely to employ direct exaggerations of the emotional themes portrayed by the musical movements. This

  

7  

  

emotional exaggeration would contribute to the increase in a viewer's ability to identify the emotions conveyed in a piece when dance and music are presented together (Krumhansl & Schenk, 1997). There are even particular qualities of music, as well as dance movements, that correspond directly to ratings of emotional arousal and valence (Gabrielson & Juslin, 1996; Thompson, 2009; Camurri, Lagerlof, & Volpe, 2003). For example, a faster musical tempo is related to higher arousal (Thompson, 2009). Major modes have been linked to positive valence, while minor modes have been linked to negative valence (Thompson, 2009). Camurri et al. (2003) specified dance movements that are connected to different emotions, on the dimensions of arousal and valence. For instance, large or sharp movements are linked to higher arousal, while the quality of those movements can qualify them as either positive or negative. Sharp movements taking place on down-beats are often linked to angry movements, where as sharp movements taking place on up-beats with an open body are linked to happiness. Finally, slower, restricted movement is linked to sadness. Since simulation of emotional movement in music has been hypothesized to mediate understanding of that music (Livingstone et al., 2009; Chan & Russo, in press), and since dancing is thought to exaggerate the emotional movements of a musical piece (Boone & Cunningham, 1998; Dittrich et al., 1996), in the current study I expected that dancing to music would enhance musical emotion engagement to a greater degree than simple facial mimicry. It has been shown that even imagining oneself participating in a dance can enhance activation of mirror neuron circuitry (Cross, Hamilton & Grafton, 2006). I expected that free movement to music would enhance mirror neuron activation, and that overt movement would be congruent with the emotional intentions behind the music in the same way that dance steps to music tend to

  

8  

  

reflect similar emotional themes (Camurri et al., 2003). I predicted that this would lead to enhanced emotional reactivity toward the music, even during subsequent listening. Movement expertise and MNS activity There is some evidence suggesting that there might be a difference between trained and untrained dancers in the capacity to be engaged in music through dancing. For example, trained dancers rate viewed dances differently than untrained dancers, in that they are more specific in discerning different dance attributes such as fluidity (Brownlow, Dixon, Egbert, & Radcliffe, 1997). Trained dancers are also accustomed to using a larger repertoire of dance steps in a free movement setting, so they are likely to employ a greater range of emotional movement in response to music, which could effect their levels of engagement simply through a higher level of movement participation. Several studies have also demonstrated that expertise contributes to MNS responsiveness during movement perception. Cross and colleagues (2006) found that dancers trained in a specific choreography exhibit greater MNS activity, as measured by fMRI, during subsequent observation of the same choreography (Cross, Hamilton, & Grafton, 2006). Calvo-Merino, Glaser, Grezes, Passingham, and Haggard (2005) conducted a study of capoeira artists, dancers, and non-movement-experts and found that capoeira artists and dancers had enhanced MNS activity while observing movements from their own area of expertise only. In a study of musical expertise, Lahav et al. (2006) demonstrated that practice playing a certain melody enhances MNS activity during later perception of that melody (Lahav et al., 2006). These findings each support the idea that neural mimicry of movements can be affected by experience with the movements themselves.

  

9  

  

Because of these differences observed between expert and novice movers, in the current study I wished to separate experts and non-experts. In order to ensure a difference in dance skill between expert and novice dancers, I compared dancers with greater than 6 years of training with individuals who had less than 1 year of dance training, to see whether the effects of free movement to music on musical emotional reactivity differed between these groups. Because it is still possible that the group with no dance training has engaged in dance recreationally, using a criteria of at least 6 years of formal training for experts helped ensure that there would be a difference between the groups in expertise. Operational Definition of Dance Movement There are various potential confounds that may arise from measuring the effects of dance movements in a laboratory setting. Participants may feel uncomfortable due to the artificial nature of the setting, and anxiety at dancing on command, and thus whole-body movements may be limited. There could be a difference in extent of movement between dancers and non-dancers due to varying levels of dance experience. Hand gestures provide a useful analog for full-body dancing, and participants are likely to engage in them with minimal hesitancy as compared to full-body movement. Clynes (1973) measured what he called "sentic forms", which were operationalized human gestures, simplified as the velocity over time of finger tapping. He found that even a movement as simple as tapping of the finger produces different waveforms for different emotions. For example, the curvature of angry tapping has a steep downward direction followed by a shallower upward movement, whereas grief follows a slower, shallow downward movement, and happiness a downward- upward course that is shallower than anger (Clynes, 1973). Clynes even characterized music in terms of these sentic forms and proposed that every

  

10  

  

composer has a "pulse", or a definable pattern of musical expressivity, which enhances the emotionality of a musical piece beyond that which can be annotated on a musical score. While these experiments were not well replicated, they suggest that it might be possible to simplify expressive gesture in this manner. Lidov (2009) suggests that if there had been a way to measure upward as well as downward gestural velocities in Clynes' studies, this would have allowed more of a differentiation of positive from negative movements. Allowing participants to make free hand gestures to music will allow for all possible hand movement directions, in addition to variation in amplitude and velocity, which should allow for a wider range of emotion expression through hand gesture. Since participants would be able to interact with the music in a freer way than simply listening or tapping to the beat, I expected that hand gestures would lead to engagement with the music in a similar way to real dancing, which would in turn enhance subsequent emotional engagement with the music. Free versus Constrained movement Different studies employing dance mechanisms have used either choreographed dance or free movement to explore emotionality of dance movements, but the two have not been extensively compared. I compared the effect of free movement versus constrained movement on subsequent emotional engagement with music, by either asking participants to move their arms up and down to the tempo of the music, or allowing the participants to move their arms and hands freely and expressively along with the music. Research suggests that self-generated movements are emotionally meaningful to a participant ­ participants are better able to recognize point-light displays of their own anonymized dance movements than those of others to the same music (Sevdalis & Keller, 2009). When participants are allowed to move their hands freely, their

  

11  

  

movements will presumably correspond to natural emotional movements that they are inspired to generate in line with music, causing feedback to emotional brain areas due to the generation of emotional movement (Riskind & Gotay, 1982, Riskind, 1984; Carr et al., 2003), and enhancing their overall emotional experience. Conversely, prescribed arm movements will control for the effect of simply moving at all during listening on subsequent engagement, and will not allow the participants to generate their own emotional action tendencies as freely. I expected that moving the arms up and down to the tempo would presumably still generate some enhanced entrainment and subsequent responsiveness to the music, but I hypothesized that the natural hand gestures elicited in response to the music by the participant would lead to a deeper level of emotional responsivity. Imagined movement Due to methodological limitations of psychophysiological and imaging equipment, many previous studies exploring the mechanisms behind movement production have employed imagination procedures in order to simulate activation in brain areas that might be involved in real movement (Cross et al., 2006; Foley, Bouffard, Raag, & Rose, 1991). These studies have found that simply imagining oneself moving can improve memory for a movement (Foley et al., 1991), as well as enhance activation in mirror neuron areas (Cross et al., 2006). I wished to examine whether imagined movement would elicit greater emotional responsiveness to music than music listening without imagined movement. Measurement of musical emotion perception Previous studies have indexed emotion perception in music in several ways. Sandstrom & Russo (2010) found that music listening affects heart rate and skin conductance responses

  

12  

  

(SCR) following exposure to an acute stressor. Witvliet, & Vrana (2007) found that liking ratings and zygomatic responses were polarized after repeated exposure to pleasant and unpleasant music. They also observed changes in heart rate, corrugator, and obicularis oculi activity. Roy, Mailhot, Gosselin, Paquette, and Peretz (2008) found that music affected startle responses as well as corrugator, SCR, and heart rate (HR) activity. In the current study, I employed various methods to index emotional processing of music in as thorough a manner as possible. Physiological measurements included electromyographical measurement of the zygomaticus major (smiling) and corrugator supercilli (frowning) muscles, whose activity have been demonstrated to discriminate musical emotions during audiovisual perception of a singer (Chan & Russo, in prep). I also indexed SCR and HR, measures of arousal (Vrana, 1995) that have been demonstrated to be affected by music (Sandstrom & Russo, 2010), and respiration (RSP), which has also been linked to emotional arousal in music (Etzel, Johnsen, Dickerson, Tranel, & Adolphs, 2006). Self-reported ratings included valence, arousal, and liking ratings, used to index conscious awareness of emotional and preference changes (Witvliet et al., 2007). For each measure except liking I created one polarization score by taking the difference between responses to happy and sad songs. The current study In the current study, I expected that dancing to music would enhance emotional responsiveness to the music during subsequent listening. I compared changes in adult participants' emotional engagement for music after one of 4 types of interaction with the music: Sitting still and listening (still), tracking musical tempo with up-and-down arm movements (constrained), freely gesturing with arms and hands (free), and imagining free gesturing (imagine).

  

13  

  

I predicted that generation of interpretive hand gestures would lead to a higher degree of interaction between movements and the music, and therefore a higher degree of emotional engagement with the music. I predicted that this higher level of engagement would be reflected in an increase in emotional arousal and valence report polarizations, as well as heightened zygomatic, corrugator, SCR, RSP, and HR polarizations between happy and sad songs, for free and imagine conditions more than for still and constrained conditions. I also expected that trained dancers would exhibit a higher level of interaction with music than non-dancers while performing interpretive hand gestures, leading to greater levels of emotional enhancement following the free condition.

Methods Participants 33 healthy adult trained dancers (24 female) and 30 healthy adult non-dancers (22 female) were recruited from the Ryerson undergraduate psychology participant pool, as well as through advertisements around campus. Table 1 provides means and standard deviations for years of dance training, music training, education and age. Dance training was significantly higher among dancers than non-dancers, t (61) = 12.25, p < .001, whereas the two groups did not differ with regard to music training, education or age, t < 1. Inclusion criteria included the absence of neurological or psychiatric disorders. All participants were fully consented prior to participation, and compensated with either course credit or $25.

  

14  

  

Table 1. Participant demographic information Dancers Non-Dancers Mean (years) SD Mean (years) Dance 12.1 5 0.4 Training Music 4.46 4.07 3.38 Training Age 25.25 6.67 23.84 Education 15.69 2.15 15.19

SD .07 5.8 8 1.93

Apparatus and materials Testing took place in a private Industrial Acoustics Company double-walled soundbooth. Physiological data was collected with Biopac MP100 amplifiers. Songs were presented in stereo via speakers located on either side of a Mac computer screen, and participants gave responses via a computer keyboard. Each participant listened to a selection of 16 songs (8 happy and 8 sad) from 32 song clips, each of which were 35 seconds long. Song presentation was always 35 seconds, including a 5-s fade-out. Song clips were taken from the beginning of each original song recording. Audio was played through speakers located on either side of the screen. Physiological recordings were measured using a Mac Mini computer running AcqKnowledge software. Music choice. Clynes (1983) theorized there is a definable quality to the emotional expression that a musician adds to a written score of music to make it "move" the listener emotionally. It was later demonstrated experimentally that listeners prefer music with the composer's "pulse" overlaid on the piece to computer-generated music, which does not add any "pulse" or interpretation to the written score (Repp, 1989). It is possible that the reason we prefer the same song by one musician over another has to do with the degree to which the musician has inspired us to simulate, by adding emotional movement into the piece, defined here

  

15  

  

as a "pulse". In the current study, I chose to play the Bach Cello Suites by Yo Yo Ma, a musician who is known to be very expressive (see Appendix C for a list of songs). I considered this music to be more likely to evoke movement simulation in listeners due to the musicians' expressivity. In addition, I expected that these songs would be less familiar to most participants than mainstream popular music would be. The absence of vocals in the music allowed me to exclude possible confounding effects of lyrics on music emotion perception. Since all songs were played by the same performer and instrument, I was able to control for differences due to musician and timbre across songs. 36 songs were rated by a pilot group on the dimensions of valence (1 = most negative to 9 = most positive) and arousal (1 = least arousing to 9 = most arousing), and then 32 selected songs were defined as happy (high valence (>5) and high arousal (>5)) or sad (low valence (<5) and low arousal (<5)). Rating Scales. Valence and arousal rating scales were obtained from the SelfAssessment Manikin (Bradley & Lang, 1994). The valence rating scale consisted of a scale from 1 = most negative to 9 = most positive (each number accompanied by a picture of a cartoon character expressing varying degrees of emotional valence from negative to positive). The arousal rating scale consisted of ratings from 1 = least arousing to 9 = most arousing (each number accompanied by a picture of a character ranging in expressivity from very bored/sleepy to very excited looking); Bradley & Lang, 1994). The familiarity scale depicted numbers from 1 = least familiar to 9 = most familiar. The liking scale also depicted numbers from 1 = least likeable to 9 = most likeable.

  

16  

  

Design The study followed a mixed design. The between-subjects independent variable was group membership (dancer, non-dancer) and the within-subjects independent variable was interaction condition (still, imagine, constrained, free). The dependent variables consisted of several rating scale responses (valence, arousal, liking) and several physiological responses (zygomaticus major, corrugator supercilli, skin conductance, heart rate, respiration). Procedure The procedure consisted of three phases: pre-interaction, interaction, and post-interaction. Each subject listened to 16 song clips, 8 happy and 8 sad, a total of 4 times: during one preinteraction phase, two interaction phases, and during one post-interaction phase. For each participant, 8 happy songs were selected from a collection of 16 pre-rated happy songs, and the same process was used for 8 sad songs. Pre-interaction phase. After providing consent, participants were seated in the soundbooth where the psychophysiological equipment was attached. EMG electrodes were attached to the left side of the face; two over the eyebrow on the corrugator supercilli muscle and two over the zygomaticus major muscle, and one to the forehead as a ground. EMG data was collected using a sampling rate of 1000 Hz and gain value of 5000, and an input voltage of +/-10 which was later converted to microsiemens. Two SCR electrodes were attached to two fingertips on the left hand. Heart rate was measured using a photoplethysmographic sensor attached to a finger on the left hand, and the breathing apparatus was strapped around the chest with velcro. SCR and HR data were sampled at 250 Hz, and breathing data at 125 Hz. Participants listened to 16 35-s song clips, eight happy and eight sad. Each clip was accompanied by a fixation cross on the screen. After each excerpt, the participants were asked to make valence, arousal, familiarity,

  

17  

  

and liking ratings. Each rating scale was presented for an unlimited amount of time until the participant made a choice by pressing the corresponding number on the keyboard, at which point the next scale would appear. Ratings were followed by a 15-s intertrial interval, after which the next song clip would play. Psychophysiological measurements were recorded while the participants listened to the music. Interaction phase. Electrodes on the hands were removed in order to avoid movement limitations for hand gestures. Participants listened to all excerpts twice more while interacting with the music in each of 4 ways, twice per emotion type. Songs were randomly paired with each instruction for each participant, and within participants, the same song was always paired with the same instruction. This randomization procedure ensured that each instruction type was paired with two happy songs and two sad songs for each participant. Each song followed the next with no intertrial interval. Songs were accompanied by a single-word visual instruction that remained on the screen for the entirety of the song clip. When the onscreen instruction said Still, participants were asked to sit still and listen to music (still condition). When the instruction said Track, participants were asked to move their arms up and down, bending and straightening in a constrained manner from the elbow, to the beat of the music (constrained condition). When the instruction said Imagine, participants were asked to imagine themselves moving their arms and hands freely to the music (imagine condition). When the instruction said Gesture, participants were asked to gesture freely to the music, and were encouraged to be creative and avoid repetitive movements (free condition). Participants were reminded that no one was watching them, and encouraged to move freely. Post-interaction phase. Approximately 5 minutes elapsed between the end of the interaction phase and the start of testing in the post-interaction phase. Hand electrodes were
   18  

  

reattached, and participants heard excerpts one more time, each accompanied by a fixation cross, while physiological measurements were taken. Valence, arousal, and liking ratings were collected after each song clip, followed by a 15-s intertrial interval. One week follow up. See appendix B for information on a one-week follow-up testing phase, which was discontinued partway through data collection due to unreliable results. Data Analysis All physiological data were processed using custom Matlab scripts. A 12-s target window was established as the approximate centre of each song clip (commencing 12 seconds following onset and ending 11 seconds prior to offset) and unless otherwise stated, a 10-s baseline window was established as the 10 seconds prior to each song clip. Pre-Interaction and post-interaction mimicry All responses collected before interaction conditions were examined to see whether there were any initial differences between groups, or song emotions, in responses. Post-interaction responses were examined in more detail to explore differences in the effects of each type of interaction on emotional responses to happy and sad song clips. EMG Data Analysis A first-order 59-61 Hz Butterworth notch filter and a fifth-order 10 Hz Butterworth highpass filter were applied offline. The filtered data was visually inspected, and trials with excessive artifact (due to movement or electrode displacement) were excluded from analyses (13.2 % of trials). Voltage data was subjected to a root mean square smoothing filter with a 50-ms time window (Fridlund & Caccioppo, 1986), which was in turn subjected to a square root transformation in order to normalize the data (Larsen, Norris, & Caccioppo, 2003). Despite
   19  

  

instructions to remain still during baseline, movement artifact was present. In order to correct for this, a one-s moving baseline was established for EMG analyses corresponding to the one-s time window with the lowest mean value. For each trial, the average transformed value for the one-s baseline was subtracted from the average transformed value for the target window. Skin Conductance Data Analysis For each trial, the average skin conductance level during the 10-s baseline window was subtracted from the average 12-s target window. Heart Rate Data Analysis Heart rate data was filtered using a third-order Butterworth filter with limits of .67 ­ 3.33 Hz, corresponding to a target heart rate interval of 40-200 beats per minute. A fast-Fourier transform was computed to determine the heart rate (HR) in each window of interest, and the component with the highest power was determined. For each trial, the HR during the baseline was subtracted from the HR during the target window. Respiration Data Analysis Respiration (RSP) data was analyzed using a Matlab software algorithm that counted peaks to determine breaths per minute. For each trial, RSP during baseline was subtracted from RSP in the target window. Post-Interaction Polarization scores Because we were expecting the difference between responses to happy songs (high arousal, high valence) and sad songs (low arousal, low valence) to increase following free as opposed to still or constrained conditions, response polarization scores for each interaction condition were created following Witvliet & Vrana (2007). For measures in which happy (high
   20  

  

arousal, high valence) songs reliably elicit greater responses, such as valence ratings, arousal ratings, zygomatic (smiling), SCR (arousal), HR (arousal) and breathing (arousal) responses, average scores for sad songs were subtracted from those for happy songs for each condition. For corrugator (frowning) activity, in which sad songs are expected to elicit greater activity, polarization scores were calculated by subtracting happy reactions from sad. It was expected that after free gesturing, polarization between happy and sad songs on each measure would be greater than after no movement. Data Exclusions Subjects were excluded from analysis of a specific measure if they generated responses greater than 3 standard deviations from the mean for that measure. This criteria resulted in exclusion of two non-dancers from valence analyses, and one non-dancer from arousal analyses. All subjects were included in liking analyses. Four dancers and one non-dancer were excluded from zygomatic analyses, while three non-dancers and four dancers were excluded from corrugator analyses. Exclusions for zygomatic and corrugator analyses were due to either excessive numbers of noisy trials excluded during visual inspection of data, or to outliers. Seven non-dancers and three dancers were excluded from SCR analyses, and two non-dancers and one dancer were excluded from heart rate analyses. Seven non-dancers and six dancers were excluded from respiratory analyses. During data collection, many dancers reported that they were always likely to imagine dancing during music listening, regardless of specific instruction on a trial. Since I did not explicitly ask participants to avoid imagined movement during the still condition, I cannot be sure that still and imagine conditions were properly differentiated by participants. Additionally, imagining hand gestures may not engage the MNS, since participants do not have much previous
   21  

  

experience generating hand gestures to music (even dancers). Because I felt that the imagine condition was not satisfactorily distinguished from other conditions in terms of instructions and participant reports, I excluded that condition from analyses. In the future, I plan to ask participants to imagine movements they have more experience executing, such as actual dancing, and plan to more explicitly distinguish instructions to sit still and avoid imagining movement during music listening from movement imagination conditions, in order to examine the effects of imagined movement on emotional responsiveness. Statistics Within each measurement type, data were subjected to a mixed model ANOVA with movement instruction as the within-subjects factor (still, constrained, free) and movement experience as the between-subjects factor (dancer, non-dancer). When Mauchly's test of sphericity was significant, a Greenhouse-Geisser correction was applied. When ANOVAs were significant, a planned simple contrast measured the group difference in changes between still and free as well as constrained and free conditions.

Results Overall results suggest that my free movement manipulation led to increased polarizations of emotional responses in dancers compared to the still condition, as I predicted, on several measurement indexes. However, non-dancers did not generate such differences between movement and non-movement conditions, and in some cases, movement even seemed to interfere with polarization in emotional responsivity to happy and sad songs. Pre-Interaction Results

  

22  

  

In order to examine whether groups differed in their initial self-reported or physiological responses to stimuli, I compared pre-interaction familiarity, liking, valence and arousal ratings, as well as all physiological measures. Comparisons between groups were made using Bonferroni-corrected t-tests. None of these were significant, even at the .05 level (all p's > .16), suggesting that overall self-reported responses were not different between groups. Please see Appendix A for additional post-hoc examinations of pre-interaction data. Post-Interaction Results Valence Ratings As can be seen in Figure 1, dancers' valence polarizations appear to increase after the free condition, whereas non-dancers' polarizations do not. There was a significant condition by group interaction: F(1.77, 104.43) = 3.60, p < .05 (please see Table 2 for ANOVA results), and a planned interaction contrast revealed that changes between still and free conditions varied by group, F(1,59) = 7.23, p <.01, as well as marginally for constrained vs. free conditions by group, F(1,59) = 3.28, p = .075. Independent t-tests with a Bonferroni-corrected alpha level of .015 indicate that dancers had marginally lower ratings than non-dancers after listening, t(59) = -2.20, p = .032, but after constrained movement and especially after gesturing freely, their responses polarized more so that they were no longer different from those of non-dancers, t(59) = -1.61, ns, and t(59) = .40, ns, respectively. When happy and sad responses were looked at separately, ANOVAs were not significant, indicating that one emotion type was not driving the polarization increase more than another.

  

23  

  

Figure 1. Valence Polarization Scores. Mean polarization scores with standard errors. Whereas dancers' polarizations increase after gesturing as opposed to still listening, nondancers' polarizations do not.

Valence  Polariza-on  Scores  
3   2.5   2   1.5   1   0.5   0   S1ll   Constrained   Free   Dancers   Novices  

Table 2. Valence Polarization ANOVA Table Sum of Squares Df Condition Condition by Group Error Group Error *significant at .05 level Arousal Ratings 1.37 11.30 185.18 3.875 78.758 1.77 1.77 104.43 1 59

Mean Square .77 6.39 1.77 3.875 1.335

F .44 3.60*

P .623 .036

2.903

.094

As can be seen in Figure 2, dancers' arousal polarization ratings appear to increase after free as opposed to still or constrained conditions, whereas non-dancers do not appear to benefit from free movement in this way. There was a significant condition by group interaction: F(2, 120) = 3.34, p < .05 (please see Table 3 for ANOVA results). A planned contrast demonstrated
   24  

  

that groups again showed different patterns after the still vs. free conditions: dancers' arousal ratings polarized after free movement, whereas non-dancers' rating polarizations decreased; F(1,60) = 5.10, p < .05. This contrast was also significant for constrained vs. free movement conditions with the same pattern; F(1,60 = 4.38, p < .05, indicating again that dancers' arousal ratings had highest polarization after gesturing freely as opposed to constrained movement, whereas non-dancers did not show this increase. A mixed model ANOVA with movement instruction as the within-subjects factor (still, constrained, free) and movement experience as the between-subjects factor (dancer, non-dancer) for happy and sad songs alone was conducted, and neither of these ANOVAs were significant, indicating that one song type was not driving polarization differences. Figure 2. Arousal Polarization Scores. Mean polarization scores with standard errors. Whereas dancers' polarizations increase after free as opposed to still, non-dancers' polarizations do not.

Arousal  Polariza-on  Scores  
2.5   2   1.5   Dancers   1   0.5   0   S1ll   Constrained   Free   Novices  

  

25  

  

Table 3. Arousal Polarization ANOVA Table Sum of Squares Df Condition Condition by Group Error Group Error *significant at .05 level Liking .420 13.270 238.502 .022 55.561 2 2 120 1 60

Mean Square .210 6.635 1.988 .022 .926

F .106 3.338*

P .900 .039

.024

.878

Figure 3 suggests that while there was no difference between liking across groups for happy and sad songs after the still condition, happy songs appear to be liked more than sad after constrained and free conditions. Instead of measuring polarization scores, since a polarization between happy and sad songs was not expected for the measure of liking, I conducted a mixed model ANOVA with group (dancer, non-dancer) as the between-subjects variable and condition (still, constrained, free) and emotion (happy, sad) as within-subjects variables. While there was no main effect of condition or group, there was a main effect of emotion; F(1,61) = 30.829, p < .001), indicating that happy songs were more well-liked than sad songs (please see Table 4 for ANOVA results). There was also an interaction between condition and emotion; F(2,122) = 5.362, p < .01, indicating that differences in liking for happy and sad songs changed across conditions. In order to explore this further, a mixed model ANOVA was conducted for happy and sad songs separately, with movement instruction as the within-subjects factor (still, constrained, free) and movement experience as the between-subjects factor (dancer, non-dancer) for liking ratings,

  

26  

  

post-interaction. This ANOVA yielded no significant effects for happy songs. For sad songs, the ANOVA yielded a marginal main effect of condition on liking; F(1.81,110.535) = 2.73, p = .075. Follow up t-tests at a Bonferroni-corrected alpha level of .015 suggest that this effect was driven by a decrease in liking of sad songs after free as opposed to still conditions; t(62) = 2.58, p < .015. Liking for sad music after constrained movement was not significantly different from still (t(62) = 1.46, ns) or gesture (t(62) = .55, ns). Figure 3. Liking scores across groups for happy and sad songs. Mean liking ratings with standard errors. Across groups, participants' liking scores decreased for sad songs after free as opposed to still.
9   8   7   6   5   4   3   2   1   0   S1ll   Constrained   Free   Happy   Sad  

Liking  

  

27  

  

Table 4. Liking ANOVA Table Sum of Squares Condition Condition by Group Error Emotion Emotion by Group Error Condition by Emotion Error **significant at .01 level ***significant at .005 level Zygomatic Activity .701 8.29

Df 1.72 1.71

Mean Square .41 4.82 2.81 133.83 3.83 4.34 7.37 1.37

F .145 1.71

P .834 .184

294.91 104.87 133.83 3.83 264.79 14.20 1 1 61 1.93

30.83*** .881

.000 .352

5.36**

.006

161.51 117.56

As Figure 4 demonstrates, dancers had higher zygomatic polarizations than non-dancers after free movement only. Whereas the mixed model ANOVA did not capture a condition by group interaction; F(2,112) = 1.31, ns, there was a marginal main effect of group, with dancers exhibiting greater overall zygomatic activity polarizations than non-dancers; F(1,56) = 3.98, p = .051 (Please see Table 5 for ANOVA results). A follow up t-test with a Bonferroni-corrected alpha level of .015 revealed that whereas dancers' and non-dancers' zygomatic polarizations were not different after still (t(56) = .14, ns) or constrained (t(56) = 1.39, ns) conditions, they became marginally different after free movement (t(56) = 2.16, p = .035), with dancers' responses polarizing and non-dancers' becoming less polarized, similarly to valence rating data, suggesting that the group difference was driven by the free condition. Differences in happy

  

28  

  

ratings and sad ratings were not significant, indicating that one emotion type was not driving the polarization increase more than another. Figure 4. Zygomatic Polarization Scores. Mean polarization scores with standard errors. Whereas dancers' polarizations increase after gesturing as opposed to still listening, nondancers' polarizations decrease.

Zygoma-c  Polariza-on  Scores  
0.4   0.3   0.2   0.1   0   S1ll   -0.1   -0.2   Constrained   Free   Dancers   Non-Dancers  

Table 5. Zygomatic Polarization ANOVA Table Sum of Mean Squares Df Square Condition Condition by Group Error Group Error Corrugator Activity .01 .64 27.56 .455 6.40 2 2 112 1 56 .01 .32 .25 .455 .114

F .03 1.31

P .974 .275

3.980

.051

  

29  

  

A mixed model ANOVA with movement instruction as the within-subjects factor (still, constrained, free) and movement experience as the between-subjects factor (dancer, non-dancer) yielded no significant results, suggesting that there were no changes in polarization of corrugator activity for either group after sitting still, moving in a constrained manner, or gesturing freely (see Figure 5 for a graphical depiction of means, and Table 6 for ANOVA results). Figure 5. Corrugator Polarization Scores. Mean polarization scores with standard errors. Corrugator polarizations were not significantly different across conditions or groups.

Corrugator  Polariza-on  Scores  
0.25   0.2   0.15   0.1   0.05   0   -0.05   -0.1   -0.15   -0.2   -0.25   S1ll   Constrained   Free   Dancers   Non-Dancers  

Table 6. Corrugator Polarization ANOVA Table Sum of Squares df Condition Condition by Group Error Group Error 1.05 .12 27.34 .012 11.802 1.78 1.78 97.89 1 55

Mean Square .59 .07 .28 .012 .215

F 2.10 .25

P .133 .754

.054

.817

  

30  

  

Skin conductance response As can be seen in Figure 6, non-dancers generated greater SCR polarizations than dancers after the still condition, but after free movement, dancers' polarizations increased and nondancers' polarizations decreased, such that the two groups' polarizations were equivalent. There was a significant condition by group interaction: F(2, 102) = 6.74, p < .005 (Please see Table 7 for ANOVA results). A planned contrast revealed that changes between still and free conditions differed between groups, such that dancers' polarizations went up and non-dancers' did not; F(1,51) = 4.83, p < .05, whereas differences between conditions by group did not change between constrained and free conditions; F(1, 51) = 2.29, ns. Follow up tests with a Bonferronicorrected alpha level of .015 suggest that while non-dancers generated greater SCR responses than dancers after the still condition; t(51) = -2.69, p < .015, and the constrained condition; t(51) = -2.58, p < .015, dancers' SCR polarizations went up to match those of non-dancers after free movement; t(51) = .41, ns. ANOVAs for happy and sad songs alone were not significant, indicating that one emotion type was not driving the polarization increase more than another.

  

31  

  

Figure 6. SCR Polarization Scores. Mean polarization scores with standard errors. After the still condition, non-dancers generated greater SCR polarizations than dancers. After tracking and gesturing this pattern reversed: As for other measurements, whereas dancers' polarizations increase after gesturing as opposed to still listening, non-dancers' polarizations decrease.

SCR  Polariza-on  Scores  
0.4   0.3   0.2   0.1   0   -0.1   -0.2   -0.3   -0.4   S1ll   Constrained   Free   Dancers   Non-Dancers  

Table 7. Skin Conductance Polarization ANOVA Table Sum of Mean Squares df Square Condition Condition by Group Error Group Error ***significant at .005 level Heart Rate Activity .21 4.511 34.111 .000 4.935 2 2 102 1 51 .10 2.255 .334 .000 .097

F .31 6.744***

P .73 .002

.002

.965

For heart rate data, the mixed model ANOVA yielded no significant results. However, the trends were consistent with the direction of valence and arousal polarizations found for dancers and non-dancers, in that dancers' polarizations appear greater after movement as

  

32  

  

opposed to still conditions, and non-dancers' polarizations show an opposing pattern (see Figure 7 for a graphical depiction of means, and see Table 8 for ANOVA results). Figure 7. Heart Rate Polarization Scores. Mean polarization scores with standard errors. HR polarizations were not different between conditions or groups.

Heart  Rate  Polariza-on  Scores  
4   2   0   S1ll   -2   -4   -6   -8   Constrained   Free   Dancers   Non-Dancers  

Table 8. Heart Rate Polarization ANOVA Table Sum of Mean Squares df Square Condition Condition by Group Error Group Error Breathing Activity 6.30 182.38 11453.25 85.787 3803.896 2 2 116 1 58 3.15 91.19 98.82 85.787 65.584

F .03 .92

P .969 .400

1.308

.257

As can be seen in Figure 8, non-dancers unexpectedly gained a marginal benefit of free movement in respiratory (RSP) polarizations as opposed to dancers. There was a marginally significant condition by group interaction; F(2,96) = 2.56, p = .083 (Please see Table 9 for

  

33  

  

ANOVA results). Planned contrasts revealed a pattern opposing those found in other measurements: Non-dancers generated a marginally greater number of breaths per minute than dancers after free as opposed to still conditions (F(1,48) = 3.66, p = .062). There were no differences in breathing rate polarizations between constrained and free conditions. A t-test within non-dancers of still vs. free conditions demonstrated that RSP polarizations became significantly higher after the free condition; t(22) = -2.45, p < .05. Examination of happy and sad songs separately did not yield any significant differences, indicating that one emotion type was not driving the polarization increase more than another. Figure 8. RSP Polarization Scores. Mean polarization scores with standard errors. In contrast to other findings, non-dancers unexpectedly gained a marginal benefit of free movement in respiratory polarizations as opposed to dancers, whose RSP polarizations did not change across conditions.

RSP  Polariza-on  
6   5   4   3   2   1   0   -1   -2   -3   -4   S1ll   Constrained   Free   Dancers   Non-Dancers  

  

34  

  

Table 9. Respiration Polarization ANOVA Table Sum of Mean Squares df Square Condition Condition by Group Error Group Error 107.51 273.07 5127.74 57.576 996.893 2 2 96 1 48 53.753 136.54 53.41 57.576 20.769

F 1.006 2.56

P .369 .083

2.772

.102

Individual Differences in Physiology of Liking Previous research has demonstrated that people will choose to listen to, and enjoy, sad music, despite its ability to evoke negative emotions (Schellenberg, Peretz & Vieillard, 2008). However, in the current study, I found that after the free condition, liking of sad music decreased across groups. It is possible that people usually refrain from mimicry of the sad emotional movements depicted by a sad musical piece when they choose to listen to it, in order to control the degree of resonance felt with the music. In the current study, when they were forced to interact with sad music through movement, maybe this enhanced their emotional responsivity to the music to a degree that caused discomfort. In order to explore this possibility further, I ran a correlation between facial animation and liking of sad music. I found that facial animation (zygomatic and corrugator combined) during sad music was in fact negatively correlated with liking for sad music (r(57) = -.33, p < .05). Discussion The results of the current study suggest that while trained dancers gain increased polarity in emotional responsiveness to happy and sad song clips after free movement, non-dancers do

  

35  

  

not. Polarization between happy and sad songs for arousal ratings, valence ratings, zygomatic, and skin conductance responses were increased for dancers after free as opposed to still conditions, and often after free as opposed to constrained conditions, but were not increased for non-dancers across conditions. As predicted, constrained movement usually did not enhance emotional responsiveness to the same degree as free movement, but for skin conductance responses, even tracking the tempo with one's hands led to enhanced subsequent emotional arousal for dancers. Non-dancers, however, did not benefit from free movement to music, and in some cases, movement interaction appeared to interfere with emotional responsivity, such as for valence, zygomatic, and SCR polarization scores. Based on the finding that the effect of movement on emotional responsiveness to music varied between groups, it appears that dancers need to move in order to achieve a sharper polarization in emotional responsiveness. Rather than gaining an increase above that attainable by non-dancers after moving to music, dancers and non-dancers do not differ in their overall physiological responsivity and ratings of songs (before interaction conditions, there were no overall group differences for any measures). It is also noteworthy that on some measures, nondancers trended towards greater polarity of emotional responsiveness than dancers after still listening, while the pattern reversed following free movement. There are a couple of possible explanations why dancers might need to move to music in order to experience it fully. It is plausible that movement training increases action perception links in the MNS, making movement-oriented musical interaction the dominant way to perceive music. Non-dancers are not accustomed to moving to music, making overt movement unnecessary for musical emotion encoding. In this group, polarizations in zygomatic and skin conductance responses during the still condition trended towards being non-significantly greater

  

36  

  

than in dancers, suggesting that greater neural simulation, as well as nonconscious peripheral mimicry, might take place in this group in the first place, without the need for exaggeration through movement of the music's emotional themes. Non-dancers might not need to move to music in order to gain optimal emotional responsivity. Dancers are accustomed to experiencing music while moving, making it necessary to overtly simulate in order to gain the greatest benefit in musical perception. An alternative possibility is that there were already-present individual differences between dancers and non-dancers that caused dancers to seek out dance training in the first place. In the current study I did not randomly select and manipulate the level of dance training, but rather selected groups based on their previously received training. It is possible that individuals born with a need to overtly simulate emotional movement in order to understand it are more likely to choose to engage in dance from a young age. Future studies should manipulate the degree of dance training in non-dancers in order to discern whether the differences found in the current study were a result of training. Research demonstrates that individuals viewing movements they have experience executing generate greater MNS activity while observing that movement than those who do not (Cross et al., 2006; Calvo-Merino et al., 2005), making it seem likely that all participants would have generated greater MNS activity during later listening to songs they had moved to in the current study. However, studies exploring the effects of movement experience on MNS activity have usually found an effect of movement learning on MNS activation in experts in a movementrelated domain such as dance or capoeira (Cross et al., 2006; Calvo-Merino et al., 2005), and have not tested the effects of movement training on non-experts. This lack of research focus on non-experts makes it possible that non-experts, like the non-dancers in my study, may process
   37  

  

movement differently than those who are already skilled in a specific movement repertoire. It is also possible that non-dancers did not move in as complex a way as dancers, since they lack experience moving creatively to music. Non-dancers generated less extensive neural simulation during movement conditions simply because they were moving in a less complex way than dancers. It is possible that my movement paradigm was too complicated for inexperienced dancers. Non-dancers could have been distracted by the idea of having to consciously generate movements in line with the music, and this may have drawn their attention away from the music, whereas dancers would have a stronger tendency to generate emotional movements automatically. In the current study I did not record movements of the two groups, as I wanted to minimize self-consciousness, which might impede free movement. However, in the future I plan to record movements of dancers and non-dancers, in order to determine whether the degree of movement interpretation was correlated with emotional understanding after free gesturing in dancers. Perhaps movement training would allow non-dancers to gain as great a benefit from movement to music as dancers. It might also be argued that dancers are more accustomed to listening and moving to classical music, which was the type of music employed in my study. During the still condition, however, it appears that non-dancers were able to gain as great, if not greater, an emotional experience from the music as dancers were. Inexperience moving to classical music could definitely have contributed to the lack of benefit gained from the free movement condition for non-dancers, but it is likely that this would have been the case for any musical genre, as dancers simply have more movement experience. Years of musical training did not differ significantly

  

38  

  

between groups, nor did familiarity ratings of the specific songs employed in the current study, suggesting that familiarity with genre or specific songs was also not an influential factor. While I think it is probable that non-dancers simply were not utilizing movement simulation as effectively as an aid in musical emotion perception, the possibility that non-dancers use a different neural system altogether in order to understand emotion in music should also be addressed. Future studies should measure MNS activation in dancers and non-dancers during music perception to demonstrate whether the two groups differentially employ the MNS during this perception, and if this is the case, whether non-dancers are employing other neural pathways more than dancers. The role of learning should also be considered as a potentially differing factor between the two groups in the current study. Dancers could be accustomed to learning action-perception links to music, and to perceiving music while acting on it. Non-dancers are not accustomed to engaging in this type of learning process. Perhaps in dancers, the MNS is more predisposed than in non-dancers to learn or encode musical processing in a way that involves movement interaction during encoding. The presence of movement during encoding could have helped dancers because this is their primary learning mechanism for music, whereas non-dancers could have been hindered by this condition because they primarily encode emotion from music through still listening. Since differences in emotional responsivity were observed following interactions as opposed to during interactions with music, the role of memory processes in emotional responsivity during subsequent music perception should also be considered. In the current study, dancers had greater emotional responsivity, and presumably greater MNS responsivity, during

  

39  

  

song listening that followed free movement. We presume that MNS ties to the musical cues became stronger after interacting with the music. It is also possible that enhanced memory encoding occurred during music listening involving free movement, due to the greater distinctiveness of this condition (Talmi, Luk, McGarry, & Moscovitch, 2007), and greater interaction with music during this condition (MacLeod, Gopie, Hourihan, Neary, & Ozubko, 2010). This enhanced memory could be what led to enhanced emotional responsivity, and presumably MNS responsivity, during retrieval. Future studies should examine the neural contributions of memory-related brain areas during encoding (the interaction conditions) and retrieval (subsequent perception conditions), in addition to MNS responsivity, to examine whether enhanced activation in memory systems could be causing enhanced MNS responsivity during retrieval, or whether enhanced MNS responsivity is occurring due to enhanced actionperception links within that system. The present study generated an interesting finding concerning liking of sad music after different levels of engagement with it. Both dancers and non-dancers liked music less after having gestured freely, as opposed to simply listening to music, with the effect of constrained movement falling in between (and not being different from either still or gesture conditions). Previous research suggests that sad music, despite its ability to evoke strong negative emotions, can still be well-liked (Schellenberg et al., 2008). It appears that this was the case in my study as well after participants listened without moving, as mean ratings were close to 5, indicating a neutral rating. This indicates that while dancers didn't necessarily like listening to the sad music, they did not dislike it and did not give lower ratings than for happy songs. However, after moving freely to sad music, mean ratings decreased significantly to approximately 4.4, indicating a negative average rating, and a significantly lower average rating than for happy

  

40  

  

songs. It is possible that when listeners normally hear sad music, they are able to inhibit their own tendency to mimic, in order to appreciate the music without becoming too emotionally involved. When asked to move to the music, however, the mover is forced to mimic the emotional cues in the music, which may cause feedback to the limbic system via the mirror neuron system, evoking a higher degree of emotional resonance with the music. In the case of sad music, this would mean evoking real sad emotions, which conceivably could be more aversive to the listener than vicariously experienced sad emotions. Examination of preinteraction data supported this idea, demonstrating that facial animation during sad music was negatively correlated with liking. A trend in the data suggested that breathing rates decreased for non-dancers after free movement, for sad songs. It is unclear why this decrease would have occurred for non-dancers as opposed to dancers. Perhaps non-dancers did not engage in the same degree of movement as dancers did during sad song listening, leading to less respiratory entrainment with music subsequently. It is unclear why there was no difference in corrugator or HR activity after different movement conditions for dancers or non-dancers. HR responses are generally less robust than SCR responses (Caccioppo, 2000), so perhaps a greater number of participants were needed in order to generate a difference for each of these measures. However, the fact that SCR and arousal ratings corresponded in patterns of polarization differences suggests that autonomic arousal as well as conscious feelings of arousal were increased following movement interaction with music in dancers. In terms of corrugator activity, it is also possible that the happy and sad songs in the Bach Cello Suites are less polarized in terms of valence than other groups of songs may be, decreasing the likelihood of eliciting corrugator polarization. However, since skin
   41  

  

conductance and marginal zygomatic polarization differences were elicited for these songs, this suggests that they were differentiable enough in valence and arousal to affect other measures. Future Directions While the current study explored the effects of moving to music on the mover, future studies should also explore the effects of viewing dance to music on the audience's perception of music. Exaggeration of bodily emotion expression leads to enhanced recognition in observers (Atkinson et al., 2004). Therefore, the performance-related purpose of dancing to music might be to provide a visual accentuation of the emotional movements depicted by the music. Viewing a dance to music enhances emotion perception of the music and different movement properties in dance have been found to correspond to specific emotions along the dimensions of valence and arousal (Camurri et al., 2003), just as different musical properties correspond to specific emotions along the same dimensions (Thompson, 2009). Future studies should measure the qualities of movement naturally elicited during free movement to music, to see whether the types of movement employed are directly linked to the degree of subsequent emotional understanding of the music, in the audience as well as in the performer. Future experiments should also explore whether the effects of movement to music on emotional understanding of music can be extended to increase overall emotional understanding in the mover. Mirroring in Dance/Movement Therapy is used with reported success in groups with deficits in empathy, such as those with autism (Adler, 1970). It is possible that practice moving emotionally in reaction to an emotional stimulus, whether musically or in regular social interaction, elicits similar exercise of the MNS, a system that is thought to be dysfunctional in autism. The possibility that movement practice could enhance MNS functioning seems quite plausible, since it has been shown that movement expertise leads to greater MNS activation
   42  

  

during observation of that movement in healthy populations (Cross et al., 2006; Calvo-Merino et al., 2005). Research studies should empirically test the effects of practice mimicking an emotional stimulus, whether in the musical or real-life domain, to see if this practice enhances emotional understanding in groups who have problems with empathy. Along these lines, individual differences in empathy should also be explored in dancers and non-dancers in future studies, to examine whether there are differences in empathy between movement experts and non-experts. Please see Appendix D for a post-hoc examination of individual differences in another emotion-related personality trait, musical absorption, that is, the tendency to become emotionally involved in music. Mimicry contributes to social understanding (Chartrand & Bargh, 1999; Barselou et al., 2003). In the current study I found that dancers generated greater zygomatic activity during perception of happy songs than non-dancers. It would be interesting to see whether this greater capacity for automatic emotional mimicry in dancers occurs in regular social situations as well. Perhaps movement training would increase the tendency to mimic emotional movements in populations with dysfunctional automatic mimicry, leading to greater social understanding. In fact, it has already been demonstrated that imitation leads to enhanced prosocial behaviours in autistic children (Ingersoll & Schreibman, 2006; Field, Field, Sanders & Nadel, 2001). Autistic populations may also gain a benefit specifically from dance training due to their enhanced propensity to understand emotion depicted in song. While this group is deficient in terms of their ability to detect emotion in vocal prosody, autistic children demonstrate equivalent musical processing, and even understanding of affect in music as healthy children. Forty percent of children with autism express a special interest in music and children with autism even perform

  

43  

  

better than healthy children on musical tasks involving pitch perception (Overy & MolnarSzakacs, 2009). Overy and Molnar-Szakacs (2009) suggest that music stimulates the MNS in these individuals, allowing them to process affective cues more easily. If this population has an easier time being asked to dance than to mimic regular social movements, perhaps they can use dance to engage in emotional movement exercise, in turn affecting the MNS and potentially extending to other social domains. For a more detailed discussion of the potential benefits of dance/movement therapy on MNS functioning and empathy enhancement, see McGarry & Russo (2011). Conclusions In the current study, I have demonstrated for the first time that free movement to music accentuates emotional responsivity towards happy and sad music in dancers. Through dance, performers simulate the emotional themes found in music and add an interpreted exaggeration, providing the audience with an audiovisual experience of exaggerated emotional movement. In the current study, I have demonstrated that when dancers interact through movement with music, they also experience an increase in emotional responsivity to songs during subsequent listening. My finding that movement expertise may contribute to movement benefits on emotional understanding is also a novel one. Not only does moving help an observer understand intention in daily situations, but regular practice moving may increase the propensity to use movement as an aid in social understanding. Individual differences and manipulation of movement training should be examined further in terms of their relationship to MNS functioning, and applicability to patients with empathy dysfunction.

  

44  

  

References Adler, J. (1970). Looking for me. New York: NYU Film Library. Atkinson, A., Dittrich, W., Gemmell, A., and Young, A. (2004). Emotion perception from dynamic and static body expressions in point-light and full-light displays. Perception, 33, 717-746. Barsalou, L. W., Niedenthal, P. M., Barbey, A. K., and Ruppert, J. A. (2003). Social embodiment. In B. Ross (Ed.), The psychology of learning and motivation. San Diego: Academic Press. Bach, J.S. (Composer), and Ma, Y.Y. (Performer) (1998). The Cello Suites [audio recording]. Boone, R.T., and Cunningham, J.G. (1998). Children's decoding of emotion in expressive body movement: The development of cue attunement. Developmental Psychology, 34, 10071016. Bradley, M. and Lang, P. (1994). Measuring emotion: The self-assessment manikin and the semantic differential. Journal of Behavioral Therapy and Experimental Psychiatry, 25 (1), 49-59. Brownlow, S., Dixon, A., Egbert, C., and Radcliffe, R. (1997). Perception of Movement and Dancer Characteristics from Point-Light Displays of Dance. The Psychological Record, 47, 411-421. Buccino, G., Binkofski, F., Fink, G., Fadiga, L., Fogassi, L., Gallese, V., et al. (2001). Action observation activates premotor and parietal areas in a somatotopic manner: an fMRI study. European Journal of Neuroscience, 13(2), 400-404. Calvo-Merino, B., Glaser, D., Grezes, J., Passingham, R., and Haggard, P. (2005). Action observation and acquired motor skills: an fMRI study with expert dancers. Cerebral Cortex, 15(8), 1243. Camurri, A., Lagerlof, I., and Volpe, G. (2003). Recognizing emotion from dance movement: comparison of spectator recognition and automated techniques. International Journal of Human-Computer Studies, 59(1), 213-225. Carr, L., Iacoboni, M., Dubeau, M., Mazziotta, J., and Lenzi, G. (2003). Neural mechanisms of empathy in humans: A relay from neural systems for imitation to limbic areas. Proceedings of the National Academy of Sciences, 100(9), 5497-5502. Chan, L., and Russo, R. (in prep). The facial feedback hypothesis and automatic mimicry in perception of sung emotion.

  

45  

  

Chartrand, T., and Bargh, J. (1999). The chameleon effect: The perception-behavior link and social interaction. Journal of Personality and Social Psychology, 76(6), 893-910. Clynes, M. (1973). Sentics: Biocybernetics of emotion communication. Annals of the New York Academy of Sciences, 220, 57-88. Cross, E.S., Hamilton, A.F.D.C., and Grafton, S.T. (2006). Building a motor simulation de novo: observation of dance by dancers. NeuroImage, 31, 1257­67. Darwin, C. (1872). The expression of the emotions in man and animals. New York: D. Appleton and Company. Dimberg, U., and Petterson, M. (2000). Facial reactions to happy and angry facial expressions: Evidence for right hemisphere dominance. Psychophysiology, 37(5), 693-696. Dittrich, W.H., Troscianko, T., Lea, S.E.G., and Morgan, D. (1996). Perception of emotion from dynamic point-light displays represented in dance. Perception, 25(6), 727 ­ 738. Etzel, J.A., Johnsen, E.L., Dickerson, J., Tranel, D., and Adolphs, R. (2006). Cardiovascular and respiratory responses during musical mood induction. International Journal of Psychophysiology 61 (1), 57­69. Fectau, S., Pascua-Leone, A., and Theoret, H. (2008). Psychopathy and the mirror neuron system: Preliminary findings from a non-psychiatric sample. Psychiatry Research, 160(2), 137-144. Field, T., Field, T., Sanders, C. and Nadel, J. (2001). Children with autism display more social behaviors after repeated imitation sessions. Autism, 5, 317-323. Foley, M.A., Bouffard, V., Raag, T., and Rose, M. (1991). The effects of enactive encoding, type of movement, and imagined perspective on memory of dance. Psychological Research, 53, 251-259. Fridlund, A. J. and Cacioppo, J. T. (1986). Guidelines for Human Electromyographic Research. Psychophysiology, 23, 567­589. Gabrielson, A., and Juslin, P. (1996). Emotional expression in music performance: between the performer's intention and the listener's experience. Psychology of Music, 24, 68-91. Gazzola, V., Aziz-Zadeh, L., and Keysers, C. (2006). Empathy and somatotopic auditory mirror system in humans. Current Biology, 16(18), 1824-1829. Iacoboni, M., and Dapretto, M. (2006). The mirror neuron system and the consequences of its dysfunction. Nature Reviews Neuroscience, 7, 942-951.

  

46  

  

Ingersol, B. and Schreibman, L. (2006). Teaching reciprocal imitation skills to young children with autism using a naturalistic behavioral approach: Effects on language, pretend play, and joint attention. Journal of autism and developmental disorders, 36(4), 487-505. Juslin, P.N., and Sloboda, J.A. (Eds). (2001). Music and emotion: Theory and research. Oxford: Oxford University Press. Krumhansl, C.L., and Schenk, D.L. (1997). Can dance reflect the structural and expressive qualities of music? A perceptual experiment on Balanchine's choreography of Mozart's Divertimento No. 15. Musicæ Scientiæ, 1(1), 63­85. Lagerlof, I. and Marie, D. (2009). Children's understanding of emotion in dance. European Journal of Developmental Psychology, 6(4), 409-431. Lahav, A., Saltzman, E., and Schlaug, G. (2007). Action representation of sound: Audiomotor recognition network while listening to newly acquired actions. The Journal of Neuroscience, 27(2), 308-314. Larsen, J.T., Norris, C.J. and Cacioppo, J.T. (2003). Effects of positive and negative affect on electromyographic activity over zygomaticus major and corrugator supercilii. Psychophysiology, 40, 776­785. Lidov, D. (2009). Hearing Curves: How does Music Represent Emotion? Talk presented at Ryerson University Music Series, Oct. 19. Livingstone, S., Thompson, W., and Russo, F. (2009). Facial Expressions and Emotional Singing: A Study of Perception and Production with Motion Capture and Electromyography. Music Perception, 26(5), 475-488. MacLeod, C.M., Gopie, N., Hourihan, K.L., Neary, K.R., and Ozubko, J.D. (2010). The production effect: Delineation of a phenomenon. Journal of Experimental Psychology: Learning, Memory, and Cognition, 36(3), 671-685. McGarry, L., and Russo, F. (2011). Mirroring in Dance/Movement Therapy: Potential mechanisms behind empathy enhancement. The Arts In Psychotherapy, 38, 178-184. Molnar-Szakacs, I., and Overy, K. (2006). Music and mirror neurons: From motion to `e'motion. Scan, 1, 235-241. Overy, K., and Molnar-Szakacs, I. (2009). Being together in time: Musical experience and the mirror neuron system. Music Perception, 26(5), 489-504. di Pellegrino, G., Fadiga, L., Fogassi, L., Gallese, V., and Rizzolatti, G. (1992). Understanding motor events: a neurophysiological study. Experimental Brain Research, 91(1), 176-180.

  

47  

  

Phillips-Silver, J., and Trainor, L. (2005). Feeling the beat: Movement influences infant rhythm perception. Science, 308, 1430. Pineda, J. (2008). Sensorimotor cortex as a critical component of an 'extended' mirror neuron system: Does it solve the development, correspondence, and control problems in mirroring? Behavioral and Brain Functions, 4(1), 47-63. Ramachandran, V.S. and Hirstein, W. (1999). The Science of Art: A Neurological Theory of Aesthetic Experience. Journal of Consciousness Studies, 6, 15­51. Repp, B. (1999). Expressive microstructure in music: A preliminary perceptual assessment of four composers' `pulses'. Music Perception, 6(3), 243-274. Riskind, J.H. (1984). They stoop to conquer: Guiding and self-regulatory functions of physical posture after success and failure. Journal of Personality and Social Psychology, 47, 479­ 493. Riskind, J.H., and Gotay, C.C. (1982). Physical posture: Could it have regulatory or feedback effects on motivation and emotion? Motivation and Emotion, 6, 273­298. Rizzolatti, G., and Craighero, L. (2004). The mirror neuron system. Annual Review of Neuroscience, 27, 169-92. Roy, M., Mailhot, J., Gosselin, N., Paquette, S., and Peretz, I. (2009). Modulation of the startle reflex by pleasant and unpleasant music. International Journal of Psychophysiology, 71, 37-42. Sandstrom, G.M., and Russo, F.A. (2010). Music hath charms: The effects of valence and arousal on the regulation of stress. Music and Medicine, 2, 137-143. Sandstrom, G.M., and Russo, F.A. (in revision). Absorption in Music: A scale to identify individuals with strong emotional responses to music. Psychology of Music. Schellenberg, G., Peretz, I., and Vieillard, S. (2008). Liking for happy- and sad-sounding music: Effects of exposure. Cognition and Emotion, 22(2), 218-237. Sevdalis, V., and Keller, P. (2009). Self-recognition in the perception of actions performed in synchrony with music. Annals of the New York Acadamy of Sciences, 1169, 499-502. Stel, M., van Baaren, R., and Vonk, R. (2007). Effects of mimicking: Acting prosocially by being emotionally moved. European Journal of Social Psychology, 38(6), 965­976. Talmi, D., Luk, B., McGarry, L., and Moscovitch, M. (2007). The contribution of relatedness and distinctiveness to emotionally enhanced memory. Journal of Memory and Language, 56(4), 555-574.

  

48  

  

Thompson, W.F., and Russo, F.A. (2007). Facing the Music. Psychological Science, 18, 756757. Thompson, W. F. (2009). Music, Thought, And Feeling: Understanding the Psychology of Music. New York: Oxford University Press. van Baaren, R., Holland, R., Kawakami, K., and van Knippenberg, A. (2004). Mimicry and prosocial behavior. Psychological Science, 15(1), 71-74. Vrana, S.R. (1995). Emotional modulation of skin conductance and eyeblink responses to a startle probe. Psychophysiology, 32, 351-357. Wicker, B., Keysers, C., Plailly, J., Royet, J., Gallese, V., and Rizzolatti, G. (2003). Both of Us Disgusted in My Insula: The Common Neural Basis of Seeing and Feeling Disgust. Neuron, 40(3), 655-664. Williams, J.H., Whiten, A., Suddendorf, T., and Perrett, D. (2001). Imitation, mirror neurons and autism. Neuroscience and Biobehavioral Reviews, 25(4), 287-295. Witvliet, C. and Vrana, S. (2007). Play it again Sam: Repeated exposure to emotionally evocative music polarizes liking and smiling responses, and influences other affective reports, facial EMG, and heart rate. Cognition and Emotion, 21(1), 3-25.

  

49  

  

Appendix A Analyses of pre-interaction data: Individual differences I wished to examine whether dancers and non-dancers could differentiate between happy and sad songs with their physiological responses. I also examined whether this responsivity was correlated with self-reported ratings for any measures. Pre-interaction zygomatic responses Four dancers and three non-dancers were excluded from pre-interaction zygomatic analyses due to outliers. As can be seen in Figure A1, dancers' zygomatic activity differentiated happy and sad songs better than non-dancers' did. There was a significant group by condition interaction; F(1,54) = 9.34, p < .005. Follow-up t tests revealed that dancers were able to distinguish between happy and sad songs with their mimicry activity, generating marginally higher zygomatic activity during happy music than sad at a Bonferroni-corrected alpha level of p = .025; t(26) = 2.35, p = .026, whereas non-dancers were not, and actually trended toward having less zygomatic activity for happy songs than sad; t(28) = -1.92, p = .065.

  

50  

  

Figure A1. Zygomatic activity across songs, pre-interaction. Mean zygomatic activity with standard errors. Dancers' zygomatic activity differentiated happy and sad songs better than non dancers' did.

Zygoma-c  ac-vity,  pre-interac-on   phase  
0.45   0.4   0.35   0.3   0.25   0.2   0.15   0.1   0.05   0   Happy   Sad  

Dancers   Non-Dancers  

Pre-interaction corrugator responses Two dancers and two non-dancers were excluded from pre-interaction corrugator analyses due to outliers. A repeated measures ANOVA with 2 conditions (Emotion: Happy, sad) by 2 groups (dancer, non-dancer) did not yield a significant main effect; F(1,57) = 1.44, ns, or an interaction; F(1,57) = 0, ns, but trends suggest that both groups generated greater corrugator activity during sad songs, as predicted (see Figure A2).

  

51  

  

Figure A2. Corrugator activity, pre-interaction. Mean corrugator activity with standard errors. Mean differences suggest that both groups generated slightly greater activity toward sad songs, but this effect was not significant.

Corrugator  ac-vity,  pre-interac-on   phase  
0.4   0.35   0.3   0.25   0.2   0.15   0.1   0.05   0   Happy   Sad  

Dancers   Non-Dancers  

Pre-interaction skin conductance, heart rate, and respiration Pre-interaction group by condition differences were not significant for skin conductance, heart rate, or respiration measures. Individual differences Pre-interaction song responses were compared along several indices to see whether individual differences in physiological responsiveness during listening without interaction with music was correlated with ratings. In order to examine whether individual differences in mimicry are linked to emotional understanding/experience in terms of ratings, I examined whether facial mimicry was correlated with emotion ratings in my pre-interaction song listening data. Zygomatic polarization scores between happy and sad songs during listening, before any interaction with songs, was correlated positively with arousal ratings for happy (r(58) = .38, p < .005) and sad songs (r(58) = .27, p <

  

52  

  

.05), as well as marginally with happy valence ratings (r(58) = .19, p = .145) and sad valence ratings (r(58) = .22, p = .087). Corrugator, SCR, HR, and RSP activity were not correlated with any rating scales. When I examined dancers' data alone, zygomatic mimicry during music listening was correlated with emotional ratings to an even greater extent (see Figures A3 and A4). Zygomatic polarization scores were positively correlated with valence ratings for happy (r(27) = .41, p < .05) and sad songs (r(27) = .42, p < .05, N = 29), as well as arousal ratings for happy (r(27) = .54, p < .005) songs, and marginally with arousal ratings for sad songs (r(27) = .33, p = .084). Again, there were no correlations for corrugator or SCR activity.

  

53  

  

Figure A3. Correlations between zygomatic polarizations and happy and sad song valence ratings for dancers. Dancers' zygomatic polarizations were positively correlated with valence ratings for sad and happy songs.

  

54  

  

Figure A4. Correlations between zygomatic polarizations and happy and sad song arousal ratings for dancers. Dancers' zygomatic polarizations were positively correlated with arousal ratings for sad and happy songs.

Interestingly, when I examined non-dancers' data alone, all correlations of valence and arousal ratings with zygomatic polarizations went away. It appears that dancers' correlations were driving the across-group findings. RSP polarizations were correlated with valence ratings for happy songs (r(25) = .43, p < .05), but not sad songs, or arousal ratings, and there were no correlations between RSP responses and emotion ratings for dancers.

  

55  

  

Discussion Dancers' ratings were correlated with zygomatic mimicry whereas non-dancers' ratings were not, supporting the idea that neural or peripheral mimicry is not linked to emotional responding to the same degree in everyone. It is thus possible that non-dancers use a different cognitive system altogether in order to perceive the emotionality of music, which is unaffected by movement.

  

56  

  

Appendix B One week follow-up In order to determine whether changes in physiological responses would remain in place one week later, I conducted a follow-up measurement of all physiological responses, valence, arousal, and liking ratings one week later. I discontinued this measurement partway through the study, as it was not yielding reliable results. Methods Participants 21 dancers and 22 non-dancers participated in the follow-up session. Procedure Upon arrival at the lab, psychophysiological measurement devices were attached, as in session one. Participants listened to the same music as in session one, and their physiological and self-report ratings were taken following the same procedures as in session one. Data Analysis Initial inspection of data suggested that there were no differences in polarization between groups or conditions for any measure (see Tables B1-B6), so this session was discontinued from the experiment halfway through data collection.

  

57  

  

Table B1. One week follow-up: Physiological and self-report data. Means and standard deviations for valence, arousal, zygomatic, corrugator, and skin conductance data. Measurement N Mean SD Listen Track Gesture Listen Track Gesture Valence Dancers 25 1.13 1.38 1.47 1.62 1.78 1.74 Polarization Non22 2.14 1.48 1.7 1.73 1.78 1.47 Dancers Arousal Dancers 25 1.04 1.48 1.80 1.73 1.74 1.56 Polarization Non22 1.58 1.70 1.64 1.46 1.47 1.86 Dancers Zygomatic Dancers 17 -.04 -.008 .007 .48 .19 .31 Polarization Non 16 .03 .05 .06 .17 .24 .32 Dancers Corrugator Dancers 21 .11 .26 .03 .43 .70 .53 Polarization Non 20 .08 .06 -.08 .37 .43 .47 Dancers SCR Dancers 16 -.08 .036 .07 .17 .21 .13 Polarization Non 17 -.47 -.13 -.05 .51 .21 .14 Dancers Tables B2-B6. ANOVA tables. Mixed model ANOVAs were conducted with movement instruction as the within-subjects factor (still, constrained movement, free gesture) and movement experience as the between-subjects factor (dancer, non-dancer) for valence, arousal, zygomatic, corrugator, and SCR polarizations. There were no significant results. Table B2. Valence Polarization ANOVA Table Sum of Mean Squares Df Square Condition Condition by Group Error Group Error 1.071 5.674 179.982 6.797 205.313 2 2 90 1 45 .536 2.837 2.000 6.797 4.563 1.490 .229

F .268 .268

P .766 .766

  

58  

  

Table B3. Arousal Polarization ANOVA Table Sum of Mean Squares Df Square Condition Condition by Group Error Group Error 4.007 2.794 181.918 1.413 181.704 2 2 90 1 45 2.004 1.397 2.021 1.413 4.038

F .991 .691

P .375 .504

.350

.557

Table B4. Zygomatic Polarization ANOVA Table Sum of Mean Squares Df Square Condition Condition by Group Error Group Error .021 1.63 .001 1.63 3451.65 .086 2.22 50.6 5 1 31 .011 .001 .133 .086 .072

F .097 .005

P .870 .987

1.203

.281

  

59  

  

Table B5. Corrugator Polarization ANOVA Table Sum of Mean Squares df Square F Condition Condition by Group Error Group Error .716 1.73 .170 1.73 16.999 .403 12.474 67.6 1 1 39 .358 .098 .251 .403 .320 1.260 1.643 .389

P .204 .650

.269

Table B6. Skin Conductance Polarization ANOVA Table Sum of Mean Squares Square df F Condition Condition by Group Error Group Error .120 .980 22.314 .127 19.551 2 2 62 1 31 .06 .490 .360 .127 .631 .201 .166 1.361

P .847 .264

.657

  

60  

  

Figures B1-B5. Graphs of physiological data for the one-week follow-up session. Mean polarization scores with standard errors. No differences in responsivity to songs was observed across conditions or groups at this stage. Figure B1. Follow-up Valence Polarization.

Follow-up  Valence  Polariza-on  
3   2.5   2   1.5   1   0.5   0   S1ll   Constrained   Free   Dancers   Non-Dancers  

Figure B2. Follow-up Arousal Polarization.

Follow-up  Arousal  Polariza-on  
2.5   2   1.5   Dancers   1   0.5   0   S1ll   Constrained   Free   Non-Dancers  

  

61  

  

Figure B3. Follow-up Zygomatic Polarization.

Follow-up  Zygoma-c  Polariza-on  
0.2   0.15   0.1   0.05   0   -0.05   -0.1   -0.15   -0.2   S1ll   Constrained   Free   Dancers   Non-Dancers  

Figure B4. Follow-up Corrugator Polarization.

Follow-up  Corrugator  Polariza-on  
0.5   0.4   0.3   0.2   0.1   0   -0.1   -0.2   -0.3   S1ll   Constrained   Free   Dancers   Non-Dancers  

  

62  

  

Figure B5. Follow-up SCR Polarization.

Follow-up  SCR  Polariza-on  
0.8   0.6   0.4   0.2   0   -0.2   -0.4   -0.6   -0.8   -1   -1.2   S1ll   Constrained   Free   Dancers   Non-Dancers  

  

63  

  

Appendix C List of songs chosen from The Bach Cello Suites by Yo Yo Ma NEGATIVE GROUP Suite 4 in E flat Major: Sarabande - J.S.Bach Suite 5 in C Minor: Prelude - J.S.Bach Suite 5 in C Minor: Allemande - J.S.Bach Suite 5 in C Minor: Courante - J.S.Bach Suite 5 in C Minor: Sarabande - J.S.Bach Suite 5 in C Minor: Gigue - J.S.Bach Suite 6 in D Major: Allemande - J.S.Bach Suite 6 in D Major: Sarabande - J.S.Bach Suite No. 1 In G Major: Sarabande - J. S. Bach Suite No. 2 in D minor: Prelude - J. S. Bach Suite No. 2 in D minor: Allemande - J. S. Bach Suite No. 2 in D minor: Sarabande - J. S. Bach Suite No. 2 in D minor: Menuett I 1 - 2 - J. S. Bach Suite No. 3 In C Major: Sarabande - J. S. Bach Suite No. 4 In E-Flat Major: Prelude - J. S. Bach Suite No. 4 In E-Flat Major: Allemande - J. S. Bach

POSITIVE GROUP Suite 6 in D Major: Prelude - J.S.Bach Suite No. 3 In C Major: Gigue - J. S. Bach Suite 4 in E flat Major: Gigue - J.S.Bach Suite No. 3 In C Major: Allemande - J. S. Bach Suite 6 in D Major: Gigue - J.S.Bach

  

64  

  

Suite 6 in D Major: Gavotte 1 - 2 - J.S.Bach Suite No. 2 in D minor: Gigue - J. S. Bach Suite No. 1 In G Major: Courante - J. S. Bach Suite No. 1 In G Major: Gigue - J. S. Bach Suite 5 in C Minor: Gavotte 1 - 2 - J.S.Bach Suite No. 3 In C Major: Courante - J. S. Bach Suite No. 2 in D minor: Courante - J. S. Bach Suite No. 1 In G Major: Prelude - J. S. Bach Suite No. 3 In C Major: Prelude - J. S. Bach Suite 6 in D Major: Courante - J.S.Bach Suite No. 3 In C Major: Bourree 1 - 2 - J. S. Bach

  

65  

  

Appendix D Absorption Scale Due to the differences in patterns of polarity in emotional responsiveness after moving in dancers vs. non dancers, I wanted to examine whether movement expertise is also related to individual differences in musical absorption (Sandstrom & Russo, in revision). The musical absorption scale (Sandstrom & Russo, in revision) measures a person's willingness to become emotionally involved in music. Since dancers presumably exhibit more MNS activity during music listening due to action-perception links in the brain with music, it might be predicted that dancers will score more highly on musical absorption. Based on some of our emotional responsiveness results, though, non-dancers gained a higher benefit of still listening on emotional responsivity to music, so these individuals might have a high capacity to become absorbed by music without moving as well. However, since dancers' pre-interaction data also supported greater differentiation between happy and sad songs based on facial mimicry and skin conductance, and since these responses were correlated with ratings of valence and arousal, I expected that dancers would score higher on musical absorption than non-dancers. Methods 10 dancers and 17 non-dancers were successfully re-recruited to complete the scale through email. Participants were compensated with a $5 Starbucks gift certificate. Results A t test comparing these groups was not significant; t(25) = .688, ns. A correlational analysis was run across subjects to see whether individual differences in absorption were related to individual differences on any other scales. Absorption scores across subjects were not correlated with any measures. I also looked at absorption score correlations within each group.

  

66  

  

Absorption scores in dancers were correlated with HR responses towards sad songs only; r(7) = .793, p < .05, as well as with RSP polarization scores; r(6) = .870, p < .05. Within non dancers, no correlations with absorption scores were found. Discussion The insignificant t-test suggests that the two groups did not differ in their degrees of musical absorption. However, I had a low response rate when trying to collect this data post hoc, so it is possible that with all participants included, results would have been significant. Within dancers, I did find that absorption was negatively correlated with heart rate towards sad songs only, which indicates that as absorption scores went up, heart rate decreased more during sad songs. This would be consistent with expectations that one who is more absorbed in a sad song will find the song more calming/less arousing than someone who is less absorbed. Absorption was also positively correlated with RSP polarization, indicating that dancers scoring higher in absorption had a greater difference in respiration between high-arousal (happy) and low-arousal (sad) songs than those who were lower in absorption. These results are consistent with my expectation that more arousing songs would elicit greater RSP activation, and these results indicate that this occurs most strongly for those who are more inclined to be absorbed by the music. It is interesting that pre-interaction differences in HR and RSP were found to be linked to absorption in dancers, since I did not find effects of interaction on HR or RSP in dancers on postinteraction responses. This suggests that HR and RSP are trait measures rather than state, as these scores seemed to vary with a personality trait but were unaffected by movement interactions with music in dancers.

  

67  

  

In conclusion, my predictions regarding musical absorption in dancers were supported in terms of individual differences in trait measurements, but not in terms of facial mimicry. Future studies should measure musical absorption in all participants in order to gain higher power to discern a difference between movement experts and non-experts in this domain.

  

68  

