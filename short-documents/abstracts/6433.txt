This dissertation deals with the design of sub-per-stage delay time-to-digital converters (TDCs).  Two classes of TDCs namely pulse-shrinking TDCs and TDCs are investigated.
In pulse-shrinking TDCs, a two-step pulse-shrinking TDC consisting of a set of coarse and fine pulse-shrinking TDCs is proposed to increase a dynamic range without employing a large number of pulse-shrinking stages. A residual time extraction scheme capable of extracting the residual time of the coarse TDC is developed.  The simulation / measurement results of the TDC implemented in an IBM 130 nm 1.2 V CMOS technology show that the TDC offers 1.4 ns conversion time,  1LSB DNL and INL, and consumes 0.163 pJ/step.  To further improve the conversion time, a time-interleaved scheme is developed to extract the residual time of the coarse TDC and utilized in design of a two-step pulse-shrinking TDC. Residual time extraction is carried out in parallel with digitization of minimize latency.  The simulation and measurement results of the TDC show that is offers 0.85 ns conversion time, 0.285 LSB DNL, and 0.78 LSB.
In TDCs, a 1-1 multi-stage noise shaping (MASH) TDC with a new differential cascode time integrator is proposed to suppress even-order harmonic tones and current mismatch-induced timing errors.  Simulation results show that the proposed TDC offers 1.9 ps time resolution over 48-415 kHz signal band with consuming 5-2 uW.  Finally , an all-digital first-order TDC utilizing a bi-directional gated delay line integrator is developed.  Time integration is obtained via the accumulation of charge of the load capacitor of gated delay stages and the logic state of gated delay stages.  The elimination of analog components allows the TDC to benefit fully from technology scaling.  Simulation results show that the TDC offers firs-order noise-shaping, 10.8 ps time resolution while consuming 46 uW.
