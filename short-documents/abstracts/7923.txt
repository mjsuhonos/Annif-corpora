Corporate use of algorithms for marketing purposes often entails that user data is collected and
processed by corporations to influence consumers online. Despite the technological efficiencies
that many algorithms provide, algorithms often pose threats to human autonomy and privacy in a
consumer context. While algorithms have the capacity to influence individuals and shape their
behaviour, human inputs and regulations shape their functions and mandates. Regulatory measures and government legislation are also capable of shaping algorithmic functions, sometimes in ways that mitigate threats to user autonomy and privacy. Many scholars suggest
that implementing practices of accountability and transparency into algorithmic regulation can
mitigate the threats algorithms pose to society. This Major Research Paper will conceptualize
algorithmic threats to user privacy and autonomy, as well as practices of accountability and
transparency. A critical analysis of the European Union’s General Data Protection Regulation
will assist in recognizing specific practices that are capable of mitigating algorithmic threats to
user privacy and autonomy. The analysis and discussion of the GDPR’s potential efficacy will
use mutual shaping theory to explore the role legislation plays in the co-evolution of algorithmic
technology and society.

Key Words: Algorithms, Data-Gathering, Privacy, Autonomy, Accountability, Transparency,
General Data Protection Regulation, GDPR, European Union, Mutual Shaping Theory
